{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK IS CREATED AT UC BERKELEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is flexible alternative to MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARK VS MAPREDUCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. MapReduce required dataFile stored in \"HDFS\" but Spark work with Data stored in \"HDFS\" as well as other Data Format also like Cassandra, AWS, OTHER\n",
    "\n",
    "##### 2. Spark is FASTER than MapReduce :\n",
    "#####                     It achieve it using ::\n",
    "                        After each and every map and reduce opertion MapReduce Store data in disk.\n",
    "                        While Spark all data,result in memory and when memory is fill then it store it in disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark is written in Scala programming language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  pyspark --master local[2]\n",
    "it means use two local core as 2 separte executor .\n",
    "it run on ur local computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apache Spark is a lightning fast real-time processing framework. It does in-memory computations to analyze data in real-time. It came into picture as Apache Hadoop MapReduce was performing batch processing only and lacked a real-time processing feature. Hence, Apache Spark was introduced as it can perform stream processing in real-time and can also take care of batch processing.Apart from real-time and batch processing, Apache Spark supports interactive queries and iterative algorithms also. Apache Spark has its own cluster manager, where it can host its application. It leverages Apache Hadoop for both storage and processing. It uses HDFS (Hadoop Distributed File system) for storage and it can run Spark applications on YARN as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To support Python with Spark, Apache Spark community released a tool, PySpark. Using PySpark, you can work with RDDs in Python programming language also. It is because of a library called Py4j that they are able to achieve this. PySpark offers PySpark Shell which links the Python API to the spark core and initializes the Spark context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RDD in spark is not persistance . it discard it after some time. so to make it avaliable all time use \"cache() or persistant()\" method. otherwise spark discard it and we have to recompute RDD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark RDD Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wo types of Apache Spark RDD operations are- Transformations and Actions. A Transformation is a function that produces new RDD from the existing RDDs but when we want to work with the actual dataset, at that point Action is performed. When the action is triggered after the result, new RDD is not formed like transformation.\n",
    "\n",
    "In this Apache Spark RDD operations tutorial we will get the detailed view of what is Spark RDD, what is the transformation in Spark RDD, various RDD transformation operations in Spark with examples, what is action in Spark RDD and various RDD action operations in Spark with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark RDD Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with Spark RDD Operations, let us deep dive into RDD in Spark.\n",
    "\n",
    "Apache Spark RDD supports two types of Operations-\n",
    "\n",
    "Transformations\n",
    "\n",
    "Actions\n",
    "\n",
    "Now let us understand first what is Spark RDD Transformation and Action-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Transformation is a function that produces new RDD from the existing RDDs. It takes RDD as input and produces one or more RDD as output. Each time it creates new RDD when we apply any transformation. Thus, the so input RDDs, cannot be changed since RDD are immutable in nature.\n",
    "\n",
    "Applying transformation built an RDD lineage, with the entire parent RDDs of the final RDD(s). RDD lineage, also known as RDD operator graph or RDD dependency graph. It is a logical execution plan i.e., it is Directed Acyclic Graph (DAG) of the entire parent RDDs of RDD.\n",
    "\n",
    "Transformations are lazy in nature i.e., they get execute when we call an action. They are not executed immediately. Two most basic type of transformations is a map(), filter().\n",
    "\n",
    "After the transformation, the resultant RDD is always different from its parent RDD. It can be smaller (e.g. filter, count, distinct, sample), bigger (e.g. flatMap(), union(), Cartesian()) or the same size (e.g. map).\n",
    "\n",
    "There are two types of transformations:\n",
    "\n",
    "Narrow transformation – In Narrow transformation, all the elements that are required to compute the records in single partition live in the single partition of parent RDD. A limited subset of partition is used to calculate the result. Narrow transformations are the result of map(), filter().\n",
    "Apache Spark Narrow Transformation Operation\n",
    "\n",
    "Wide transformation – In wide transformation, all the elements that are required to compute the records in the single partition may live in many partitions of parent RDD. The partition may live in many partitions of parent RDD. Wide transformations are the result of groupbyKey() and reducebyKey().\n",
    "Spark Wide Transformation Operations\n",
    "\n",
    "There are various functions in RDD transformation. Let us see RDD transformation with examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map function iterates over every line in RDD and split into new RDD. Using map() transformation we take in any function, and that function is applied to every element of RDD.\n",
    "\n",
    "In the map, we have the flexibility that the input and the return type of RDD may differ from each other. For example, we can have input RDD type as String, after applying the map() function the return RDD can be Boolean.\n",
    "\n",
    "For example, in RDD {1, 2, 3, 4, 5} if we apply “rdd.map(x=>x+2)” we will get the result as (3, 4, 5, 6, 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  flatMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of flatMap() function, to each input element, we have many elements in an output RDD. The most simple use of flatMap() is to split each input string into words.\n",
    "\n",
    "Map and flatMap are similar in the way that they take a line from input RDD and apply a function on that line. The key difference between map() and flatMap() is map() returns only one element, while flatMap() can return a list of elements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark RDD filter() function returns a new RDD, containing only the elements that meet a predicate. It is a narrow operation because it does not shuffle data from one partition to many partitions.\n",
    "\n",
    "For example, Suppose RDD contains first five natural numbers (1, 2, 3, 4, and 5) and the predicate is check for an even number. The resulting RDD after the filter will contain only the even numbers i.e., 2 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mapPartitions(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MapPartition converts each partition of the source RDD into many elements of the result (possibly none). In mapPartition(), the map() function is applied on each partitions simultaneously. MapPartition is like a map, but the difference is it runs separately on each partition(block) of the RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mapPartitionWithIndex()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is like mapPartition; Besides mapPartition it provides func with an integer value representing the index of the partition, and the map() is applied on partition index wise one after the other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### union(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the union() function, we get the elements of both the RDD in new RDD. The key rule of this function is that the two RDDs should be of the same type.\n",
    "\n",
    "For example, the elements of RDD1 are (Spark, Spark, Hadoop, Flink) and that of RDD2 are (Big data, Spark, Flink) so the resultant rdd1.union(rdd2) will have elements (Spark, Spark, Spark, Hadoop, Flink, Flink, Big data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  intersection(other-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the intersection() function, we get only the common element of both the RDD in new RDD. The key rule of this function is that the two RDDs should be of the same type.\n",
    "\n",
    "Consider an example, the elements of RDD1 are (Spark, Spark, Hadoop, Flink) and that of RDD2 are (Big data, Spark, Flink) so the resultant rdd1.intersection(rdd2) will have elements (spark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It returns a new dataset that contains the distinct elements of the source dataset. It is helpful to remove duplicate data.\n",
    "\n",
    "For example, if RDD has elements (Spark, Spark, Hadoop, Flink), then rdd.distinct() will give elements (Spark, Hadoop, Flink)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use groupByKey() on a dataset of (K, V) pairs, the data is shuffled according to the key value K in another RDD. In this transformation, lots of unnecessary data get to transfer over the network.\n",
    "\n",
    "Spark provides the provision to save data to disk when there is more data shuffled onto a single executor machine than can fit in memory. Follow this link to learn about RDD Caching and Persistence mechanism in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  reduceByKey(func, [numTasks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use reduceByKey on a dataset (K, V), the pairs on the same machine with the same key are combined, before the data is shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  sortByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply the sortByKey() function on a dataset of (K, V) pairs, the data is sorted according to the key K in another RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Join is database term. It combines the fields from two table using common values. join() operation in Spark is defined on pair-wise RDD. Pair-wise RDDs are RDD in which each element is in the form of tuples. Where the first element is key and the second element is the value.\n",
    "\n",
    "The boon of using keyed data is that we can combine the data together. The join() operation combines two data sets on the basis of the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Transformations create RDDs from each other, but when we want to work with the actual dataset, at that point action is performed. When the action is triggered after the result, new RDD is not formed like transformation. Thus, Actions are Spark RDD operations that give non-RDD values. The values of action are stored to drivers or to the external storage system. It brings laziness of RDD into motion.\n",
    "\n",
    "An action is one of the ways of sending data from Executer to the driver. Executors are agents that are responsible for executing a task. While the driver is a JVM process that coordinates workers and execution of the task. Some of the actions of Spark are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action count() returns the number of elements in RDD.\n",
    "\n",
    "For example, RDD has values {1, 2, 2, 3, 4, 5, 5, 6} in this RDD “rdd.count()” will give the result 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### . collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action collect() is the common and simplest operation that returns our entire RDDs content to driver program. The application of collect() is unit testing where the entire RDD is expected to fit in memory. As a result, it makes easy to compare the result of RDD with the expected result.\n",
    "\n",
    "Action Collect() had a constraint that all the data should fit in the machine, and copies to the driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action take(n) returns n number of elements from RDD. It tries to cut the number of partition it accesses, so it represents a biased collection. We cannot presume the order of the elements.\n",
    "\n",
    "For example, consider RDD {1, 2, 2, 3, 4, 5, 5, 6} in this RDD “take (4)” will give result { 2, 2, 3, 4}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  top()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If ordering is present in our RDD, then we can extract top elements from our RDD using top(). Action top() use default ordering of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The countByValue() returns, many times each element occur in RDD.\n",
    "\n",
    "For example, RDD has values {1, 2, 2, 3, 4, 5, 5, 6} in this RDD “rdd.countByValue()”  will give the result {(1,1), (2,2), (3,1), (4,1), (5,2), (6,1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduce() function takes the two elements as input from the RDD and then produces the output of the same type as that of the input elements. The simple forms of such function are an addition. We can add the elements of RDD, count the number of words. It accepts commutative and associative operations as an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  foreach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a situation where we want to apply operation on each element of RDD, but it should not return value to the driver. In this case, foreach() function is useful. For example, inserting a record into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Spark In-memory Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the data in-memory improves the performance by an order of magnitudes. The main abstraction of Spark is its RDDs. And the RDDs are cached using the cache() or persist() method.Follow this link to learn Spark RDD persistence and caching mechanism.\n",
    "\n",
    "When we use cache() method, all the RDD are stored in-memory. When RDD stores the value in memory, the data that does not fit in memory is either recalculated or the excess data is sent to disk. Whenever we want RDD, it can be extracted without going to disk. This reduces the space – time complexity and overhead of disk storage.\n",
    "\n",
    "The in-memory capability of Spark is good for machine learning and micro-batch processing. It provides faster execution for iterative jobs.\n",
    "\n",
    "When we use persist() method the RDDs can also be stored in-memory, we can use it across parallel operations. The difference between cache() and persist() is that using cache() the default storage level is MEMORY_ONLY while using persist() we can use various storage levels.\n",
    "\n",
    "Spark RDD persistence is an optimization technique in which saves the result of RDD evaluation. Using this we save the intermediate result so that we can use it further if required. It reduces the computation overhead.\n",
    "\n",
    "We can make persisted RDD through cache() and persist() methods. When we use the cache() method we can store all the RDD in-memory. We can persist the RDD in memory and use it efficiently across parallel operations.\n",
    "\n",
    "The difference between cache() and persist() is that using cache() the default storage level is MEMORY_ONLY while using persist() we can use various storage levels (described below). It is a key tool for an interactive algorithm. Because, when we persist RDD each node stores any partition of it that it computes in memory and makes it reusable for future use. This process speeds up the further computation ten times.\n",
    "\n",
    "When the RDD is computed for the first time, it is kept in memory on the node. The cache memory of the Spark is fault tolerant so whenever any partition of RDD is lost, it can be recovered by transformation Operation that originally created it.\n",
    "\n",
    "Storage levels of RDD Persist() in Spark\n",
    "\n",
    "The various storage level of persist() method in Apache Spark RDD are:\n",
    "\n",
    "MEMORY_ONLY\n",
    "\n",
    "MEMORY_AND_DISK\n",
    "\n",
    "MEMORY_ONLY_SER\n",
    "\n",
    "MEMORY_AND_DISK_SER\n",
    "\n",
    "DISK_ONLY\n",
    "\n",
    "MEMORY_ONLY_2 and MEMORY_AND_DISK_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if there is more than one sparksubmit kill them using \"kill pid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SparkContext is the entry gate of Apache Spark functionality. The most important step of any Spark driver application is to generate SparkContext. It allows your Spark Application to access Spark Cluster with the help of Resource Manager (YARN/Mesos). To create SparkContext, first SparkConf should be made. The SparkConf has a configuration parameter that our Spark driver application will pass to SparkContext.\n",
    "\n",
    "How to Create SparkContext Class?\n",
    "\n",
    "If you want to create SparkContext, first SparkConf should be made. The SparkConf has a configuration parameter that our Spark driver application will pass to SparkContext. Some of these parameter defines properties of Spark driver application. While some are used by Spark to allocate resources on the cluster, like the number, memory size, and cores used by executor running on the worker nodes.\n",
    "\n",
    "In short, it guides how to access the Spark cluster. After the creation of a SparkContext object, we can invoke functions such as textFile, sequenceFile, parallelize etc. The different contexts in which it can run are local, yarn-client, Mesos URL and Spark URL.\n",
    "\n",
    "Once the SparkContext is created, it can be used to create RDDs, broadcast variable, and accumulator, ingress Spark service and run jobs. All these things can be carried out until SparkContext is stopped.\n",
    "\n",
    "\n",
    " Functions of SparkContext in Apache Spark\n",
    " \n",
    " 1. To get the current status of Spark Application\n",
    " \n",
    "1. SpkEnv –\n",
    "\n",
    "It is a runtime environment with Spark’s public services. It interacts with each other to establish a distributed computing platform for Spark Application. A SparkEnv object that holds the required runtime services for running Spark application with the different environment for the driver and executor represents the Spark runtime environment.\n",
    "\n",
    "2. SparkConf – \n",
    "\n",
    "The Spark Properties handles maximum applications settings and are configured separately for each application. We can also easily set these properties on a SparkConf. Some common properties like master URL and application name, as well as an arbitrary key-value pair, configured through the set() method.\n",
    "\n",
    "3. Deployment environment (as master URL) – \n",
    "\n",
    "Spark deployment environment are of two types namely local and clustered. Local mode is non-distributed single-JVM deployment mode. All the execution components – driver, executor, LocalSchedulerBackend, and master are present in same single JVM. Hence, the only mode where drivers are useful for execution is the local mode. For testing, debugging or demonstration purpose, the local mode is suitable because it requires no earlier setup to launch spark application. While in clustered mode, the Spark runs in distributive mode.\n",
    "\n",
    "6.2. To set the configuration\n",
    "\n",
    "1. Master URL – \n",
    "\n",
    "The master method returns back the current value of spark.master which is deployment environment in use.\n",
    "\n",
    "2. Local properties-\n",
    "\n",
    "Creating Logical Job Groups – The reason of local properties concept is to form logical groups of jobs by means of properties that create the separate job launched from different threads belong to a single logic group. We can set a local property which will affect Spark jobs submitted from a thread, such as the Spark fair scheduler pool.\n",
    "\n",
    "3. Default Logging level –\n",
    "\n",
    "It lets you set the root login level in a Spark application, \n",
    "\n",
    "6.3. To Access various services\n",
    "\n",
    "It also helps in accessing services like TaskScheduler, LiveListenBus, BlockManager, SchedulerBackend, ShuffelManager and the optional ContextCleaner.\n",
    "\n",
    "6.4. To Cancel a job\n",
    "\n",
    "cancleJob simply requests DAGScheduler to drop a Spark job.\n",
    "\n",
    "Learn about Spark DAG(Directed Acyclic Graph) in detail.\n",
    "\n",
    "6.5. To Cancel a stage\n",
    "\n",
    "cancleStage simply requests DAGScheduler to drop a Spark stage.\n",
    "\n",
    "6.6. For Closure cleaning in Spark\n",
    "\n",
    "Spark cleanups the closure every time an Action occurs, i.e. the body of Action before it is serialized and sent over the wire to execute. The clean method in SparkContext does this. This, in turn, calls ClosureClean.clean method. It not only cleans the closure but also referenced closure is clean transitively. It assumes serializable until it does not explicitly reference unserializable objects.\n",
    "\n",
    "6.7. To Register Spark listener\n",
    "\n",
    "We can register a custom SparkListenerInterface with the help of addSparkListener method. We can also register custom listeners using the spark.extraListeners setting.\n",
    "\n",
    "6.8. Programmable Dynamic allocation\n",
    "\n",
    "It also provides the following method as the developer API for dynamic allocation of executors: requestExecutors, killExecutors, requestTotalExecutors, getExecutorIds.\n",
    "\n",
    "6.9. To access persistent RDD\n",
    "\n",
    "getPersistentRDDs gives the collection of RDDs that have marked themselves as persistent via cache.\n",
    "\n",
    "6.10. To unpersist RDDs\n",
    "\n",
    "From the master’s Block Manager and the internal persistentRdds mapping, the unpersist removes the RDD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Engine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark engine is responsible for scheduling, distributing, monitoring application across spark cluster\n",
    "\n",
    "spark cluster contain 1 master node and other slave node.- which run application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Driver:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is run on master node and responsiable for tranformation and action on RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Apache Spark Cluster Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark is an engine for Big Data processing. One can run Spark on distributed mode on the cluster. In the cluster, there is master and n number of workers. It schedules and divides resource in the host machine which forms the cluster. The prime work of the cluster manager is to divide resources across applications. It works as an external service for acquiring resources on the cluster.\n",
    "\n",
    "The cluster manager dispatches work for the cluster. Spark supports pluggable cluster management. The cluster manager in Spark handles starting executor processes. Refer this link to learn Apache Spark terminologies and concepts.\n",
    "\n",
    "Apache Spark system supports three types of cluster managers namely-\n",
    "\n",
    "a) Standalone Cluster Manager\n",
    "\n",
    "b) Hadoop YARN\n",
    "\n",
    "c) Apache Mesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Apache Spark Works – Run-time Spark Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Apache Spark, the central coordinator is called the driver. When you enter your code in spark, SparkContext in the driver program creates the job when an Action is called. This job is submitted to DAG Scheduler which creates the operator graph and then submits it to task Scheduler. Task Scheduler launches the task via cluster manager. Thus, with the help of cluster manager, a Spark Application is launched on a set of machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internals of How Apache Spark works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark is an open source, general-purpose distributed computing engine used for processing and analyzing a large amount of data. Just like Hadoop MapReduce, it also works with the system to distribute data across the cluster and process the data in parallel. Spark uses master/slave architecture i.e. one central coordinator and many distributed workers. Here, the central coordinator is called the driver.\n",
    "\n",
    "The driver runs in its own Java process. These drivers communicate with a potentially large number of distributed workers called executors. Each executor is a separate java process. A Spark Application is a combination of driver and its own executors. With the help of cluster manager, a Spark Application is launched on a set of machines. Standalone Cluster Manager is the default built in cluster manager of Spark. Apart from its built-in cluster manager, Spark also works with some open source cluster manager like Hadoop Yarn, Apache Mesos etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Apache Spark Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Shell is a Spark Application written in Scala. It offers command line environment with auto-completion. It helps us to get familiar with the features of Spark, which help in developing our own Standalone Spark Application. Thus, this tool helps in exploring Spark and is also the reason why Spark is so helpful in processing data set of all size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Spark Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spark application is a self-contained computation that runs user-supplied code to compute a result. A Spark application can have processes running on its behalf even when it’s not running a job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A task is a unit of work that is sent to the executor. Each stage has some task, one task per partition. The Same task is done over different partitions of RDD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job is parallel computation consisting of multiple tasks that get spawned in response to actions in Apache Spark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each job gets divided into smaller sets of tasks called stages that depend on each other. Stages are classified as computational boundaries. All computation cannot be done in single stage. It is achieved over many stages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Components of Spark Run-time Architecture of Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apache Spark Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main() method of the program runs in the driver. The driver is the process that runs the user code that creates RDDs, and performs transformation and action, and also creates SparkContext. When the Spark Shell is launched, this signifies that we have created a driver program. On the termination of the driver, the application is finished.\n",
    "\n",
    "The driver program splits the Spark application into the task and schedules them to run on the executor. The task scheduler resides in the driver and distributes task among workers. The two main key roles of drivers are:\n",
    "\n",
    "Converting user program into the task.\n",
    "Scheduling task on the executor.\n",
    "The structure of Spark program at a higher level is: RDDs are created from some input data, derive new RDD from existing using various transformations, and then after it performs an action to compute data. In Spark Program, the DAG (directed acyclic graph) of operations are created implicitly. And when the driver runs, it converts that Spark DAG into a physical execution plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Apache Spark Cluster Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark relies on cluster manager to launch executors and in some cases, even the drivers are launched through it. It is a pluggable component in Spark. On the cluster manager, jobs and action within a spark application are scheduled by Spark Scheduler in a FIFO fashion. Alternatively, the scheduling can also be done in Round Robin fashion. The resources used by a Spark application can be dynamically adjusted based on the workload. Thus, the application can free unused resources and request them again when there is a demand. This is available on all coarse-grained cluster managers, i.e. standalone mode, YARN mode, and Mesos coarse-grained mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark Executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual task in the given Spark job runs in the Spark executors. Executors are launched once in the beginning of Spark Application and then they run for the entire lifetime of an application. Even if the Spark executor fails, the Spark application can continue with ease. There are two main roles of the executors:\n",
    "\n",
    "Runs the task that makes up the application and returns the result to the driver.\n",
    "Provide in-memory storage for RDDs that are cached by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to launch a Program in Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Despite using any cluster manager, Spark comes with the facility of a single script that can be used to submit a program, called as spark-submit. It launches the application on the cluster. There are various options through which spark-submit can connect to different cluster manager and control how many resources our application gets. For some cluster managers, spark-submit can run the driver within the cluster (e.g., on a YARN worker node), while for others, it can run only on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to Run Apache Spark Application on a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spark-submit, the user submits an application.\n",
    "\n",
    "In spark-submit, the main() method specified by the user is invoked. It also launches the driver program.\n",
    "\n",
    "The driver program asks for the resources to the cluster manager that is required to launch executors.\n",
    "\n",
    "The cluster manager launches executors on behalf of the driver program.\n",
    "\n",
    "The driver process runs with the help of user application. Based on the actions and transformation on RDDs, the driver sends work to executors in the form of tasks.\n",
    "\n",
    "The executors process the task and the result is sent back to the driver through cluster manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directed Acyclic Graph DAG in Apache Spark 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Directed Acyclic Graph) DAG in Apache Spark is a set of Vertices and Edges, where vertices represent the RDDs and the edges represent the Operation to be applied on RDD. In Spark DAG, every edge is directed from earlier to later in the sequence. On calling of Action, the created DAG is submitted to DAG Scheduler which further splits the graph into the stages of the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is DAG in Apache Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAG is a finite directed graph with no directed cycles. There are finitely many vertices and edges, where each edge directed from one vertex to another. It contains a sequence of vertices such that every edge is directed from earlier to later in the sequence. It is a strict generalization of MapReduce model. DAG operations can do better global optimization than other systems like MapReduce. The picture of DAG becomes clear in more complex jobs.\n",
    "\n",
    "Apache Spark DAG allows the user to dive into the stage and expand on detail on any stage. In the stage view, the details of all RDDs belonging to that stage are expanded. The Scheduler splits the Spark RDD into stages based on various transformation applied. (You can refer this link to learn RDD Transformations and Actions in detail) Each stage is comprised of tasks, based on the partitions of the RDD, which will perform same computation in parallel. The graph here refers to navigation, and directed and acyclic refers to how it is done.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Need of Directed Acyclic Graph in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitations of Hadoop MapReduce became a key point to introduce DAG in Spark. The computation through MapReduce is carried in three steps:\n",
    "\n",
    "The data is read from HDFS.\n",
    "\n",
    "Map and Reduce operations are applied.\n",
    "\n",
    "The computed result is written back to HDFS.\n",
    "\n",
    "Each MapReduce operation is independent of each other and HADOOP has no idea of which Map reduce would come next. Sometimes for some iteration, it is irrelevant to read and write back the immediate result between two map-reduce jobs. In such case, the memory in stable storage (HDFS) or disk memory gets wasted.\n",
    "\n",
    "In multiple-step, till the completion of the previous job all the jobs are blocked from the beginning. As a result, complex computation can require a long time with small data volume.\n",
    "\n",
    "While in Spark, a DAG (Directed Acyclic Graph) of consecutive computation stages is formed. In this way, the execution plan is optimized, e.g. to minimize shuffling data around. In contrast, it is done manually in MapReduce by tuning each MapReduce step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How DAG works in Spark?\n",
    "\n",
    "https://stackoverflow.com/questions/25836316/how-dag-works-under-the-covers-in-rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpreter is the first layer, using a Scala interpreter, Spark interprets the code with some modifications.\n",
    "\n",
    "Spark creates an operator graph when you enter your code in Spark console.\n",
    "\n",
    "When an Action is called on Spark RDD at a high level, Spark submits the operator graph to the DAG Scheduler.\n",
    "\n",
    "Operators are divided into stages of the task in the DAG Scheduler. A stage contains task based on the partition of the input data. The DAG scheduler pipelines operators together. For example, map operators are scheduled in a single stage.\n",
    "\n",
    "The stages are passed on to the Task Scheduler. It launches task through cluster manager. The dependencies of stages are unknown to the task scheduler.\n",
    "\n",
    "The Workers execute the task on the slave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At higher level, two type of RDD transformations can be applied: narrow transformation (e.g. map(), filter() etc.) and wide transformation (e.g. reduceByKey()). Narrow transformation does not require the shuffling of data across a partition, the narrow transformations will be grouped into single stage while in wide transformation the data is shuffled. Hence, Wide transformation results in stage boundaries. Each RDD maintains a pointer to one or more parent along with metadata about what type of relationship it has with the parent. For example, if we call val b=a.map() on an RDD, the RDD b keeps a reference to its parent RDD a, that’s an RDD lineage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How is Fault tolerance achieved through DAG?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD is split into the partition and each node is operating on a partition at any point in time. Here, the series of Scala function is executing on a partition of the RDD. These operations are composed together and Spark execution engine view these as DAG (Directed Acyclic Graph).\n",
    "\n",
    "When any node crashes in the middle of any operation say O3 which depends on operation O2, which in turn O1. The cluster manager finds out the node is dead and assign another node to continue processing. This node will operate on the particular partition of the RDD and the series of operation that it has to execute (O1->O2->O3).  Now there will be no data loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Variables\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, when a function passed to a Spark operation (such as map or reduce) is executed on a remote cluster node, it works on separate copies of all the variables used in the function. These variables are copied to each machine, and no updates to the variables on the remote machine are propagated back to the driver program. Supporting general, read-write shared variables across tasks would be inefficient. However, Spark does provide two limited types of shared variables for two common usage patterns: broadcast variables and accumulators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcast Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcast variables allow the programmer to keep a read-only variable cached on each machine rather than shipping a copy of it with tasks. They can be used, for example, to give every node a copy of a large input dataset in an efficient manner. Spark also attempts to distribute broadcast variables using efficient broadcast algorithms to reduce communication cost.\n",
    "\n",
    "Spark actions are executed through a set of stages, separated by distributed “shuffle” operations. Spark automatically broadcasts the common data needed by tasks within each stage. The data broadcasted this way is cached in serialized form and deserialized before running each task. This means that explicitly creating broadcast variables is only useful when tasks across multiple stages need the same data or when caching the data in deserialized form is important.\n",
    "\n",
    "Broadcast variables are created from a variable v by calling SparkContext.broadcast(v). The broadcast variable is a wrapper around v, and its value can be accessed by calling the value metho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/routes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/icpl12900/Desktop/assignments/routes.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-163a00766ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "route=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "route.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take top 10 rows from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "route.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take count of no of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take first row from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#route.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take all rows from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all this upper operation request data from RDD and all are called ACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method which is use to read file as textFile is call \"TRANSFORMATION\"\n",
    "\n",
    "Operations that create RDD and Convert one RDD into another RDD call \"TRANSFORMATION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Difference between transformations and RDD is:\n",
    "1. Transformation is not execute immediately. they execute only actions are call on them\n",
    "\n",
    "** textFile only take file from path and create RDD for it. It not read or do any operation on it. this job is done by actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_for_filter=\"file:///home/icpl12900/Desktop/data_files/prat.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-617a60d85cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_for_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_for_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "data_for_filter=sc.textFile(file_for_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_for_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4879501abcbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_for_filter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_for_filter' is not defined"
     ]
    }
   ],
   "source": [
    "data_for_filter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataofhead=data_for_filter.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_without_head=data_for_filter.filter(lambda x : x <> dataofhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_without_head.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using map we can convert unstructre string into structure string with name of filds with we can access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_string=data_without_head.map(lambda x:x.split(\",\")[1])\n",
    "#if we give [1] then it fetch 2 column from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list_string=data_without_head.map(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it take whole record and split it into individual string i.e list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_string.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_string.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields=dataofhead.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to print list use only name of list i.e fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',fields,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any object of class have fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row) #this function return object of class_for_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data_without_head.map(parse) #nametuple is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.first() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.first().id #access filed using name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out missing value and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/routes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "route=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = route.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_missing = route.filter(lambda x : x <> header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_missing.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_fields = header.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',header_fields,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_name=data_missing.map(parse) #nametuple is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.map(lambda x : x.Codeshare).countByValue()  #contain null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.map(lambda x : x.Equipment).countByValue() #''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter = data_name.filter(lambda x : not (x.Codeshare == '' or x.Equipment == '')) #take all data from data_name and apply function only on codeshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter.map(lambda x : x.Codeshare).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=data_filter.map(lambda x : x.Source_airport_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.reduce(lambda x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter.map(lambda x : x.Airline).countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/air.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_header = airpot.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot_data = airpot.filter(lambda x :x <> airpot_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot_header_fields = airpot_header.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_header_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',airpot_header_fields,verbose=True) #verbose=True it use for give more output related to class u create in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='/home/icpl12900/Desktop/example1.log',level=logging.DEBUG)\n",
    "logging.debug('This message should go to the log file')\n",
    "logging.info('So should this')\n",
    "logging.warning('And this, too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    try:\n",
    "        reader = csv.reader(StringIO(row))\n",
    "        row=reader.next()\n",
    "        print(\"{} {}\".format(\"My Data\",row.get(1)))\n",
    "        return class_for_nametuple(*row)\n",
    "    except:\n",
    "        return class_for_nametuple(Airport_ID='24', Name='St Anthony', City='St. Anthony', Country='Canada', IATA_FAA='YAY', ICAO='CYAY', Location=\"51.391944,-56.083056\", Altitude='108', Timezone='-3.5', DST='A', Tz='America/St_Johns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name=airpot_data.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processRecord(record):\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data.foreach(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name.map(lambda x: x.Location).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractCoords(location):\n",
    "    loc_lat = float(location[1:location.index(\",\")])\n",
    "    loc_lan = float(location[location.index(\",\")+1:-1])\n",
    "    return(loc_lat,loc_lan)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location)).reduce(lambda x,y:(min(x[0],y[0]),(min(x[1],y[1]))))\n",
    "\n",
    "#x,y means two rows\n",
    "#it find long and minimum latitude\n",
    "#lambda x, y means two arguuments pass to function\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name.filter(lambda x:x.DST == 'N').map(lambda x:x.Tz).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to work on it\n",
    "\n",
    "import gmplot\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(37.428, -122.145, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAIR RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file1=\"file:///home/icpl12900/Desktop/Pair_rdd/Dodgers.data\"\n",
    "file2=\"file:///home/icpl12900/Desktop/Pair_rdd/Dodgers.events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traffic=sc.textFile(file1)\n",
    "traffic.take(10) #time after 5 min , no of car within that 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game=sc.textFile(file2)\n",
    "game.take(10)  #startTime , endTime, audience,opponent,win/loss along with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def parsetraffic(row):\n",
    "    date_format = \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_format)\n",
    "    row[1]=int(row[1])\n",
    "    return(row[0],row[1]) #here we create tuple from record and i.e we create pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trafficparse = traffic.map(parsetraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trafficparse.take(10) #timestamp = key and no. of cars = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. reduceByKey : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "same as reduce operation and use for combine record who have same key\n",
    "\n",
    "it need function with two arguments\n",
    "\n",
    "it is transformation\n",
    "\n",
    "it return RDD and we have to do operation on it\n",
    "\n",
    "\n",
    "syntax: lambda(x,y:x+y)    it take 2 value of same key and combine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailytrend = trafficparse.map(lambda x : (x[0].date(),x[1]))\\\n",
    "                        .reduceByKey(lambda x,y :x+y)\n",
    "    \n",
    "    \n",
    "    #we create RDD where key = date and Value = sum of cars\n",
    "    #we convert timestamp into date and take 2nd argument as it is and apply reduceByKey function to sum no of cars of same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailytrend.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_dailytrend = dailytrend.sortBy(lambda x: -x[1]) \n",
    "\n",
    "#sort operation to sort record and -x[1]   means sort by value i.e x[1] and -x[1] means sort by descinding order\n",
    "#if we use x[1] only then sort by ascending order\n",
    "#sortBy is built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_dailytrend.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Merge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark allow you to merge two pair RDD based on keys . and if they have different value then it make list of that differnt value of same key and this operation is called \"JOIN\"\n",
    "\n",
    "three diff join:\n",
    "\n",
    "1.join == inner join\n",
    "\n",
    "2.leftOuterJoin == same as sql\n",
    "\n",
    "3.rightOuterJoin == same as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def parsegame(row):\n",
    "    date_format = \"%m/%d/%y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_format).date()\n",
    "    return(row[0],row[4])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameparse = game.map(parsegame)  #create pair RDD of Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameparse.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailyTrendCombined = dailytrend.leftOuterJoin(gameparse)\n",
    "#create new RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailyTrendCombined.take(10)\n",
    "#here we join two RDD using date =key and make list of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkGameDay(row):\n",
    "    if row[1][1] == None:\n",
    "        return (row[0],row[1][1],\"Regular Day\",row[1][0])\n",
    "    else:\n",
    "         return (row[0],row[1][1],\"Game Day\",row[1][0])\n",
    "\n",
    "#create function to convert tuple into 4 values:\n",
    "    #date,opponent,type of day and #car\n",
    "    \n",
    "#here row[1][1] means row from leftOuterJoin 2 value from Value elment bcoz index start with 0 so key =0 index and value=1st index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailytrendgame = dailyTrendCombined.map(checkGameDay)\n",
    "#apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailytrendgame.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dailytrendgame.sortBy(lambda x : -x[3]).take(10) #apply descending sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. CombineByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use for combine record of same key within RDD\n",
    "\n",
    "use for finding \"AVERAGE of value\"\n",
    "\n",
    "if we want to calculate average by using \"reduceByKey\" then it give wrong result bcoz reduceByKey 1st apply on 1st two rows then result and 3rd row. so it give wrong result\n",
    "\n",
    "so for right result use following:\n",
    "\n",
    "1.sum per group\n",
    "\n",
    "2.count per group\n",
    "\n",
    "3.join\n",
    "\n",
    "4.divide sum/count\n",
    "\n",
    "using combineByKey we complete 1st three steps in 1 step:\n",
    "\n",
    "    combineByKey required 3 function  to compute sum and count at same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailytrendgame.map(lambda x : (x[2],x[3]))\\  #here 1st create pair RDD where key=regular day or game day and value=traffic\n",
    "               .combineByKey(lambda value : (value,1),\\\n",
    "                             (lambda acc,value : (acc[0] + value, acc[1] + 1)),\\\n",
    "                             (lambda acc1,acc2 : (acc1[0]+acc2[0],acc1[1]+acc2[1])))\\\n",
    "                .mapValues(lambda x : x[0]/x[1])\\ #here we take ratio of sum and count\n",
    "                .collect()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling Relationships in the Marvel Social Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookpath = \"file:///home/icpl12900/Desktop/marvel/Books.txt\"\n",
    "charpath = \"file:///home/icpl12900/Desktop/marvel/Characters.txt\"\n",
    "edgepath = \"file:///home/icpl12900/Desktop/marvel/Edges.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = sc.textFile(bookpath)\n",
    "char =  sc.textFile(charpath)\n",
    "edge =  sc.textFile(edgepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book.take(2) #vertex name and book name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char.take(2) #vertex no or character id and char name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge.take(2) #1st contain all vertex that appear in book and char , and edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edgefilter(row):\n",
    "    if '*' in row or '\"' in row:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "edgefil = edge.filter(edgefilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edgefil.take(2)  #it contain only edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. For most influence char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charbookmap = edgefil.map(lambda x : x.split())\\\n",
    "                        .map(lambda x : (x[0],x[1:]))  #x[0] is char and x[1:] list book that contain char\n",
    "    #here we create pair RDD where key = character and value is list of book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charbookmap.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charPairRDD = char.map(lambda x : x.split(\":\"))\\\n",
    "                .map(lambda x : (x[0][7:] , x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charPairRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charDictionary = charPairRDD.collectAsMap() #collectAsMap is use with Pair RDD and take pair RDD and return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charDictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charStrength = charbookmap.mapValues(lambda x : len(x))\\\n",
    "                            .map(lambda x : (charDictionary[x[0]],x[1]))\\\n",
    "                            .reduceByKey(lambda x,y : x+y)\\\n",
    "                            .sortBy(lambda x : -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapValues is special operation use on pair rdd same as map opertion but only on value part of RDD\n",
    "#key remain as it is only apply map on value \n",
    "#1. charbookmap.mapValues(lambda x : len(x)) === here we computed length of book list in which char appear\n",
    "#2.  .map(lambda x : (charDictionary[x[0]],x[1])) == here we do mapping of vertex id to actual character name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charStrength.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Coorance Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # STEP 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. bookCharMap = charbookmap.flatMapValues(lambda x:x)\n",
    "\n",
    "#here we use flatMapVlues operation to take values from Pair RDD of \"charbookmap\" and make flat list of them \n",
    "\n",
    "#i.e individual items\n",
    "\n",
    "#flatMapValue take list of values and iterate through them and make single record for each item in it\n",
    "\n",
    "#keep key as it is and apply function onlly on values and make single record value for each item in list of values\n",
    "\n",
    " result :\n",
    " \n",
    "[(u'1', u'6487'),\n",
    "\n",
    " (u'2', u'6488'),\n",
    " \n",
    " (u'2', u'6489'),\n",
    " \n",
    " (u'2', u'6490'),\n",
    " \n",
    " (u'2', u'6491'),\n",
    " \n",
    " (u'2', u'6492'),\n",
    " \n",
    " (u'2', u'6493'),\n",
    " \n",
    " (u'2', u'6494'),\n",
    " \n",
    " (u'2', u'6495'),\n",
    " \n",
    " (u'2', u'6496')]\n",
    " \n",
    " 2.  bookCharMap = charbookmap.flatMapValues(lambda x:x)\n",
    "                              .map(lambda x: (x[1],x[0]))\n",
    " \n",
    " #reverse list i.e key = book and value = id\n",
    " \n",
    " result:\n",
    " \n",
    " \n",
    " [(u'6487', u'1'),\n",
    " \n",
    " (u'6488', u'2'),\n",
    " \n",
    " (u'6489', u'2'),\n",
    " \n",
    " (u'6490', u'2'),\n",
    " \n",
    " (u'6491', u'2'),\n",
    " \n",
    " (u'6492', u'2'),\n",
    " \n",
    " (u'6493', u'2'),\n",
    " \n",
    " (u'6494', u'2'),\n",
    " \n",
    " (u'6495', u'2'),\n",
    " \n",
    " (u'6496', u'2')]\n",
    " \n",
    "3. bookCharMap = charbookmap.flatMapValues(lambda x:x)\\\n",
    "                               .map(lambda x: (x[1],x[0]))\\\n",
    "                               .reduceByKey(lambda x ,y : x +\",\"+ y )\n",
    "  \n",
    "  #use reduceByKey to collect all character for each book into one string\n",
    "  \n",
    "  Result : \n",
    "      book , list of char for that book\n",
    "      \n",
    "  [(u'11542', u'545,1084,1319,4415'),\n",
    "  \n",
    " (u'11540', u'545,1084,1319,1347,1602,3750,3959,4415,5019'),\n",
    " \n",
    " (u'11546', u'550,1077,1602,3959,6316'),\n",
    " \n",
    " (u'11544',\n",
    "  u'548,612,748,865,1415,2043,2239,2397,2401,2545,2602,2661,5920,6312,6368'),\n",
    "  \n",
    " (u'11548', u'554,1869,2197,2360,2776,3072,3645,4613,5121,5662,5954,6399'),\n",
    " \n",
    " (u'19399', u'6372'),\n",
    " \n",
    " (u'19397', u'6351'),\n",
    " \n",
    " (u'19395', u'6351'),\n",
    " \n",
    " (u'19393', u'6316'),\n",
    " \n",
    " (u'19391', u'6313')]\n",
    " \n",
    " \n",
    " 4.bookCharMap = charbookmap.flatMapValues(lambda x:x)\\\n",
    " \n",
    "                               .map(lambda x: (x[1],x[0]))\\\n",
    "                               \n",
    "                               .reduceByKey(lambda x ,y : x +\",\"+ y )\\\n",
    "                               \n",
    "                                .mapValues(lambda x : x.split(\",\"))\n",
    "                                \n",
    "                                \n",
    "    # to split string into list\n",
    "    \n",
    "    result:\n",
    "    \n",
    "    [(u'11542', [u'545', u'1084', u'1319', u'4415']),\n",
    "    \n",
    "     (u'11540',[u'545',u'1084',u'1319', u'1347',u'1602', u'3750', u'3959', u'4415',u'5019'])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " bookCharMap = charbookmap.flatMapValues(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookCharMap.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookCharMap = charbookmap.flatMapValues(lambda x:x)\\\n",
    "                .map(lambda x: (x[1],x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookCharMap.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookCharMap = charbookmap.flatMapValues(lambda x:x)\\\n",
    "                               .map(lambda x: (x[1],x[0]))\\\n",
    "                               .reduceByKey(lambda x ,y : x +\",\"+ y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookCharMap.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookCharMap = charbookmap.flatMapValues(lambda x:x)\\\n",
    "                               .map(lambda x: (x[1],x[0]))\\\n",
    "                               .reduceByKey(lambda x ,y : x +\",\"+ y )\\\n",
    "                                .mapValues(lambda x : x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookCharMap.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #STEP 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each BOOK create complete list of all pair that appear together for ecah book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "cooccurenceMap = bookCharMap.flatMap(lambda x : list(itertools.combinations(x[1],2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we use python \"itertools\" module that take list of character and create pair from that list\n",
    "\n",
    "and then use flatMap to create one record pair from list of pair\n",
    "\n",
    "cooccurence is RDD which contain pair of character that appear together in book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cooccurenceMap.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # STEP 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to compute count for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coocurenceStrenght = cooccurenceMap.map(lambda x : (x,1))\\\n",
    "                                    .reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. coocurenceStrenght = cooccurenceMap.map(lambda x : (x,1))\n",
    "\n",
    "  #here we give count 1 to each pair in cooccurence and make Pair RDD \n",
    "  \n",
    "  \n",
    "2.  coocurenceStrenght = cooccurenceMap.map(lambda x : (x,1))\\\n",
    "                                    .reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "    #apply reduceByKey to calculate count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coocurenceStrenght.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have RDD where  keys == edges are connected by pair characters and values are count for how much time that pair appear in that one book i.e strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cooccurenceEdges = coocurenceStrenght.map(lambda x : (x[0][0], x[0][1], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we create basic RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cooccurenceEdges.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedCooccurence = cooccurenceEdges.sortBy(lambda x : -x[2]) #sort using strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortedCooccurence.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedCooccurence = cooccurenceEdges.sortBy(lambda x : -x[2])\\\n",
    "                                        .map(lambda x : (charDictionary[x[0]],charDictionary[x[1]],x[2]))\n",
    "    #do mapping from id to name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortedCooccurence.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortedCooccurence.filter(lambda x :u' SPIDER-MAN/PETER PARKER' in x).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortedCooccurence.map(lambda x : x[2]).stats()\n",
    "#it give sence of distrubution using numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "edges = sortedCooccurence.map(lambda x : (x[0], x[1], {'weight' : 1000/x[2]})).take(50)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# average no of friends by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/fakefriends.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "friend = sc.textFile(filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,Will,33,385',\n",
       " u'1,Jean-Luc,26,2',\n",
       " u'2,Hugh,55,221',\n",
       " u'3,Deanna,40,465',\n",
       " u'4,Quark,68,21',\n",
       " u'5,Weyoun,59,318',\n",
       " u'6,Gowron,37,220',\n",
       " u'7,Will,54,307',\n",
       " u'8,Jadzia,38,380',\n",
       " u'9,Hugh,27,181']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friend.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PairFriendRDD = friend.map(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 385),\n",
       " (26, 2),\n",
       " (55, 221),\n",
       " (40, 465),\n",
       " (68, 21),\n",
       " (59, 318),\n",
       " (37, 220),\n",
       " (54, 307),\n",
       " (38, 380),\n",
       " (27, 181)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PairFriendRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = PairFriendRDD.reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18, 2747),\n",
       " (20, 825),\n",
       " (22, 1445),\n",
       " (24, 1169),\n",
       " (26, 4115),\n",
       " (28, 2091),\n",
       " (30, 2594),\n",
       " (32, 2287),\n",
       " (34, 1473),\n",
       " (36, 2466)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averageAge = PairFriendRDD.mapValues(lambda x : (x,1)).reduceByKey(lambda x , y : ((x[0] + y[0]) , (x[1] + y[1]))).map(lambda x : (x[0] , (x[1][0] /x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averageAge.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = \"file:///home/icpl12900/Desktop/assignments/1800.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ITE00100554,18000101,TMAX,-75,,,E,',\n",
       " u'ITE00100554,18000101,TMIN,-148,,,E,',\n",
       " u'GM000010962,18000101,PRCP,0,,,E,',\n",
       " u'EZE00100082,18000101,TMAX,-86,,,E,',\n",
       " u'EZE00100082,18000101,TMIN,-135,,,E,',\n",
       " u'ITE00100554,18000102,TMAX,-60,,I,E,',\n",
       " u'ITE00100554,18000102,TMIN,-125,,,E,',\n",
       " u'GM000010962,18000102,PRCP,0,,,E,',\n",
       " u'EZE00100082,18000102,TMAX,-44,,,E,',\n",
       " u'EZE00100082,18000102,TMIN,-130,,,E,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseData(row) :\n",
    "    row = row.split(',')\n",
    "    row[0] = row[0]\n",
    "    row[1] = row[2]\n",
    "    row[2] = row[3]\n",
    "    return (row[0],row[1],row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempData = temp.map(parseData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ITE00100554', u'TMAX', u'-75'),\n",
       " (u'ITE00100554', u'TMIN', u'-148'),\n",
       " (u'GM000010962', u'PRCP', u'0'),\n",
       " (u'EZE00100082', u'TMAX', u'-86'),\n",
       " (u'EZE00100082', u'TMIN', u'-135'),\n",
       " (u'ITE00100554', u'TMAX', u'-60'),\n",
       " (u'ITE00100554', u'TMIN', u'-125'),\n",
       " (u'GM000010962', u'PRCP', u'0'),\n",
       " (u'EZE00100082', u'TMAX', u'-44'),\n",
       " (u'EZE00100082', u'TMIN', u'-130')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempFilterData = tempData.filter(lambda x : u'TMIN' in x[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ITE00100554', u'TMIN', u'-148'),\n",
       " (u'EZE00100082', u'TMIN', u'-135'),\n",
       " (u'ITE00100554', u'TMIN', u'-125'),\n",
       " (u'EZE00100082', u'TMIN', u'-130'),\n",
       " (u'ITE00100554', u'TMIN', u'-46'),\n",
       " (u'EZE00100082', u'TMIN', u'-73'),\n",
       " (u'ITE00100554', u'TMIN', u'-13'),\n",
       " (u'EZE00100082', u'TMIN', u'-74'),\n",
       " (u'ITE00100554', u'TMIN', u'-6'),\n",
       " (u'EZE00100082', u'TMIN', u'-58')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempFilterData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-23b5639823b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtempFilterData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempMinData = tempFilterData.map(lambda x : (x[0], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ITE00100554', u'-148'),\n",
       " (u'EZE00100082', u'-135'),\n",
       " (u'ITE00100554', u'-125'),\n",
       " (u'EZE00100082', u'-130'),\n",
       " (u'ITE00100554', u'-46'),\n",
       " (u'EZE00100082', u'-73'),\n",
       " (u'ITE00100554', u'-13'),\n",
       " (u'EZE00100082', u'-74'),\n",
       " (u'ITE00100554', u'-6'),\n",
       " (u'EZE00100082', u'-58')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempMinData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempMinFilterData = tempMinData.reduceByKey(lambda x,y: (min(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'ITE00100554', u'-10'), (u'EZE00100082', u'-102')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempMinFilterData.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath =\"file:///home/icpl12900/Desktop/assignments/Book.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Self-Employment: Building an Internet Business of One',\n",
       " u'Achieving Financial and Personal Freedom through a Lifestyle Technology Business',\n",
       " u'By Frank Kane',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'Copyright \\ufffd 2015 Frank Kane. ',\n",
       " u'All rights reserved worldwide.',\n",
       " u'',\n",
       " u'']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    row = row.split()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = data.flatMap(lambda x: x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCount = words.countByValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {u'addictive': 1,\n",
       "             u'considered.': 1,\n",
       "             u'better!': 1,\n",
       "             u'similarity': 1,\n",
       "             u'better,': 3,\n",
       "             u'better.': 4,\n",
       "             u'prices': 2,\n",
       "             u'considered?': 1,\n",
       "             u'Does': 2,\n",
       "             u'ocean,': 1,\n",
       "             u'Dartmouth,': 1,\n",
       "             u'hanging': 1,\n",
       "             u'B2B': 1,\n",
       "             u'payoff': 2,\n",
       "             u'up.': 10,\n",
       "             u'looking': 9,\n",
       "             u'entirely\\ufffd': 1,\n",
       "             u'LAST': 1,\n",
       "             u'disability': 2,\n",
       "             u'up?': 1,\n",
       "             u'Revenue': 2,\n",
       "             u'fares?': 1,\n",
       "             u'Identifying': 1,\n",
       "             u'Discarding': 1,\n",
       "             u'Lean': 4,\n",
       "             u'oceans': 1,\n",
       "             u'advice.': 1,\n",
       "             u'advice,': 7,\n",
       "             u'extensions\"': 1,\n",
       "             u'ever-improving': 1,\n",
       "             u'updates': 2,\n",
       "             u'affect': 9,\n",
       "             u'today,': 1,\n",
       "             u'writing,': 1,\n",
       "             u'vast': 2,\n",
       "             u'basics': 2,\n",
       "             u'job),': 1,\n",
       "             u'skills': 10,\n",
       "             u'Harmony,': 1,\n",
       "             u'companies': 27,\n",
       "             u'unrelated': 1,\n",
       "             u'TELLING': 1,\n",
       "             u'path': 15,\n",
       "             u'amount.': 1,\n",
       "             u'AdSense,': 1,\n",
       "             u'non-compete': 2,\n",
       "             u'front.': 1,\n",
       "             u'Conventional': 1,\n",
       "             u'force': 1,\n",
       "             u'INVESTING': 1,\n",
       "             u'me,': 3,\n",
       "             u'me.': 5,\n",
       "             u'27,': 1,\n",
       "             u'batch': 1,\n",
       "             u'second': 3,\n",
       "             u'believing': 1,\n",
       "             u'Ageism': 1,\n",
       "             u'even': 68,\n",
       "             u'sales?': 1,\n",
       "             u'Kane,': 2,\n",
       "             u'Kane.': 1,\n",
       "             u'doesn\\ufffdt': 6,\n",
       "             u'hate': 3,\n",
       "             u'Hawaii': 1,\n",
       "             u'Rafi.': 1,\n",
       "             u'(\\ufffdObamacare\\ufffd,)': 1,\n",
       "             u'sales.': 6,\n",
       "             u'sales,': 9,\n",
       "             u'high-dollar': 1,\n",
       "             u'attractive': 1,\n",
       "             u'designing': 2,\n",
       "             u'new': 143,\n",
       "             u'tips': 2,\n",
       "             u'\"moderately': 1,\n",
       "             u'ever': 9,\n",
       "             u'evolving': 1,\n",
       "             u'something?': 1,\n",
       "             u'Tech\",': 1,\n",
       "             u'resignation,': 1,\n",
       "             u'courses,': 1,\n",
       "             u'resignation.': 1,\n",
       "             u'Measure': 1,\n",
       "             u'disposable': 1,\n",
       "             u'up,': 4,\n",
       "             u'here': 11,\n",
       "             u'challenge.': 1,\n",
       "             u'met': 5,\n",
       "             u'Rumsey,': 1,\n",
       "             u'affiliated': 1,\n",
       "             u'100': 1,\n",
       "             u\"aren't\": 17,\n",
       "             u'Insider11.': 1,\n",
       "             u'DirectX': 1,\n",
       "             u'reasons:': 1,\n",
       "             u'dry': 1,\n",
       "             u'kids': 5,\n",
       "             u'release;': 1,\n",
       "             u'covers': 2,\n",
       "             u'millions-of-dollars-per-year': 1,\n",
       "             u'reports': 2,\n",
       "             u'credit': 7,\n",
       "             u'harass': 1,\n",
       "             u'Startup\\ufffd': 1,\n",
       "             u'Choosing': 1,\n",
       "             u'crises': 1,\n",
       "             u'NOT': 2,\n",
       "             u'military': 2,\n",
       "             u\"someone's\": 1,\n",
       "             u'menial': 1,\n",
       "             u'astute': 1,\n",
       "             u'rebel': 1,\n",
       "             u'criticism': 1,\n",
       "             u'trademarks': 1,\n",
       "             u'campaign': 17,\n",
       "             u'slices': 1,\n",
       "             u'bust,': 1,\n",
       "             u'Three': 2,\n",
       "             u'Relations': 1,\n",
       "             u'replace': 4,\n",
       "             u'brought': 1,\n",
       "             u'Also': 3,\n",
       "             u'remnant': 1,\n",
       "             u'website,': 13,\n",
       "             u'anywhere.': 1,\n",
       "             u'stern': 1,\n",
       "             u'\"The': 4,\n",
       "             u'Security': 2,\n",
       "             u'landscape': 1,\n",
       "             u'municipality,': 1,\n",
       "             u'cheating': 1,\n",
       "             u'revenue,': 2,\n",
       "             u'concept!': 1,\n",
       "             u'revenue.': 4,\n",
       "             u'catchy': 1,\n",
       "             u'revenue!': 1,\n",
       "             u'right?': 1,\n",
       "             u'arms': 2,\n",
       "             u'call': 8,\n",
       "             u'therefore': 2,\n",
       "             u'use.': 4,\n",
       "             u'strike': 1,\n",
       "             u'survive': 2,\n",
       "             u'right.': 2,\n",
       "             u'type': 3,\n",
       "             u'until': 15,\n",
       "             u'show,': 2,\n",
       "             u'paperwork': 2,\n",
       "             u'posting': 2,\n",
       "             u'relax': 2,\n",
       "             u'successful': 14,\n",
       "             u'brings': 3,\n",
       "             u'tenacity': 1,\n",
       "             u'specific,': 1,\n",
       "             u'Misleading': 1,\n",
       "             u'warm': 1,\n",
       "             u'tying': 1,\n",
       "             u'hold': 1,\n",
       "             u'extorting': 1,\n",
       "             u'circumstances': 1,\n",
       "             u'pivoting': 1,\n",
       "             u'room': 1,\n",
       "             u'demos': 1,\n",
       "             u'pursue': 1,\n",
       "             u'liability,': 1,\n",
       "             u'roof': 1,\n",
       "             u'incubator': 3,\n",
       "             u'placements.': 1,\n",
       "             u'marketer,': 1,\n",
       "             u'placements,': 1,\n",
       "             u'example': 3,\n",
       "             u'however?': 1,\n",
       "             u'minimize.': 1,\n",
       "             u'household': 1,\n",
       "             u'Reality': 1,\n",
       "             u'involve': 4,\n",
       "             u'caution': 2,\n",
       "             u'reviewing': 1,\n",
       "             u'want': 99,\n",
       "             u'minimum,': 4,\n",
       "             u'otherwise,': 1,\n",
       "             u'minimum.': 3,\n",
       "             u'honest': 2,\n",
       "             u'statistics,': 1,\n",
       "             u'mistake\\ufffd': 1,\n",
       "             u'DPI': 1,\n",
       "             u'around.': 1,\n",
       "             u'around,': 3,\n",
       "             u'\"Silver': 1,\n",
       "             u'Watching': 1,\n",
       "             u'travel': 4,\n",
       "             u'feature': 2,\n",
       "             u'revisit': 2,\n",
       "             u'machine': 1,\n",
       "             u'how': 127,\n",
       "             u'hot': 1,\n",
       "             u'win.': 1,\n",
       "             u'answer': 6,\n",
       "             u'place': 12,\n",
       "             u'A': 39,\n",
       "             u'gaming': 3,\n",
       "             u'beauty': 3,\n",
       "             u'3%?': 1,\n",
       "             u'typed': 2,\n",
       "             u'loyalty': 2,\n",
       "             u'wrong': 9,\n",
       "             u'chump': 1,\n",
       "             u'\\ufffdwhat': 1,\n",
       "             u'types': 1,\n",
       "             u'(SEO)': 1,\n",
       "             u'purchase': 10,\n",
       "             u'All': 13,\n",
       "             u'attempt': 1,\n",
       "             u'effective': 7,\n",
       "             u'68%': 1,\n",
       "             u'attracts': 1,\n",
       "             u'UNLIMITED': 1,\n",
       "             u'SALES': 2,\n",
       "             u'Earning': 1,\n",
       "             u'maintain': 9,\n",
       "             u'Another': 2,\n",
       "             u'keeps': 4,\n",
       "             u'every': 28,\n",
       "             u'belong': 2,\n",
       "             u'LIFESTYLE': 4,\n",
       "             u'feedback': 5,\n",
       "             u'school,': 1,\n",
       "             u'effect.': 1,\n",
       "             u'vary': 5,\n",
       "             u'down,': 1,\n",
       "             u\"today's\": 1,\n",
       "             u'today.': 2,\n",
       "             u'responsive': 1,\n",
       "             u'rewarded': 1,\n",
       "             u'Rich.': 1,\n",
       "             u'welcomes': 1,\n",
       "             u'Estimating': 1,\n",
       "             u'(be': 1,\n",
       "             u'then.': 1,\n",
       "             u'fit': 3,\n",
       "             u'IT\\ufffdS': 1,\n",
       "             u'personal': 43,\n",
       "             u'rankings': 2,\n",
       "             u'fix': 2,\n",
       "             u'revenue': 33,\n",
       "             u'niche?': 1,\n",
       "             u'represent?': 1,\n",
       "             u'better': 40,\n",
       "             u'print-quality': 1,\n",
       "             u'differently': 1,\n",
       "             u'salesforce.com,': 1,\n",
       "             u'TRACKING': 1,\n",
       "             u'weeks': 1,\n",
       "             u'easier': 8,\n",
       "             u'overcome': 2,\n",
       "             u'niche,': 3,\n",
       "             u'PR,': 3,\n",
       "             u'strings,': 1,\n",
       "             u'school': 2,\n",
       "             u'10%': 6,\n",
       "             u'inclined,': 1,\n",
       "             u'effects': 1,\n",
       "             u'devices.': 2,\n",
       "             u'represents': 1,\n",
       "             u'eight-hour': 1,\n",
       "             u'week,': 3,\n",
       "             u'they\\ufffdve': 1,\n",
       "             u'DECISION': 1,\n",
       "             u'Planning': 3,\n",
       "             u'component': 1,\n",
       "             u'STICK': 1,\n",
       "             u\"doctor's\": 1,\n",
       "             u'mature.': 1,\n",
       "             u'went': 5,\n",
       "             u'higher': 8,\n",
       "             u'restaurants,': 1,\n",
       "             u'side': 24,\n",
       "             u'luck': 1,\n",
       "             u'powerlessness': 1,\n",
       "             u'Radically': 1,\n",
       "             u'problems.': 1,\n",
       "             u'financial': 12,\n",
       "             u'Insert': 1,\n",
       "             u'series': 1,\n",
       "             u'ideas?': 1,\n",
       "             u'contracting': 3,\n",
       "             u'taught': 3,\n",
       "             u'legwork': 1,\n",
       "             u'substantially': 1,\n",
       "             u'temporary': 2,\n",
       "             u'replacement?': 1,\n",
       "             u'message': 6,\n",
       "             u'CPA\\ufffds': 1,\n",
       "             u'is:': 1,\n",
       "             u'release.': 3,\n",
       "             u'message;': 1,\n",
       "             u'DEVELOPING': 1,\n",
       "             u'at.': 3,\n",
       "             u'quantify': 1,\n",
       "             u'at,': 2,\n",
       "             u'crucial': 5,\n",
       "             u'government-funded': 2,\n",
       "             u'content': 14,\n",
       "             u'encourage': 3,\n",
       "             u'message,': 1,\n",
       "             u'start.': 4,\n",
       "             u'adapt': 2,\n",
       "             u'reader': 1,\n",
       "             u'at?': 1,\n",
       "             u'size': 9,\n",
       "             u'available.': 2,\n",
       "             u'separately.': 1,\n",
       "             u'Join': 1,\n",
       "             u'linear': 1,\n",
       "             u'University': 3,\n",
       "             u'Work': 4,\n",
       "             u'given': 9,\n",
       "             u'Ego': 1,\n",
       "             u'estimate': 13,\n",
       "             u'substantiation': 1,\n",
       "             u'cornerstone': 1,\n",
       "             u'competes': 1,\n",
       "             u'Furthermore,': 1,\n",
       "             u'groups.': 2,\n",
       "             u'starts': 4,\n",
       "             u'Separate': 1,\n",
       "             u'shutdown?': 1,\n",
       "             u'smartphone\\ufffd': 1,\n",
       "             u'heading': 1,\n",
       "             u'freelancer.': 1,\n",
       "             u'tempting': 3,\n",
       "             u'York,': 1,\n",
       "             u'gamble.': 2,\n",
       "             u'capitalist\\ufffd': 1,\n",
       "             u'gamble,': 1,\n",
       "             u'features': 3,\n",
       "             u'channels': 7,\n",
       "             u'spinning': 1,\n",
       "             u'risk-aversion,': 1,\n",
       "             u'likes,': 1,\n",
       "             u'clarity': 2,\n",
       "             u'reward.': 1,\n",
       "             u'Website': 2,\n",
       "             u'severance': 1,\n",
       "             u'you\\ufffdd': 4,\n",
       "             u'service': 7,\n",
       "             u'\"URL': 1,\n",
       "             u'engagement': 1,\n",
       "             u'Effect': 1,\n",
       "             u'Liability': 2,\n",
       "             u'needed': 7,\n",
       "             u'coverage!': 1,\n",
       "             u'existed.': 1,\n",
       "             u'worlds': 1,\n",
       "             u'Press': 2,\n",
       "             u'approach.': 1,\n",
       "             u'easy.': 1,\n",
       "             u'easy,': 4,\n",
       "             u'Adapting': 1,\n",
       "             u'self-motivated': 1,\n",
       "             u'rewards': 7,\n",
       "             u'channel.': 1,\n",
       "             u'wisdom': 2,\n",
       "             u'Summit': 1,\n",
       "             u'was.': 1,\n",
       "             u'(Census': 1,\n",
       "             u'Channels:': 1,\n",
       "             u'distance': 1,\n",
       "             u'outlay': 2,\n",
       "             u'Consider': 5,\n",
       "             u'showed': 4,\n",
       "             u'livelihood,': 1,\n",
       "             u'zero.': 2,\n",
       "             u'older': 1,\n",
       "             u'likely': 26,\n",
       "             u'project': 4,\n",
       "             u'matter': 10,\n",
       "             u'silly': 1,\n",
       "             u'friend': 2,\n",
       "             u'feeling': 1,\n",
       "             u'old,': 1,\n",
       "             u'acquisition': 1,\n",
       "             u'well?': 1,\n",
       "             u'sees': 1,\n",
       "             u'emailing,': 1,\n",
       "             u'willingness': 1,\n",
       "             u'modern': 1,\n",
       "             u'Generally': 2,\n",
       "             u'mine': 2,\n",
       "             u'well,': 11,\n",
       "             u'well.': 20,\n",
       "             u'Designing': 1,\n",
       "             u'transaction,': 1,\n",
       "             u'(FEIN)': 1,\n",
       "             u'transaction.': 1,\n",
       "             u'seek': 5,\n",
       "             u'Acknowledgments': 1,\n",
       "             u'sound,': 1,\n",
       "             u'tools,': 1,\n",
       "             u'data.': 3,\n",
       "             u'do.': 15,\n",
       "             u'releases': 12,\n",
       "             u'do,': 12,\n",
       "             u'person': 16,\n",
       "             u'responsible': 4,\n",
       "             u'data!': 1,\n",
       "             u'point.': 4,\n",
       "             u'competitor.': 1,\n",
       "             u'recommended': 1,\n",
       "             u'absorbed': 1,\n",
       "             u'do?': 3,\n",
       "             u'They': 26,\n",
       "             u'recommended.': 2,\n",
       "             u'Ask': 4,\n",
       "             u'do7': 1,\n",
       "             u'Bank': 1,\n",
       "             u'relevant': 26,\n",
       "             u'FUELING': 1,\n",
       "             u'headers.': 2,\n",
       "             u'committing': 1,\n",
       "             u'transactions': 1,\n",
       "             u'\"like\"': 2,\n",
       "             u'see;': 1,\n",
       "             u'looming': 1,\n",
       "             u'fees,': 1,\n",
       "             u'regular': 3,\n",
       "             u'mouth': 2,\n",
       "             u'letter': 2,\n",
       "             u'fast,': 1,\n",
       "             u'iterate': 1,\n",
       "             u'99-101.': 1,\n",
       "             u'one\\ufffd': 1,\n",
       "             u'mitigate': 1,\n",
       "             u'people?': 1,\n",
       "             u'observation': 1,\n",
       "             u'released': 1,\n",
       "             u'Tools': 2,\n",
       "             u'medical': 2,\n",
       "             u'competitors': 4,\n",
       "             u'definitely': 2,\n",
       "             u'tech': 5,\n",
       "             u'mailing': 10,\n",
       "             u'came': 11,\n",
       "             u'saying': 4,\n",
       "             u'Continuous': 1,\n",
       "             u'visitor': 1,\n",
       "             u'meetings': 3,\n",
       "             u'advisors': 1,\n",
       "             u'networks.': 3,\n",
       "             u'gauge': 1,\n",
       "             u'sexism': 2,\n",
       "             u'Hawaii?': 1,\n",
       "             u'Achieving': 1,\n",
       "             u'Resources': 1,\n",
       "             u'lessons': 1,\n",
       "             u'busy': 2,\n",
       "             u'clicked': 2,\n",
       "             u'became': 6,\n",
       "             u'headline': 2,\n",
       "             u'menu': 1,\n",
       "             u'explain': 1,\n",
       "             u'bonuses': 2,\n",
       "             u'Free': 1,\n",
       "             u'for-sale': 1,\n",
       "             u'3-hour': 1,\n",
       "             u'LIVE': 2,\n",
       "             u'rich': 6,\n",
       "             u'integrate': 2,\n",
       "             u'salespeople': 2,\n",
       "             u'resources,': 3,\n",
       "             u'item,': 1,\n",
       "             u'bit.': 1,\n",
       "             u'investors.': 1,\n",
       "             u'practices.': 1,\n",
       "             u'investors,': 2,\n",
       "             u'stop': 9,\n",
       "             u'minimal.': 1,\n",
       "             u'Leave': 1,\n",
       "             u'12': 1,\n",
       "             u'dropping,': 2,\n",
       "             u'competitive': 4,\n",
       "             u'cushion': 1,\n",
       "             u'Organization': 1,\n",
       "             u'WHERE': 1,\n",
       "             u'net': 10,\n",
       "             u'signature.': 1,\n",
       "             u'years\\ufffd': 1,\n",
       "             u'earn': 16,\n",
       "             u'bar': 1,\n",
       "             u'exception.': 1,\n",
       "             u'them?': 6,\n",
       "             u'discount...\"': 1,\n",
       "             u'Over': 2,\n",
       "             u'them;': 1,\n",
       "             u'them:': 1,\n",
       "             u'bad': 12,\n",
       "             u'debt,': 1,\n",
       "             u'architecture': 1,\n",
       "             u'artificially-set': 1,\n",
       "             u'release': 23,\n",
       "             u'them.': 35,\n",
       "             u'them,': 15,\n",
       "             u'respond': 5,\n",
       "             u'ethical': 1,\n",
       "             u'effectiveness.': 2,\n",
       "             u'richer?': 1,\n",
       "             u'Orlando,': 2,\n",
       "             u'fair': 1,\n",
       "             u'our': 5,\n",
       "             u'ideas,': 1,\n",
       "             u'insurance?': 1,\n",
       "             u'testing': 3,\n",
       "             u'niche': 14,\n",
       "             u'Recommended': 1,\n",
       "             u'decided': 2,\n",
       "             u'result': 17,\n",
       "             u'directors,': 1,\n",
       "             u'insurance.': 6,\n",
       "             u'insurance,': 3,\n",
       "             u'alternative': 2,\n",
       "             u'best': 39,\n",
       "             u'subject': 3,\n",
       "             u\"Angie's\": 1,\n",
       "             u'matters.': 1,\n",
       "             u'Risk': 1,\n",
       "             u'matters,': 1,\n",
       "             u'Analytics': 10,\n",
       "             u'lots': 7,\n",
       "             u'Yoast,': 1,\n",
       "             u'artificial': 2,\n",
       "             u'adventure.': 1,\n",
       "             u'adventure,': 1,\n",
       "             u'score': 1,\n",
       "             u'Timothy.': 1,\n",
       "             u'sorts': 6,\n",
       "             u'customer.': 2,\n",
       "             u'tolerance': 1,\n",
       "             u'pirate': 1,\n",
       "             u'preserve': 1,\n",
       "             u'letting': 2,\n",
       "             u'lazy': 1,\n",
       "             u'never': 26,\n",
       "             u'involved.': 1,\n",
       "             u'enthusiasts.': 1,\n",
       "             u'extend': 3,\n",
       "             u'nature': 2,\n",
       "             u'zone.': 1,\n",
       "             u'<h2>,': 1,\n",
       "             u'agree\"': 1,\n",
       "             u'standpoint,': 3,\n",
       "             u'standpoint.': 1,\n",
       "             u'worse,': 1,\n",
       "             u'generates': 3,\n",
       "             u'debt': 4,\n",
       "             u'Otherwise': 1,\n",
       "             u'Companies\",': 1,\n",
       "             u'accident': 3,\n",
       "             u'sort,': 2,\n",
       "             u'enough\\ufffd': 1,\n",
       "             u'refinement': 1,\n",
       "             u'country': 4,\n",
       "             u'cup': 1,\n",
       "             u'stamp,': 1,\n",
       "             u'against': 12,\n",
       "             u'car?': 2,\n",
       "             u'exceptions,': 1,\n",
       "             u'ring,': 1,\n",
       "             u'planned': 3,\n",
       "             u'surprises': 1,\n",
       "             u'adapted': 1,\n",
       "             u'directly.': 1,\n",
       "             u'directly,': 2,\n",
       "             u'Given': 1,\n",
       "             u'alternate': 1,\n",
       "             u'individual,': 2,\n",
       "             u'money.': 12,\n",
       "             u'gathering': 2,\n",
       "             u'money,': 9,\n",
       "             u'WRITING': 1,\n",
       "             u'offerings': 2,\n",
       "             u'gloat.': 1,\n",
       "             u'rationally,': 1,\n",
       "             u'profitable,': 2,\n",
       "             u'money?': 1,\n",
       "             u'focused.': 1,\n",
       "             u'penalize': 1,\n",
       "             u'now.': 6,\n",
       "             u'cardboard': 1,\n",
       "             u'targeting': 3,\n",
       "             u'undertaking,': 1,\n",
       "             u'asks': 1,\n",
       "             u'C#': 1,\n",
       "             u'SDK,': 1,\n",
       "             u'contrast,': 4,\n",
       "             u'subside': 1,\n",
       "             u'now!': 1,\n",
       "             u'tiny': 1,\n",
       "             u'commission': 2,\n",
       "             u'much': 78,\n",
       "             u'replicate': 1,\n",
       "             u'interest': 10,\n",
       "             u'basic': 6,\n",
       "             u'threw': 1,\n",
       "             u'website': 79,\n",
       "             u'stresses': 1,\n",
       "             u'life': 21,\n",
       "             u'deeper': 2,\n",
       "             u\"customers'\": 1,\n",
       "             u'needed.': 3,\n",
       "             u'offering.': 4,\n",
       "             u'needed,': 1,\n",
       "             u'offering,': 1,\n",
       "             u'shoestring': 2,\n",
       "             u'tapping': 1,\n",
       "             u'personally': 7,\n",
       "             u'business-related': 1,\n",
       "             u'aviation': 1,\n",
       "             u'worked': 16,\n",
       "             u'spin': 1,\n",
       "             u'needed?': 1,\n",
       "             u'\\ufffdowner': 1,\n",
       "             u'commerce': 1,\n",
       "             u'Beware': 5,\n",
       "             u'originate': 1,\n",
       "             u'bother.': 1,\n",
       "             u'professionally': 3,\n",
       "             u'near': 5,\n",
       "             u'pre-qualified.': 1,\n",
       "             u'electricians,': 1,\n",
       "             u'employees': 8,\n",
       "             u'over.': 1,\n",
       "             u'seven': 1,\n",
       "             u'potential\"': 1,\n",
       "             u'Projects,': 1,\n",
       "             u'potential,': 2,\n",
       "             u'Apple,': 1,\n",
       "             u'it': 311,\n",
       "             u'Ideal': 1,\n",
       "             u'2009.': 1,\n",
       "             u'Brookings': 1,\n",
       "             u'sells': 4,\n",
       "             u'said.': 4,\n",
       "             u'if': 174,\n",
       "             u'investment.': 1,\n",
       "             u'investment,': 2,\n",
       "             u'things': 34,\n",
       "             u'realizing': 1,\n",
       "             u'format': 3,\n",
       "             u'potentially': 3,\n",
       "             u'split': 2,\n",
       "             u'tuning.': 1,\n",
       "             u'big': 36,\n",
       "             u'program,': 2,\n",
       "             u'program.': 1,\n",
       "             u'grows': 3,\n",
       "             u'fairly': 3,\n",
       "             u'inadvertently': 3,\n",
       "             u'can.': 6,\n",
       "             u'Maybe': 13,\n",
       "             u'can,': 3,\n",
       "             u'workforce': 1,\n",
       "             u'belongings,': 1,\n",
       "             u'VR': 1,\n",
       "             u'scale': 10,\n",
       "             u'ownership': 7,\n",
       "             u'symmetrical': 1,\n",
       "             u'Usually': 4,\n",
       "             u'opportunity': 11,\n",
       "             u'tune': 1,\n",
       "             u'grow.': 2,\n",
       "             u'grow,': 1,\n",
       "             u'maximizing': 2,\n",
       "             u'programs': 1,\n",
       "             u'spouse,': 3,\n",
       "             u'failing': 1,\n",
       "             u'world\\ufffd': 1,\n",
       "             u'practices': 1,\n",
       "             u'thing.': 4,\n",
       "             u'thing,': 2,\n",
       "             u'corporate': 17,\n",
       "             u'investments': 1,\n",
       "             u'left': 6,\n",
       "             u'addresses,': 1,\n",
       "             u'Oceans': 1,\n",
       "             u'foreigners': 1,\n",
       "             u'just': 131,\n",
       "             u'wasteful': 1,\n",
       "             u'distribute': 1,\n",
       "             u'financially': 4,\n",
       "             u'identify': 8,\n",
       "             u'human': 4,\n",
       "             u'yes': 1,\n",
       "             u'yet': 6,\n",
       "             u'previous': 2,\n",
       "             u'nudge': 1,\n",
       "             u'Sometimes': 4,\n",
       "             u'taxes.': 1,\n",
       "             u'old-fashioned': 1,\n",
       "             u'taxes,': 1,\n",
       "             u'had': 23,\n",
       "             u'advancement': 1,\n",
       "             u'Boss': 1,\n",
       "             u'(See': 1,\n",
       "             u'potential': 30,\n",
       "             u'copyrights': 2,\n",
       "             u'easy': 27,\n",
       "             u'News': 1,\n",
       "             u'has': 40,\n",
       "             u'http://www.openforum.com.': 1,\n",
       "             u'Let\\ufffds': 2,\n",
       "             u'Apart': 1,\n",
       "             u'opt': 1,\n",
       "             u'jeopardy.': 1,\n",
       "             u'ago.': 1,\n",
       "             u'wouldn\\ufffdt': 2,\n",
       "             u'fact,': 5,\n",
       "             u'survival': 1,\n",
       "             u'online': 30,\n",
       "             u'possible': 10,\n",
       "             u'You\\ufffdre': 2,\n",
       "             u'indicative': 1,\n",
       "             u'SEO\"': 1,\n",
       "             u'SEO,': 1,\n",
       "             u'(ones': 1,\n",
       "             u'sleep.': 2,\n",
       "             u'desire': 1,\n",
       "             u'county': 2,\n",
       "             u'thank-you': 1,\n",
       "             u'unnecessary': 1,\n",
       "             u'remind': 5,\n",
       "             u'steps': 3,\n",
       "             u'Are': 23,\n",
       "             u'jobs,': 2,\n",
       "             u'notorious': 1,\n",
       "             u'Arm': 1,\n",
       "             u'right': 20,\n",
       "             u'old': 6,\n",
       "             u'deal': 6,\n",
       "             u'people': 122,\n",
       "             u'Shelton,': 1,\n",
       "             u'somehow': 4,\n",
       "             u'dead': 1,\n",
       "             u'beginners,': 1,\n",
       "             u'sure': 65,\n",
       "             u'paragraphs': 1,\n",
       "             u'left,': 1,\n",
       "             u'multiple': 1,\n",
       "             u'repelling': 1,\n",
       "             u'Brainstorm': 1,\n",
       "             u'housekeepers,': 2,\n",
       "             u'short-term': 1,\n",
       "             u'ignore': 2,\n",
       "             u'attendees': 1,\n",
       "             u'for': 500,\n",
       "             u'bottom': 3,\n",
       "             u'MARKETING': 2,\n",
       "             u'Nobody': 6,\n",
       "             u'creative': 8,\n",
       "             u'contributing': 1,\n",
       "             u'continue': 7,\n",
       "             u'Facebook': 15,\n",
       "             u'Lifestyle': 5,\n",
       "             u'bold': 1,\n",
       "             u'CITY,': 1,\n",
       "             u'subscriptions': 1,\n",
       "             u'forever.': 1,\n",
       "             u'H.S.A.': 1,\n",
       "             u'burn': 3,\n",
       "             u'decisions': 5,\n",
       "             u'ads.': 10,\n",
       "             u'losing': 2,\n",
       "             u'memorable': 1,\n",
       "             u'manufacturing': 3,\n",
       "             u'super': 1,\n",
       "             u'Think': 18,\n",
       "             u'First': 3,\n",
       "             u'projected': 2,\n",
       "             u'plunge.': 1,\n",
       "             u'bar,)': 1,\n",
       "             u'dollars': 14,\n",
       "             u'corporation.': 1,\n",
       "             u'essential': 1,\n",
       "             u'browse': 1,\n",
       "             u'magazine': 2,\n",
       "             u'\\ufffdA': 1,\n",
       "             u'Forbes,': 1,\n",
       "             u'lacked': 1,\n",
       "             u'complicated.': 2,\n",
       "             u'slightly': 1,\n",
       "             u'salesperson,': 1,\n",
       "             u'automatically': 10,\n",
       "             u'salesperson.': 1,\n",
       "             u'raised': 2,\n",
       "             u'Dad.': 1,\n",
       "             u'statements': 2,\n",
       "             u'for.': 9,\n",
       "             u'for,': 2,\n",
       "             u'low.': 1,\n",
       "             u'\"Plan': 1,\n",
       "             u'done.\\ufffd9': 1,\n",
       "             u'refines': 1,\n",
       "             u'intellectual': 3,\n",
       "             u'negative': 3,\n",
       "             u'for;': 1,\n",
       "             u'Few': 1,\n",
       "             u'Aaron': 2,\n",
       "             u'Florida:': 1,\n",
       "             u'raises': 2,\n",
       "             u'wrap': 2,\n",
       "             u'chime': 1,\n",
       "             u'refined': 1,\n",
       "             u'due,': 1,\n",
       "             u'screens.': 1,\n",
       "             u'riskier': 1,\n",
       "             u'stage.': 2,\n",
       "             u'amazingly': 1,\n",
       "             u'support': 10,\n",
       "             u'initial': 27,\n",
       "             u'one-time': 1,\n",
       "             u'pages': 12,\n",
       "             u'systems.': 1,\n",
       "             u'Dependencies': 1,\n",
       "             u'editor': 1,\n",
       "             u'resulted': 2,\n",
       "             u'build,': 1,\n",
       "             u'launching': 7,\n",
       "             u'happy': 13,\n",
       "             u'creation': 2,\n",
       "             u'form': 6,\n",
       "             u'offer': 20,\n",
       "             u'raise.': 1,\n",
       "             u'\"CRM\"': 1,\n",
       "             u'raise,': 1,\n",
       "             u'recommend': 11,\n",
       "             u'Dada': 1,\n",
       "             u'so,': 24,\n",
       "             u'landing': 13,\n",
       "             u'so.': 2,\n",
       "             u'misunderstandings.': 1,\n",
       "             u'right,': 1,\n",
       "             u'Control10,': 1,\n",
       "             u'justify': 1,\n",
       "             u'raise?': 1,\n",
       "             u'statement,': 1,\n",
       "             u'IT': 4,\n",
       "             u'hall.': 1,\n",
       "             u'braces,': 1,\n",
       "             u'builds': 1,\n",
       "             u\"else's\": 2,\n",
       "             u'inside': 3,\n",
       "             u'Whoever': 1,\n",
       "             u'devices': 3,\n",
       "             u'tell': 13,\n",
       "             u'company\\ufffds': 1,\n",
       "             u'lays': 1,\n",
       "             u'Usually,': 1,\n",
       "             u'product\\ufffd': 3,\n",
       "             u'stages': 2,\n",
       "             u'average': 9,\n",
       "             u'delete': 1,\n",
       "             u'originating': 2,\n",
       "             u'breathe': 1,\n",
       "             u'proud': 1,\n",
       "             u'proved': 2,\n",
       "             u'die?': 1,\n",
       "             u'Depending': 3,\n",
       "             u'Personal': 3,\n",
       "             u'proven': 1,\n",
       "             u'sale': 4,\n",
       "             u'somebody': 2,\n",
       "             u'exist': 2,\n",
       "             u'model.': 1,\n",
       "             u'model,': 1,\n",
       "             u'accounting': 7,\n",
       "             u'Offline': 1,\n",
       "             u'commuting': 4,\n",
       "             u'FEAR': 1,\n",
       "             u'profit,': 2,\n",
       "             u'profit.': 4,\n",
       "             u'Description': 2,\n",
       "             u'Only': 1,\n",
       "             u'authoritative': 1,\n",
       "             u'minds.': 1,\n",
       "             u'Oculus': 5,\n",
       "             u'generally': 5,\n",
       "             u'handed': 1,\n",
       "             u'offerings.': 1,\n",
       "             u'geographically': 2,\n",
       "             u'digital': 10,\n",
       "             u'temporarily.': 1,\n",
       "             u'developers': 8,\n",
       "             u'models': 1,\n",
       "             u'dies': 1,\n",
       "             u'felt': 4,\n",
       "             u'modern,': 1,\n",
       "             u'modern.': 1,\n",
       "             u'drops,': 1,\n",
       "             u'HOW': 1,\n",
       "             u'POTENTIAL': 1,\n",
       "             u'Websites': 2,\n",
       "             u'variable': 2,\n",
       "             u'entrust': 1,\n",
       "             u'employees,': 2,\n",
       "             u'weekend': 3,\n",
       "             u'derail': 1,\n",
       "             u'billion': 2,\n",
       "             u'workers.': 1,\n",
       "             u'workers,': 3,\n",
       "             u'developer,': 2,\n",
       "             u'developer.': 1,\n",
       "             u'assume': 5,\n",
       "             u'daily': 3,\n",
       "             u'premiums': 4,\n",
       "             u'Page:': 1,\n",
       "             u'time': 165,\n",
       "             u'push': 3,\n",
       "             u'Hal.': 1,\n",
       "             u'profits': 3,\n",
       "             u'shop': 3,\n",
       "             u'managed': 4,\n",
       "             u'whoever': 1,\n",
       "             u'provided;': 1,\n",
       "             u'real-time': 2,\n",
       "             u'profits.': 1,\n",
       "             u'profits,': 1,\n",
       "             u'(LPO),': 1,\n",
       "             u'manages': 1,\n",
       "             u'burdened': 1,\n",
       "             u'paycheck!': 1,\n",
       "             u'paycheck.': 1,\n",
       "             u'car,)': 1,\n",
       "             u'paycheck,': 2,\n",
       "             u'retention': 1,\n",
       "             u'YOURSELF,': 1,\n",
       "             u'back\\ufffd': 1,\n",
       "             u'depend': 6,\n",
       "             u'default,': 2,\n",
       "             u'freelance': 11,\n",
       "             u'Exactly': 1,\n",
       "             u'editors': 7,\n",
       "             u'travel,': 1,\n",
       "             u'answered': 1,\n",
       "             u'DESIGNING': 1,\n",
       "             u'losing.': 1,\n",
       "             u\"else's.\": 1,\n",
       "             u'solve,': 1,\n",
       "             u'solve.': 2,\n",
       "             u'Neomek': 1,\n",
       "             u'downloading': 3,\n",
       "             u'manage,': 1,\n",
       "             u'choice': 5,\n",
       "             u'fees': 3,\n",
       "             u'embark': 2,\n",
       "             u'join': 1,\n",
       "             u'Research': 1,\n",
       "             u'exact': 3,\n",
       "             u'minute': 1,\n",
       "             u'governments': 1,\n",
       "             u'prod': 1,\n",
       "             u'solves': 2,\n",
       "             u'did': 12,\n",
       "             u'die': 1,\n",
       "             u'rights': 3,\n",
       "             u'Tax': 2,\n",
       "             u'leave': 7,\n",
       "             u'item': 4,\n",
       "             u'editor,': 1,\n",
       "             u\"Here's\": 7,\n",
       "             u'team': 4,\n",
       "             u'(SBA),': 1,\n",
       "             u'attracting': 1,\n",
       "             u'software,': 3,\n",
       "             u'prevent': 2,\n",
       "             u'software.': 1,\n",
       "             u'unexpected': 1,\n",
       "             u'fearing': 1,\n",
       "             u'And,': 2,\n",
       "             u'else,': 5,\n",
       "             u'dealing': 5,\n",
       "             u'ADVICE': 1,\n",
       "             u'measurable': 2,\n",
       "             u'sign': 4,\n",
       "             u'running.': 1,\n",
       "             u'else?': 1,\n",
       "             u'email-based': 1,\n",
       "             u'attainable,': 1,\n",
       "             u'headset': 1,\n",
       "             u'educate': 1,\n",
       "             u'anecdotes': 1,\n",
       "             u'statistic\\ufffd': 1,\n",
       "             u'current': 18,\n",
       "             u'example.': 3,\n",
       "             u'covers,': 1,\n",
       "             u'suspect': 1,\n",
       "             u'gender,': 1,\n",
       "             u'Seriously,': 1,\n",
       "             u'boost': 1,\n",
       "             u'example,': 13,\n",
       "             u'filled': 1,\n",
       "             u'target.': 1,\n",
       "             u'drafted': 1,\n",
       "             ...})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\"CRM\"', 1),\n",
       " (u'\"Display', 1),\n",
       " (u'\"Flexibility', 1),\n",
       " (u'\"Good', 1),\n",
       " (u'\"How', 1),\n",
       " (u'\"I', 1),\n",
       " (u'\"Lean', 1),\n",
       " (u'\"Measure', 1),\n",
       " (u'\"Office', 1),\n",
       " (u'\"Oh,', 1),\n",
       " (u'\"Only', 1),\n",
       " (u'\"Plan', 1),\n",
       " (u'\"Shark', 2),\n",
       " (u'\"Silver', 1),\n",
       " (u'\"SilverLining\".', 1),\n",
       " (u'\"The', 4),\n",
       " (u'\"URL', 1),\n",
       " (u'\"Why', 1),\n",
       " (u'\"WordPress', 1),\n",
       " (u'\"Y', 1),\n",
       " (u'\"account', 1),\n",
       " (u'\"acqui-hires.\"', 1),\n",
       " (u'\"action\"', 2),\n",
       " (u'\"ad', 1),\n",
       " (u'\"adaptive\"', 1),\n",
       " (u'\"advertorial\"', 1),\n",
       " (u'\"ageism', 1),\n",
       " (u'\"audience\"', 1),\n",
       " (u'\"brand', 1),\n",
       " (u'\"broad', 2),\n",
       " (u'\"call', 1),\n",
       " (u'\"call-outs\"', 1),\n",
       " (u'\"campaign', 1),\n",
       " (u'\"click', 1),\n",
       " (u'\"come', 1),\n",
       " (u'\"cost', 1),\n",
       " (u'\"designed\"', 1),\n",
       " (u'\"dimensions\"', 1),\n",
       " (u'\"goals\".', 1),\n",
       " (u'\"growth', 3),\n",
       " (u'\"hobby\"', 1),\n",
       " (u'\"how', 3),\n",
       " (u'\"landing', 1),\n",
       " (u'\"like\"', 2),\n",
       " (u'\"liking\"', 1),\n",
       " (u'\"link', 2),\n",
       " (u'\"market', 1),\n",
       " (u'\"moderately', 1),\n",
       " (u'\"modern\"', 1),\n",
       " (u'\"moonlighting\"', 2),\n",
       " (u'\"negative', 1),\n",
       " (u'\"organic', 1),\n",
       " (u'\"remarketing', 1),\n",
       " (u'\"remnant', 1),\n",
       " (u'\"responsive\"?', 1),\n",
       " (u'\"retirement.\"', 1),\n",
       " (u'\"search', 2),\n",
       " (u'\"second', 1),\n",
       " (u'\"similar', 1),\n",
       " (u'\"site', 1),\n",
       " (u'\"skyscraper', 1),\n",
       " (u'\"soft', 1),\n",
       " (u'\"spammy\"', 1),\n",
       " (u'\"strongly', 1),\n",
       " (u'\"their', 1),\n",
       " (u'\"unlimited', 1),\n",
       " (u'\"what', 1),\n",
       " (u'#1', 1),\n",
       " (u'$1,000', 2),\n",
       " (u'$1,800', 1),\n",
       " (u'$10', 1),\n",
       " (u'$10,000', 8),\n",
       " (u'$100', 1),\n",
       " (u'$100,', 1),\n",
       " (u'$100,000', 3),\n",
       " (u'$1000', 1),\n",
       " (u'$104', 1),\n",
       " (u'$11,000', 1),\n",
       " (u'$125', 1),\n",
       " (u'$150', 1),\n",
       " (u'$300', 1),\n",
       " (u'$300,000', 2),\n",
       " (u'$312', 1),\n",
       " (u'$40,000', 2),\n",
       " (u'$5', 1),\n",
       " (u'$50,000', 2),\n",
       " (u'$500', 1),\n",
       " (u'$75,000', 2),\n",
       " (u'$82.50', 1),\n",
       " (u'&', 2),\n",
       " (u'(\"impressions\")', 1),\n",
       " (u'(A', 1),\n",
       " (u'(AWS)', 1),\n",
       " (u'(BLS)', 1),\n",
       " (u'(CPA)', 1),\n",
       " (u'(CPA).', 1),\n",
       " (u'(Census', 1),\n",
       " (u'(December', 1),\n",
       " (u'(FEIN)', 1),\n",
       " (u'(I', 1),\n",
       " (u\"(I've\", 1),\n",
       " (u'(LPO)', 2),\n",
       " (u'(LPO),', 1),\n",
       " (u'(LPO?)', 1),\n",
       " (u'(MVP),', 1),\n",
       " (u'(Month,', 1),\n",
       " (u'(NIOSH)', 1),\n",
       " (u'(SBA),', 1),\n",
       " (u'(SEO)', 1),\n",
       " (u'(SEO).', 1),\n",
       " (u'(SEO,)', 1),\n",
       " (u'(See', 1),\n",
       " (u'(W3TC)', 1),\n",
       " (u\"(You'll\", 1),\n",
       " (u'(Your', 2),\n",
       " (u'(and', 2),\n",
       " (u'(arcade', 1),\n",
       " (u'(at', 1),\n",
       " (u'(be', 1),\n",
       " (u'(by', 1),\n",
       " (u'(click', 1),\n",
       " (u'(dots', 1),\n",
       " (u'(free)', 1),\n",
       " (u'(go', 1),\n",
       " (u'(health', 1),\n",
       " (u'(hosted', 1),\n",
       " (u'(http://moz.com/learn/seo)', 1),\n",
       " (u'(in', 1),\n",
       " (u'(including', 1),\n",
       " (u'(it\\ufffds', 1),\n",
       " (u'(like', 1),\n",
       " (u'(ones', 1),\n",
       " (u'(or', 3),\n",
       " (u'(other', 1),\n",
       " (u'(pre-tax)', 1),\n",
       " (u'(someone', 1),\n",
       " (u'(such', 2),\n",
       " (u'(that', 1),\n",
       " (u'(that\\ufffds', 1),\n",
       " (u'(the', 1),\n",
       " (u'(unless', 2),\n",
       " (u'(\\ufffdObamacare\\ufffd,)', 1),\n",
       " (u'*', 22),\n",
       " (u'***', 1),\n",
       " (u'--', 2),\n",
       " (u'---------------', 2),\n",
       " (u'------------------------------------------------------------', 2),\n",
       " (u'.com', 1),\n",
       " (u'0-5:', 1),\n",
       " (u'1', 2),\n",
       " (u'1%', 4),\n",
       " (u'10', 6),\n",
       " (u'10%', 6),\n",
       " (u'10%?', 1),\n",
       " (u'100', 1),\n",
       " (u'100%', 4),\n",
       " (u'1099', 1),\n",
       " (u'11', 2),\n",
       " (u'12', 1),\n",
       " (u'13', 1),\n",
       " (u'14%', 1),\n",
       " (u'15%', 1),\n",
       " (u'17.9', 1),\n",
       " (u'18%', 1),\n",
       " (u'19,', 1),\n",
       " (u'1:1', 1),\n",
       " (u'1:1124.', 1),\n",
       " (u'2', 4),\n",
       " (u'2,', 1),\n",
       " (u'20%', 3),\n",
       " (u'20-mile', 1),\n",
       " (u'20-something', 1),\n",
       " (u'2006,', 1),\n",
       " (u'20081,', 1),\n",
       " (u'2009.', 1),\n",
       " (u'2010', 1),\n",
       " (u'2010,', 1),\n",
       " (u'2010.', 1),\n",
       " (u'2011', 1),\n",
       " (u'2011.', 2),\n",
       " (u'2012', 7),\n",
       " (u'2012,', 1),\n",
       " (u'2013', 1),\n",
       " (u'2014', 2),\n",
       " (u'2014)', 1),\n",
       " (u'2014.', 4),\n",
       " (u'2015', 3),\n",
       " (u'2015,', 1),\n",
       " (u'212,000', 1),\n",
       " (u'22', 1),\n",
       " (u'22%', 1),\n",
       " (u'27,', 1),\n",
       " (u'28%', 1),\n",
       " (u'29%', 2),\n",
       " (u'3', 6),\n",
       " (u'3%?', 1),\n",
       " (u'3,000', 1),\n",
       " (u'3-D', 2),\n",
       " (u'3-hour', 1),\n",
       " (u'300', 2),\n",
       " (u'360', 1),\n",
       " (u'3?', 1),\n",
       " (u'3D', 2),\n",
       " (u'4', 6),\n",
       " (u'4,', 1),\n",
       " (u'4-Hour', 1),\n",
       " (u'4.6', 1),\n",
       " (u'40', 1),\n",
       " (u'40%', 1),\n",
       " (u'401(K)', 1),\n",
       " (u'41%', 1),\n",
       " (u'41,', 1),\n",
       " (u'43', 1),\n",
       " (u'46%', 2),\n",
       " (u'46.7', 1),\n",
       " (u'47', 1),\n",
       " (u'49.3%', 1),\n",
       " (u'5', 6),\n",
       " (u'50', 4),\n",
       " (u'50%', 5),\n",
       " (u'50/50', 2),\n",
       " (u'55', 1),\n",
       " (u'55%', 1),\n",
       " (u'6', 2),\n",
       " (u'6%', 1),\n",
       " (u'6-8:', 1),\n",
       " (u'60', 1),\n",
       " (u'62', 3),\n",
       " (u'65', 1),\n",
       " (u'68%', 1),\n",
       " (u'7', 3),\n",
       " (u'70%', 1),\n",
       " (u'7?', 1),\n",
       " (u'8', 4),\n",
       " (u'8-10:', 1),\n",
       " (u'8-plus-hour-day', 1),\n",
       " (u'85%', 1),\n",
       " (u'9', 5),\n",
       " (u'9-5', 1),\n",
       " (u'9-5,', 1),\n",
       " (u'9-5.', 2),\n",
       " (u'90%', 2),\n",
       " (u'90%.', 1),\n",
       " (u'93%', 1),\n",
       " (u'99-101.', 1),\n",
       " (u'<alt>', 1),\n",
       " (u'<h1>,', 1),\n",
       " (u'<h2>,', 1),\n",
       " (u'<title>,', 1),\n",
       " (u'A', 39),\n",
       " (u'ABOUT', 1),\n",
       " (u'ACKNOWLEDGMENTS', 1),\n",
       " (u'ACT', 1),\n",
       " (u'ADAPTING', 1),\n",
       " (u'ADVERTISING', 1),\n",
       " (u'ADVICE', 1),\n",
       " (u'AGREEMENT', 1),\n",
       " (u'ALONE', 1),\n",
       " (u'AM', 4),\n",
       " (u'AM,', 1),\n",
       " (u'AM.', 1),\n",
       " (u'AND', 8),\n",
       " (u'AS', 1),\n",
       " (u'AUTHOR', 1),\n",
       " (u'AVOIDING', 1),\n",
       " (u'Aaron', 2),\n",
       " (u'Aaron\\ufffds', 1),\n",
       " (u'About', 4),\n",
       " (u'Accept', 2),\n",
       " (u'According', 5),\n",
       " (u'Achieving', 1),\n",
       " (u'Acknowledgments', 1),\n",
       " (u'Act', 2),\n",
       " (u'Act,\"', 1),\n",
       " (u'Ad', 2),\n",
       " (u'AdSense', 1),\n",
       " (u'AdSense,', 1),\n",
       " (u'AdWords', 23),\n",
       " (u\"AdWords'\", 1),\n",
       " (u'AdWords,', 6),\n",
       " (u'Adapting', 1),\n",
       " (u'Adding', 1),\n",
       " (u'Additional', 1),\n",
       " (u'Administration', 2),\n",
       " (u'Administration,', 1),\n",
       " (u'Ads', 3),\n",
       " (u'Advertising', 3),\n",
       " (u'Advice', 1),\n",
       " (u'Affordable', 1),\n",
       " (u'After', 3),\n",
       " (u'Again,', 2),\n",
       " (u'Ageism', 1),\n",
       " (u'Ageist,', 1),\n",
       " (u'AgileSrc', 1),\n",
       " (u'AgileSrc,', 2),\n",
       " (u'Agreement', 1),\n",
       " (u'Alerts', 1),\n",
       " (u'Alexa,', 1),\n",
       " (u'All', 13),\n",
       " (u'Alone', 1),\n",
       " (u'Also', 3),\n",
       " (u'Also,', 4),\n",
       " (u'Although', 5),\n",
       " (u'Always', 3),\n",
       " (u'Am', 1),\n",
       " (u'Amazon', 2),\n",
       " (u\"Amazon's\", 2),\n",
       " (u'Amazon,', 3),\n",
       " (u'Amazon.', 1),\n",
       " (u'Amazon.com', 1),\n",
       " (u'American', 4),\n",
       " (u'Americans', 1),\n",
       " (u'An', 6),\n",
       " (u'Analytics', 10),\n",
       " (u'Analytics,', 5),\n",
       " (u'Analytics.', 1),\n",
       " (u'And', 14),\n",
       " (u'And,', 2),\n",
       " (u\"Angie's\", 1),\n",
       " (u'Another', 2),\n",
       " (u'Answer', 1),\n",
       " (u'Anywhere,', 1),\n",
       " (u'Apart', 1),\n",
       " (u'App', 1),\n",
       " (u'Apple,', 1),\n",
       " (u'Are', 23),\n",
       " (u'Arm', 1),\n",
       " (u'Armed', 2),\n",
       " (u'As', 45),\n",
       " (u'Asia', 1),\n",
       " (u'Ask', 4),\n",
       " (u'Assembly.', 1),\n",
       " (u'Association,', 1),\n",
       " (u'Assume', 1),\n",
       " (u'Assuming', 1),\n",
       " (u'At', 24),\n",
       " (u'Attention-Grabbing', 1),\n",
       " (u'Austin,', 1),\n",
       " (u'Author', 1),\n",
       " (u'Automated', 1),\n",
       " (u'Automation', 1),\n",
       " (u'Average', 1),\n",
       " (u'Avoid', 2),\n",
       " (u'Avoiding', 2),\n",
       " (u'B\"', 1),\n",
       " (u'B2B', 1),\n",
       " (u'BASICS', 5),\n",
       " (u'BEWARE', 5),\n",
       " (u'BIG', 1),\n",
       " (u'BLANKET', 1),\n",
       " (u'BLS', 1),\n",
       " (u'BOSS', 1),\n",
       " (u'BUILDING', 2),\n",
       " (u'BUSINESS', 10),\n",
       " (u'Bank', 1),\n",
       " (u'Banner', 2),\n",
       " (u'Based', 1),\n",
       " (u'Basics', 5),\n",
       " (u'Be', 11),\n",
       " (u'Bear', 1),\n",
       " (u'Because', 1),\n",
       " (u'Become', 1),\n",
       " (u'Before', 3),\n",
       " (u'Being', 2),\n",
       " (u'Beware', 5),\n",
       " (u'Beyond', 1),\n",
       " (u'Big', 1),\n",
       " (u'Bing,', 1),\n",
       " (u'Binging', 1),\n",
       " (u'Blanket', 1),\n",
       " (u'Bob', 1),\n",
       " (u'Bob,', 1),\n",
       " (u'Books.', 1),\n",
       " (u'Boss', 1),\n",
       " (u'Boston.', 1),\n",
       " (u'Both', 2),\n",
       " (u'Brainstorm', 1),\n",
       " (u'Brookings', 1),\n",
       " (u'Brutal', 1),\n",
       " (u'Bryc', 1),\n",
       " (u'Build', 2),\n",
       " (u'Builder\"', 1),\n",
       " (u'Building', 5),\n",
       " (u'Bureau', 2),\n",
       " (u'Bureau,', 1),\n",
       " (u'Bus', 1),\n",
       " (u'Business', 19),\n",
       " (u'Business,', 2),\n",
       " (u'Business-to-business?', 1),\n",
       " (u'Businesses.', 1),\n",
       " (u'But', 38),\n",
       " (u'But,', 12),\n",
       " (u'Buying', 1),\n",
       " (u'By', 9),\n",
       " (u'C#', 1),\n",
       " (u'C++', 1),\n",
       " (u'C-suite.', 1),\n",
       " (u'CAMPAIGNS', 1),\n",
       " (u'CARE', 1),\n",
       " (u'CAREER', 1),\n",
       " (u'CARROT', 1),\n",
       " (u'CASE', 1),\n",
       " (u'CEO', 2),\n",
       " (u'CEO!', 1),\n",
       " (u\"CEO's\", 3),\n",
       " (u'CEO,', 2),\n",
       " (u'CEO.', 1),\n",
       " (u'CHECK', 1),\n",
       " (u'CHECKLIST', 1),\n",
       " (u'CITY,', 1),\n",
       " (u'CLOSING', 1),\n",
       " (u'COBRA', 2),\n",
       " (u'COMMUTE', 1),\n",
       " (u'COMPOUNDING', 1),\n",
       " (u'CONSIDER', 1),\n",
       " (u'CONTENTS', 1),\n",
       " (u'CPA', 4),\n",
       " (u\"CPA's\", 2),\n",
       " (u'CPA,', 2),\n",
       " (u'CPA\\ufffds', 1),\n",
       " (u'CRM', 2),\n",
       " (u'CSS', 1),\n",
       " (u'CTR', 1),\n",
       " (u'Cache', 1),\n",
       " (u'California', 1),\n",
       " (u'California,', 1),\n",
       " (u'Campaigns', 1),\n",
       " (u'Can', 21),\n",
       " (u'Canada,', 1),\n",
       " (u'Car?\\ufffd,', 1),\n",
       " (u'Care', 2),\n",
       " (u'Career', 1),\n",
       " (u'Carrot', 1),\n",
       " (u'Case', 1),\n",
       " (u'Catch-22', 1),\n",
       " (u'Census', 1),\n",
       " (u'Centers', 1),\n",
       " (u'Central', 3),\n",
       " (u'Certain', 1),\n",
       " (u'Chances', 1),\n",
       " (u'Channels', 1),\n",
       " (u'Channels:', 1),\n",
       " (u'Check', 4),\n",
       " (u'Checking', 1),\n",
       " (u'Checklist', 1),\n",
       " (u'China\"', 1),\n",
       " (u'China,', 2),\n",
       " (u'China.', 1),\n",
       " (u'Choosing', 1),\n",
       " (u'Closing', 1),\n",
       " (u'Combinator\"', 1),\n",
       " (u'Come', 1),\n",
       " (u'Commercial', 1),\n",
       " (u'Community', 1),\n",
       " (u'Commute', 1),\n",
       " (u'Companies', 1),\n",
       " (u'Companies\",', 1),\n",
       " (u'Company', 2),\n",
       " (u'Company)', 1),\n",
       " (u'Compare', 1),\n",
       " (u'Compounding', 1),\n",
       " (u'Congratulations!', 1),\n",
       " (u'Congress', 1),\n",
       " (u'Conservatively,', 1),\n",
       " (u'Consider', 5),\n",
       " (u'Constant', 2),\n",
       " (u'Consulting.', 1),\n",
       " (u'Contact', 2),\n",
       " (u'Contact,', 1),\n",
       " (u'Continuous', 1),\n",
       " (u'Control10,', 1),\n",
       " (u'Conventional', 1),\n",
       " (u'Conversions:', 1),\n",
       " (u'Copyright', 1),\n",
       " (u'Costs', 3),\n",
       " (u'Could', 2),\n",
       " (u'Council', 1),\n",
       " (u'Council,', 1),\n",
       " (u'Countless', 1),\n",
       " (u'Countries', 1),\n",
       " (u'County.', 1),\n",
       " (u'Coursera,', 2),\n",
       " (u'Courses.', 1),\n",
       " (u'Cover', 1),\n",
       " (u'Crash', 1),\n",
       " (u'Create', 1),\n",
       " (u'Creating', 1),\n",
       " (u'Creating,', 1),\n",
       " (u'Crown', 1),\n",
       " (u'Customer', 2),\n",
       " (u'Customers', 1),\n",
       " (u'Customizing', 1),\n",
       " (u'DECISION', 1),\n",
       " (u'DEFINITION', 1),\n",
       " (u'DEPENDENCIES', 1),\n",
       " (u'DESCRIPTION', 2),\n",
       " (u'DESIGNING', 1),\n",
       " (u'DEVELOPING', 1),\n",
       " (u'DHHS', 1),\n",
       " (u'DISCLAIMER', 1),\n",
       " (u\"DON'T\", 1),\n",
       " (u'DPI', 1),\n",
       " (u'DPI.', 1),\n",
       " (u'Dad.', 1),\n",
       " (u'Dada', 1),\n",
       " (u'Daniel', 1),\n",
       " (u'Dartmouth,', 1),\n",
       " (u'Day', 1),\n",
       " (u'Deborah', 1),\n",
       " (u'Decision', 1),\n",
       " (u'Definition', 1),\n",
       " (u'Dental', 2),\n",
       " (u'Department', 1),\n",
       " (u'Dependencies', 1),\n",
       " (u'Depending', 3),\n",
       " (u'Describe', 3),\n",
       " (u'Description', 2),\n",
       " (u'Designing', 1),\n",
       " (u'Despite', 1),\n",
       " (u'Develop', 1),\n",
       " (u'Developing', 1),\n",
       " (u'Did', 2),\n",
       " (u\"Didn't\", 1),\n",
       " (u'Digging', 1),\n",
       " (u'DirectX', 1),\n",
       " (u'Director', 1),\n",
       " (u'Director-level', 1),\n",
       " (u'Discarding', 1),\n",
       " (u'Disclaimer', 1),\n",
       " (u'Disease', 1),\n",
       " (u'Do', 19),\n",
       " (u'Does', 2),\n",
       " (u'Doing', 3),\n",
       " (u\"Don't\", 22),\n",
       " (u'Done?', 1),\n",
       " (u'Don\\ufffdt', 1),\n",
       " (u'Doubling', 1),\n",
       " (u'Dummies,', 1),\n",
       " (u'Dummies.', 1),\n",
       " (u'Dummies\\ufffd', 1),\n",
       " (u'Dykstra,', 1),\n",
       " (u'E-mail', 1),\n",
       " (u'EBay,', 2),\n",
       " (u'EFFECT', 1),\n",
       " (u'EGO', 1),\n",
       " (u'ELSE', 1),\n",
       " (u'EMAIL', 1),\n",
       " (u'EMPLOYER', 1),\n",
       " (u'EMPLOYMENT', 1),\n",
       " (u'ENGINE', 2),\n",
       " (u'EVALUATING', 1),\n",
       " (u'EVEN', 1),\n",
       " (u'Earning', 1),\n",
       " (u'Economic', 1),\n",
       " (u'Editors', 1),\n",
       " (u'Effect', 1),\n",
       " (u'Effective', 1),\n",
       " (u'Ego', 1),\n",
       " (u'Elance', 1),\n",
       " (u'Eliminating', 1),\n",
       " (u'Else', 1),\n",
       " (u'Email', 5),\n",
       " (u'Emails', 1),\n",
       " (u'Employer', 2),\n",
       " (u'Employment', 1),\n",
       " (u'Engine', 2),\n",
       " (u'English', 3),\n",
       " (u'English,', 1),\n",
       " (u'English.', 1),\n",
       " (u'Entrepreneurs', 1),\n",
       " (u'Eric', 2),\n",
       " (u'Eric.', 1),\n",
       " (u'Escape', 1),\n",
       " (u'Especially', 1),\n",
       " (u'Estimating', 1),\n",
       " (u'Etsy,', 1),\n",
       " (u'Etsy.', 1),\n",
       " (u'Europe', 1),\n",
       " (u'Evaluate', 1),\n",
       " (u'Evaluating', 1),\n",
       " (u'Even', 35),\n",
       " (u'Every', 4),\n",
       " (u'Everyone', 2),\n",
       " (u\"Everyone's\", 1),\n",
       " (u'Exactly', 1),\n",
       " (u'Expenses', 1),\n",
       " (u'Explain', 1),\n",
       " (u'Express\\ufffds', 1),\n",
       " (u'FAA.', 1),\n",
       " (u'FAILURE', 1),\n",
       " (u'FALLACY', 1),\n",
       " (u'FEAR', 1),\n",
       " (u'FINAL', 1),\n",
       " (u'FINANCIAL', 2),\n",
       " (u'FINDING', 3),\n",
       " (u'FIRE', 1),\n",
       " (u'FIXED', 1),\n",
       " (u'FLOWCHART:', 1),\n",
       " (u'FOR', 3),\n",
       " (u'FREEDOM', 3),\n",
       " (u'FUELING', 1),\n",
       " (u'Face', 1),\n",
       " (u'FaceBook', 1),\n",
       " (u'Facebook', 15),\n",
       " (u'Facebook,', 3),\n",
       " (u'Facebook?', 1),\n",
       " (u'Failure', 1),\n",
       " (u'Fallacy', 1),\n",
       " (u'Far', 1),\n",
       " (u'Fear', 1),\n",
       " (u'Federal', 1),\n",
       " (u'Fees', 1),\n",
       " (u\"Ferriss's\", 1),\n",
       " (u'Ferriss,', 1),\n",
       " (u'Few', 1),\n",
       " (u'Figure', 2),\n",
       " (u'Fiji?', 1),\n",
       " (u'Final', 1),\n",
       " (u'Finally,', 5),\n",
       " (u'Finally\\ufffd', 1),\n",
       " (u'Financial', 3),\n",
       " (u'Find', 2),\n",
       " (u'Finding', 4),\n",
       " (u'Fire', 1),\n",
       " (u'First', 3),\n",
       " (u'First,', 2),\n",
       " (u'Fixed', 1),\n",
       " (u'Fla.', 1),\n",
       " (u'Florida', 4),\n",
       " (u'Florida:', 1),\n",
       " (u'Flowchart:', 1),\n",
       " (u'Focus', 1),\n",
       " (u'For', 19),\n",
       " (u'Forbes,', 1),\n",
       " (u'Founded', 1),\n",
       " (u'Founder,', 1),\n",
       " (u'Four', 1),\n",
       " (u'Frank', 10),\n",
       " (u\"Frank's\", 1),\n",
       " (u'Free', 1),\n",
       " (u'Freed', 1),\n",
       " (u'Freedom', 7),\n",
       " (u'Freelance', 4),\n",
       " (u'Freelancers', 1),\n",
       " (u'From', 1),\n",
       " (u'Fueling', 1),\n",
       " (u'Furthermore,', 1),\n",
       " (u'GO', 2),\n",
       " (u'GROWTH', 3),\n",
       " (u'GUILT', 1),\n",
       " (u'Gallup', 1),\n",
       " (u'Gaming', 1),\n",
       " (u'Geared', 1),\n",
       " (u'General', 1),\n",
       " (u'Generally', 2),\n",
       " (u'Germany,', 1),\n",
       " (u'Get', 6),\n",
       " (u'Gets', 1),\n",
       " (u'Getting', 3),\n",
       " (u'Given', 1),\n",
       " (u'Giving', 1),\n",
       " (u'Glass', 1),\n",
       " (u'Go', 7),\n",
       " (u'GoDaddy.com', 1),\n",
       " (u\"God's\", 1),\n",
       " (u'Good', 1),\n",
       " (u'Google', 53),\n",
       " (u\"Google's\", 3),\n",
       " (u'Google,', 4),\n",
       " (u'Google.', 2),\n",
       " (u'Google.\"', 1),\n",
       " (u'Grow.', 1),\n",
       " (u'Growing', 1),\n",
       " (u'Growth', 4),\n",
       " (u'Guide', 1),\n",
       " (u'Guilt', 1),\n",
       " (u'H.S.A.', 1),\n",
       " (u'HAPPEN', 1),\n",
       " (u'HAVE', 1),\n",
       " (u'HAVING', 1),\n",
       " (u'HEALTH', 1),\n",
       " (u'HIRE', 1),\n",
       " (u'HIRING', 1),\n",
       " (u'HOW', 1),\n",
       " (u'HTML', 1),\n",
       " (u'Had', 4),\n",
       " (u'Hal', 1),\n",
       " (u'Hal.', 1),\n",
       " (u'Hanging', 1),\n",
       " (u'Happen', 1),\n",
       " (u'Harmony,', 1),\n",
       " (u'Harper', 1),\n",
       " (u'Have', 9),\n",
       " (u'Having', 2),\n",
       " (u'Hawaii', 1),\n",
       " (u'Hawaii?', 1),\n",
       " (u'He', 3),\n",
       " (u'Headline', 1),\n",
       " (u'Headset', 1),\n",
       " (u'Health', 2),\n",
       " (u'Hell', 1),\n",
       " (u'Here', 8),\n",
       " (u\"Here's\", 7),\n",
       " (u'Hire', 1),\n",
       " (u'Hiring', 3),\n",
       " (u'Hopefully', 2),\n",
       " (u'Hopefully,', 2),\n",
       " (u'Hour', 1),\n",
       " (u'How', 29),\n",
       " (u'However,', 6),\n",
       " (u'Human', 1),\n",
       " (u'I', 322),\n",
       " (u\"I'd\", 1),\n",
       " (u\"I'll\", 3),\n",
       " (u\"I'm\", 25),\n",
       " (u\"I've\", 23),\n",
       " (u'I:', 2),\n",
       " (u'IAG', 1),\n",
       " (u'IDEA', 1),\n",
       " (u'IDEAL', 1),\n",
       " (u'IDEAS', 2),\n",
       " (u'II:', 2),\n",
       " (u'III:', 2),\n",
       " (u'IMDb', 1),\n",
       " (u'IMDb.com,', 1),\n",
       " (u'IMPORTANCE', 1),\n",
       " (u'IN', 1),\n",
       " (u'INDOCTRINATION', 1),\n",
       " (u'INERTIA', 1),\n",
       " (u'INTERPRETING', 1),\n",
       " (u'INTRODUCING', 1),\n",
       " (u'INVESTING', 1),\n",
       " (u'IRS', 2),\n",
       " (u'IS', 1),\n",
       " (u'IT', 4),\n",
       " (u'IT\\ufffdS', 1),\n",
       " (u'Idea', 1),\n",
       " (u'Ideal', 1),\n",
       " (u'Ideally', 1),\n",
       " (u'Ideally,', 4),\n",
       " (u'Ideas', 2),\n",
       " (u'Identification', 1),\n",
       " (u'Identifying', 1),\n",
       " (u'If', 237),\n",
       " (u'Images', 1),\n",
       " (u'Impact', 1),\n",
       " (u'Importance', 1),\n",
       " (u'In', 41),\n",
       " (u'Inc.,', 1),\n",
       " (u'Increasing', 1),\n",
       " (u'Incubation', 1),\n",
       " (u'Indoctrination', 2),\n",
       " (u'Industry', 4),\n",
       " (u'Industry-specific', 1),\n",
       " (u'Inertia', 1),\n",
       " (u'Innovation', 1),\n",
       " (u'Insert', 1),\n",
       " (u'Insider11.', 1),\n",
       " (u'Instagram,', 1),\n",
       " (u'Instagram.', 1),\n",
       " (u'Instead', 3),\n",
       " (u'Instead,', 4),\n",
       " (u'Institution,', 1),\n",
       " (u'Internet', 13),\n",
       " (u'Internet,', 6),\n",
       " (u'Internet-based', 4),\n",
       " (u'Internet.', 3),\n",
       " (u'Interpreting', 1),\n",
       " (u'Introducing', 1),\n",
       " (u'Investing', 3),\n",
       " (u'Investors', 1),\n",
       " (u'Iraq,', 1),\n",
       " (u'Iraq.', 1),\n",
       " (u'Is', 17),\n",
       " (u'It', 42),\n",
       " (u\"It's\", 46),\n",
       " (u'It.', 2),\n",
       " (u'Its', 3),\n",
       " (u'It\\ufffds', 6),\n",
       " (u'I\\ufffdd', 1),\n",
       " (u'I\\ufffdll', 1),\n",
       " (u'I\\ufffdm', 5),\n",
       " (u'I\\ufffdve', 1),\n",
       " (u'J.', 1),\n",
       " (u'Join', 1),\n",
       " (u'Jose,', 1),\n",
       " (u'Just', 11),\n",
       " (u'KEY', 1),\n",
       " (u'Kahneman', 1),\n",
       " (u'Kane', 7),\n",
       " (u'Kane,', 2),\n",
       " (u'Kane.', 1),\n",
       " (u'Keep', 7),\n",
       " (u'Keeping', 1),\n",
       " (u'Key', 1),\n",
       " (u'LANDING', 1),\n",
       " (u'LAST', 1),\n",
       " (u'LAUNCHING', 1),\n",
       " (u'LEECHES', 1),\n",
       " (u'LETTING', 1),\n",
       " (u'LICENSES', 1),\n",
       " (u'LIFE', 1),\n",
       " (u'LIFESTYLE', 4),\n",
       " (u'LITTLE', 1),\n",
       " (u'LIVE', 2),\n",
       " (u'LLC', 3),\n",
       " (u'LLC,', 3),\n",
       " (u'LPO', 2),\n",
       " (u'LPO,', 1),\n",
       " (u'LPO.', 1),\n",
       " (u'Labor', 2),\n",
       " (u'Laminar', 1),\n",
       " (u'Landing', 4),\n",
       " (u'Last', 1),\n",
       " (u'Launching', 2),\n",
       " (u'Lean', 4),\n",
       " (u'Leave', 1),\n",
       " (u'Leaving', 2),\n",
       " (u'Leeches', 1),\n",
       " (u'Let', 1),\n",
       " (u\"Let's\", 8),\n",
       " (u'Letting', 1),\n",
       " (u'Let\\ufffds', 2),\n",
       " (u'Liability', 2),\n",
       " (u'Licenses', 1),\n",
       " (u'Life', 2),\n",
       " (u'Lifestyle', 5),\n",
       " (u'Like', 2),\n",
       " (u'Likes', 1),\n",
       " (u'Limited', 2),\n",
       " (u'Lining', 1),\n",
       " (u'LinkedIn', 9),\n",
       " (u'LinkedIn,', 2),\n",
       " (u'List', 1),\n",
       " (u'Listen', 1),\n",
       " (u'Little', 1),\n",
       " (u'Live', 3),\n",
       " (u'Living', 1),\n",
       " (u'Load', 1),\n",
       " (u'Local', 1),\n",
       " (u'Look', 4),\n",
       " (u'Looking', 3),\n",
       " (u'MAKING', 4),\n",
       " (u'MANAGEMENT', 2),\n",
       " (u'MARKET', 1),\n",
       " (u'MARKETING', 2),\n",
       " (u'MEASURE', 1),\n",
       " (u'MEASURING', 1),\n",
       " (u'METRICS', 1),\n",
       " (u'MISLEADING', 1),\n",
       " (u'MITIGATION', 1),\n",
       " (u'MVP', 1),\n",
       " (u'Mail', 1),\n",
       " (u'MailChimp', 4),\n",
       " (u'Maintaining', 2),\n",
       " (u'Maintenance', 1),\n",
       " (u'Major', 1),\n",
       " (u'Make', 15),\n",
       " (u'Making', 5),\n",
       " (u'Management', 2),\n",
       " (u'Management,', 1),\n",
       " (u'Many', 7),\n",
       " (u'Market', 2),\n",
       " (u'Marketing', 5),\n",
       " (u'Marketplace', 1),\n",
       " (u'Massachusetts', 1),\n",
       " (u'May', 1),\n",
       " (u'Maybe', 13),\n",
       " (u'Meanwhile', 1),\n",
       " (u'Meanwhile,', 1),\n",
       " (u'Measure', 1),\n",
       " (u'Measuring', 1),\n",
       " (u'Medicare', 2),\n",
       " (u'Meetup', 4),\n",
       " (u'Metrics', 2),\n",
       " (u'Michal', 3),\n",
       " (u'Military', 1),\n",
       " (u'Minimizing', 1),\n",
       " (u'Misleading', 1),\n",
       " (u'Mitigation', 1),\n",
       " (u'Mohammed', 1),\n",
       " (u'Mohammed,', 1),\n",
       " (u'Moleskine', 1),\n",
       " (u'Mom', 1),\n",
       " (u'More', 2),\n",
       " (u'Most', 8),\n",
       " (u'Moz.com', 1),\n",
       " (u'Much', 1),\n",
       " (u'Multiply', 1),\n",
       " (u'My', 16),\n",
       " (u'NAMING', 1),\n",
       " (u'NASA', 1),\n",
       " (u'NET', 1),\n",
       " (u'NETWORKS', 1),\n",
       " (u'NEW', 1),\n",
       " (u'NO', 2),\n",
       " (u'NOT', 2),\n",
       " (u'Naming', 1),\n",
       " (u'National', 1),\n",
       " (u'Need', 1),\n",
       " (u'Neomek', 1),\n",
       " (u'Net', 2),\n",
       " (u'Networks', 1),\n",
       " (u'New', 6),\n",
       " (u'News', 1),\n",
       " (u'Next,', 1),\n",
       " (u'No', 14),\n",
       " (u'Nobel', 1),\n",
       " (u'Nobody', 6),\n",
       " (u\"Nobody's\", 4),\n",
       " (u'None', 1),\n",
       " (u'Not', 7),\n",
       " (u'Note', 2),\n",
       " (u'Notice', 1),\n",
       " (u'Now', 4),\n",
       " (u'Now,', 4),\n",
       " (u'Number', 2),\n",
       " (u'OBTAINING', 1),\n",
       " (u'OF', 16),\n",
       " (u'OFFLINE', 1),\n",
       " (u'OK', 6),\n",
       " (u'OK.', 1),\n",
       " (u'ON', 2),\n",
       " (u'ONLINE', 1),\n",
       " (u'OPEN', 1),\n",
       " (u'OPTIMIZATION', 2),\n",
       " (u'ORGANIZATION', 1),\n",
       " (u'ORLANDO,', 1),\n",
       " (u'OTHER', 1),\n",
       " (u'OVERCOMING', 1),\n",
       " (u'Obtaining', 1),\n",
       " (u'Ocean', 7),\n",
       " (u'Oceans', 1),\n",
       " (u'Oculus', 5),\n",
       " (u'Odds', 2),\n",
       " (u'Of', 3),\n",
       " (u'Office', 2),\n",
       " (u'Offline', 1),\n",
       " (u'Often', 1),\n",
       " (u'Often,', 3),\n",
       " (u'Oftentimes,', 1),\n",
       " (u'Once', 23),\n",
       " (u'One', 12),\n",
       " (u'Ongoing', 1),\n",
       " (u'Ongoing,', 1),\n",
       " (u'Online', 8),\n",
       " (u'Only', 1),\n",
       " (u'OpenGL', 1),\n",
       " (u'Optimization', 3),\n",
       " (u'Or', 3),\n",
       " (u'Or,', 1),\n",
       " (u'Orange', 1),\n",
       " (u'Organization', 1),\n",
       " (u'Orlando', 4),\n",
       " (u'Orlando,', 2),\n",
       " (u'Other', 4),\n",
       " (u'Otherwise', 1),\n",
       " (u'Otherwise,', 2),\n",
       " (u'Out', 1),\n",
       " (u'Over', 2),\n",
       " (u'Overcoming', 1),\n",
       " (u'PAGE', 1),\n",
       " (u'PART', 5),\n",
       " (u\"PC's,\", 1),\n",
       " (u'PC,', 1),\n",
       " (u'PEOPLE', 1),\n",
       " (u'PERSONAL', 1),\n",
       " (u'PITFALLS', 1),\n",
       " (u'PLAN', 3),\n",
       " (u'PLANNING', 3),\n",
       " (u'PM.', 2),\n",
       " (u'PNG,', 1),\n",
       " (u'POINTS', 1),\n",
       " (u'POTENTIAL', 1),\n",
       " (u'PR', 6),\n",
       " (u'PR,', 3),\n",
       " (u'PREFACE', 1),\n",
       " (u'PRESSURE', 1),\n",
       " (u'PRODUCT', 1),\n",
       " (u'PRODUCT,', 1),\n",
       " (u'PROTECTION', 1),\n",
       " (u'PUBLIC', 1),\n",
       " (u'PULLING', 1),\n",
       " (u'Page', 2),\n",
       " (u'Page:', 1),\n",
       " (u'Park', 1),\n",
       " (u'Part', 2),\n",
       " (u'Participate', 1),\n",
       " (u'Patent', 1),\n",
       " (u'Pay', 2),\n",
       " (u'Paying', 2),\n",
       " (u'People', 4),\n",
       " (u'Perhaps', 17),\n",
       " (u'Personal', 3),\n",
       " (u'Personally,', 2),\n",
       " (u'Philippines', 1),\n",
       " (u'Physical', 1),\n",
       " (u'Pinterest', 1),\n",
       " (u'Pitfalls', 1),\n",
       " (u'Plan', 4),\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wordCount.items())  #to sort dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wordcount with sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath =\"file:///home/icpl12900/Desktop/assignments/Book.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = data.flatMap(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCount = words.map(lambda x : (x,1)).reduceByKey(lambda x,y : x+y).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'\"CRM\"', 1),\n",
       " (u'\"Display', 1),\n",
       " (u'\"Flexibility', 1),\n",
       " (u'\"Good', 1),\n",
       " (u'\"How', 1),\n",
       " (u'\"I', 1),\n",
       " (u'\"Lean', 1),\n",
       " (u'\"Measure', 1),\n",
       " (u'\"Office', 1),\n",
       " (u'\"Oh,', 1)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most popular movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath =\"file:///home/icpl12900/Desktop/assignments/ml-100k/u.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'196\\t242\\t3\\t881250949',\n",
       " u'186\\t302\\t3\\t891717742',\n",
       " u'22\\t377\\t1\\t878887116',\n",
       " u'244\\t51\\t2\\t880606923',\n",
       " u'166\\t346\\t1\\t886397596',\n",
       " u'298\\t474\\t4\\t884182806',\n",
       " u'115\\t265\\t2\\t881171488',\n",
       " u'253\\t465\\t5\\t891628467',\n",
       " u'305\\t451\\t3\\t886324817',\n",
       " u'6\\t86\\t3\\t883603013']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    row = row.split('\\t')\n",
    "    row[0] = row[0]\n",
    "    return(row[0],1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parseMovieData = data.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'196', 1),\n",
       " (u'186', 1),\n",
       " (u'22', 1),\n",
       " (u'244', 1),\n",
       " (u'166', 1),\n",
       " (u'298', 1),\n",
       " (u'115', 1),\n",
       " (u'253', 1),\n",
       " (u'305', 1),\n",
       " (u'6', 1)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseMovieData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostPopularMovie = parseMovieData.reduceByKey(lambda x,y:x+y).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1', 272),\n",
       " (u'10', 184),\n",
       " (u'100', 59),\n",
       " (u'101', 67),\n",
       " (u'102', 216),\n",
       " (u'103', 29),\n",
       " (u'104', 111),\n",
       " (u'105', 23),\n",
       " (u'106', 64),\n",
       " (u'107', 22)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMovie.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most popular Movie with total Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath =\"file:///home/icpl12900/Desktop/assignments/ml-100k/u.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    row = row.split('\\t')\n",
    "    row[0] = int(row[0])\n",
    "    row[1] = int(row[2])\n",
    "    return(row[0],row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parseMovieData = data.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, u'3'),\n",
       " (186, u'3'),\n",
       " (22, u'1'),\n",
       " (244, u'2'),\n",
       " (166, u'1'),\n",
       " (298, u'4'),\n",
       " (115, u'2'),\n",
       " (253, u'5'),\n",
       " (305, u'3'),\n",
       " (6, u'3')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseMovieData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'3', u'3', u'1', u'2', u'1', u'4', u'2', u'5', u'3', u'3']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " parseMovieData.map(lambda x:x[1]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostPopularMovie = parseMovieData.reduceByKey(lambda x,y:x + y).sortByKey(False) #to sort in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(943,\n",
       "  u'444142445524454523214254435414443344435344344544524145135432424152535254555235443454255445241235534233533244123242154442525322414145131345441424144445245353331344214342'),\n",
       " (942,\n",
       "  u'4445454334533245554554544534455553544334444555445455455454434534535555544355554'),\n",
       " (941, u'4555444444422355453544'),\n",
       " (940,\n",
       "  u'33334444335543525141145422324353453324534122434343342343444345333444434444355324433435423453441324445444324'),\n",
       " (939, u'2344554554545323545555555255545455525533444535455'),\n",
       " (938,\n",
       "  u'415233214443215332524542223423355341331354343244533345341555431413544334253323344253433325541145451432533135'),\n",
       " (937, u'4541544344144445444341343245143324431441'),\n",
       " (936,\n",
       "  u'2444344445344545435442335544445455533124453254223443534344433255532345444144243334145434353444424534454424335554533424434434543354554554433443'),\n",
       " (935, u'443444425454454445541444534443452454344'),\n",
       " (934,\n",
       "  u'532134553543224444545444314453334425325553443544335455444454423544444443454424144534553344443344424114345334354444444544423444344442334434422234445534534444345345444444444411')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMovie.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Movie Name instead of Movie Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath1 = \"file:///home/icpl12900/Desktop/assignments/ml-100k/u.item\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieData = sc.textFile(filepath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseMovieData(row):\n",
    "    row = row.split('|')\n",
    "    MovieId = int(row[0])\n",
    "    MovieName = row[1]\n",
    "    return(MovieId,MovieName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieParseData = movieData.map(parseMovieData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'Toy Story (1995)'),\n",
       " (2, u'GoldenEye (1995)'),\n",
       " (3, u'Four Rooms (1995)'),\n",
       " (4, u'Get Shorty (1995)'),\n",
       " (5, u'Copycat (1995)'),\n",
       " (6, u'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)'),\n",
       " (7, u'Twelve Monkeys (1995)'),\n",
       " (8, u'Babe (1995)'),\n",
       " (9, u'Dead Man Walking (1995)'),\n",
       " (10, u'Richard III (1995)')]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieParseData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MovieDictionary = movieParseData.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: u'Toy Story (1995)',\n",
       " 2: u'GoldenEye (1995)',\n",
       " 3: u'Four Rooms (1995)',\n",
       " 4: u'Get Shorty (1995)',\n",
       " 5: u'Copycat (1995)',\n",
       " 6: u'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)',\n",
       " 7: u'Twelve Monkeys (1995)',\n",
       " 8: u'Babe (1995)',\n",
       " 9: u'Dead Man Walking (1995)',\n",
       " 10: u'Richard III (1995)',\n",
       " 11: u'Seven (Se7en) (1995)',\n",
       " 12: u'Usual Suspects, The (1995)',\n",
       " 13: u'Mighty Aphrodite (1995)',\n",
       " 14: u'Postino, Il (1994)',\n",
       " 15: u\"Mr. Holland's Opus (1995)\",\n",
       " 16: u'French Twist (Gazon maudit) (1995)',\n",
       " 17: u'From Dusk Till Dawn (1996)',\n",
       " 18: u'White Balloon, The (1995)',\n",
       " 19: u\"Antonia's Line (1995)\",\n",
       " 20: u'Angels and Insects (1995)',\n",
       " 21: u'Muppet Treasure Island (1996)',\n",
       " 22: u'Braveheart (1995)',\n",
       " 23: u'Taxi Driver (1976)',\n",
       " 24: u'Rumble in the Bronx (1995)',\n",
       " 25: u'Birdcage, The (1996)',\n",
       " 26: u'Brothers McMullen, The (1995)',\n",
       " 27: u'Bad Boys (1995)',\n",
       " 28: u'Apollo 13 (1995)',\n",
       " 29: u'Batman Forever (1995)',\n",
       " 30: u'Belle de jour (1967)',\n",
       " 31: u'Crimson Tide (1995)',\n",
       " 32: u'Crumb (1994)',\n",
       " 33: u'Desperado (1995)',\n",
       " 34: u'Doom Generation, The (1995)',\n",
       " 35: u'Free Willy 2: The Adventure Home (1995)',\n",
       " 36: u'Mad Love (1995)',\n",
       " 37: u'Nadja (1994)',\n",
       " 38: u'Net, The (1995)',\n",
       " 39: u'Strange Days (1995)',\n",
       " 40: u'To Wong Foo, Thanks for Everything! Julie Newmar (1995)',\n",
       " 41: u'Billy Madison (1995)',\n",
       " 42: u'Clerks (1994)',\n",
       " 43: u'Disclosure (1994)',\n",
       " 44: u'Dolores Claiborne (1994)',\n",
       " 45: u'Eat Drink Man Woman (1994)',\n",
       " 46: u'Exotica (1994)',\n",
       " 47: u'Ed Wood (1994)',\n",
       " 48: u'Hoop Dreams (1994)',\n",
       " 49: u'I.Q. (1994)',\n",
       " 50: u'Star Wars (1977)',\n",
       " 51: u'Legends of the Fall (1994)',\n",
       " 52: u'Madness of King George, The (1994)',\n",
       " 53: u'Natural Born Killers (1994)',\n",
       " 54: u'Outbreak (1995)',\n",
       " 55: u'Professional, The (1994)',\n",
       " 56: u'Pulp Fiction (1994)',\n",
       " 57: u'Priest (1994)',\n",
       " 58: u'Quiz Show (1994)',\n",
       " 59: u'Three Colors: Red (1994)',\n",
       " 60: u'Three Colors: Blue (1993)',\n",
       " 61: u'Three Colors: White (1994)',\n",
       " 62: u'Stargate (1994)',\n",
       " 63: u'Santa Clause, The (1994)',\n",
       " 64: u'Shawshank Redemption, The (1994)',\n",
       " 65: u\"What's Eating Gilbert Grape (1993)\",\n",
       " 66: u'While You Were Sleeping (1995)',\n",
       " 67: u'Ace Ventura: Pet Detective (1994)',\n",
       " 68: u'Crow, The (1994)',\n",
       " 69: u'Forrest Gump (1994)',\n",
       " 70: u'Four Weddings and a Funeral (1994)',\n",
       " 71: u'Lion King, The (1994)',\n",
       " 72: u'Mask, The (1994)',\n",
       " 73: u'Maverick (1994)',\n",
       " 74: u'Faster Pussycat! Kill! Kill! (1965)',\n",
       " 75: u'Brother Minister: The Assassination of Malcolm X (1994)',\n",
       " 76: u\"Carlito's Way (1993)\",\n",
       " 77: u'Firm, The (1993)',\n",
       " 78: u'Free Willy (1993)',\n",
       " 79: u'Fugitive, The (1993)',\n",
       " 80: u'Hot Shots! Part Deux (1993)',\n",
       " 81: u'Hudsucker Proxy, The (1994)',\n",
       " 82: u'Jurassic Park (1993)',\n",
       " 83: u'Much Ado About Nothing (1993)',\n",
       " 84: u\"Robert A. Heinlein's The Puppet Masters (1994)\",\n",
       " 85: u'Ref, The (1994)',\n",
       " 86: u'Remains of the Day, The (1993)',\n",
       " 87: u'Searching for Bobby Fischer (1993)',\n",
       " 88: u'Sleepless in Seattle (1993)',\n",
       " 89: u'Blade Runner (1982)',\n",
       " 90: u'So I Married an Axe Murderer (1993)',\n",
       " 91: u'Nightmare Before Christmas, The (1993)',\n",
       " 92: u'True Romance (1993)',\n",
       " 93: u'Welcome to the Dollhouse (1995)',\n",
       " 94: u'Home Alone (1990)',\n",
       " 95: u'Aladdin (1992)',\n",
       " 96: u'Terminator 2: Judgment Day (1991)',\n",
       " 97: u'Dances with Wolves (1990)',\n",
       " 98: u'Silence of the Lambs, The (1991)',\n",
       " 99: u'Snow White and the Seven Dwarfs (1937)',\n",
       " 100: u'Fargo (1996)',\n",
       " 101: u'Heavy Metal (1981)',\n",
       " 102: u'Aristocats, The (1970)',\n",
       " 103: u'All Dogs Go to Heaven 2 (1996)',\n",
       " 104: u'Theodore Rex (1995)',\n",
       " 105: u'Sgt. Bilko (1996)',\n",
       " 106: u'Diabolique (1996)',\n",
       " 107: u'Moll Flanders (1996)',\n",
       " 108: u'Kids in the Hall: Brain Candy (1996)',\n",
       " 109: u'Mystery Science Theater 3000: The Movie (1996)',\n",
       " 110: u'Operation Dumbo Drop (1995)',\n",
       " 111: u'Truth About Cats & Dogs, The (1996)',\n",
       " 112: u'Flipper (1996)',\n",
       " 113: u'Horseman on the Roof, The (Hussard sur le toit, Le) (1995)',\n",
       " 114: u'Wallace & Gromit: The Best of Aardman Animation (1996)',\n",
       " 115: u'Haunted World of Edward D. Wood Jr., The (1995)',\n",
       " 116: u'Cold Comfort Farm (1995)',\n",
       " 117: u'Rock, The (1996)',\n",
       " 118: u'Twister (1996)',\n",
       " 119: u'Maya Lin: A Strong Clear Vision (1994)',\n",
       " 120: u'Striptease (1996)',\n",
       " 121: u'Independence Day (ID4) (1996)',\n",
       " 122: u'Cable Guy, The (1996)',\n",
       " 123: u'Frighteners, The (1996)',\n",
       " 124: u'Lone Star (1996)',\n",
       " 125: u'Phenomenon (1996)',\n",
       " 126: u'Spitfire Grill, The (1996)',\n",
       " 127: u'Godfather, The (1972)',\n",
       " 128: u'Supercop (1992)',\n",
       " 129: u'Bound (1996)',\n",
       " 130: u'Kansas City (1996)',\n",
       " 131: u\"Breakfast at Tiffany's (1961)\",\n",
       " 132: u'Wizard of Oz, The (1939)',\n",
       " 133: u'Gone with the Wind (1939)',\n",
       " 134: u'Citizen Kane (1941)',\n",
       " 135: u'2001: A Space Odyssey (1968)',\n",
       " 136: u'Mr. Smith Goes to Washington (1939)',\n",
       " 137: u'Big Night (1996)',\n",
       " 138: u'D3: The Mighty Ducks (1996)',\n",
       " 139: u'Love Bug, The (1969)',\n",
       " 140: u'Homeward Bound: The Incredible Journey (1993)',\n",
       " 141: u'20,000 Leagues Under the Sea (1954)',\n",
       " 142: u'Bedknobs and Broomsticks (1971)',\n",
       " 143: u'Sound of Music, The (1965)',\n",
       " 144: u'Die Hard (1988)',\n",
       " 145: u'Lawnmower Man, The (1992)',\n",
       " 146: u'Unhook the Stars (1996)',\n",
       " 147: u'Long Kiss Goodnight, The (1996)',\n",
       " 148: u'Ghost and the Darkness, The (1996)',\n",
       " 149: u'Jude (1996)',\n",
       " 150: u'Swingers (1996)',\n",
       " 151: u'Willy Wonka and the Chocolate Factory (1971)',\n",
       " 152: u'Sleeper (1973)',\n",
       " 153: u'Fish Called Wanda, A (1988)',\n",
       " 154: u\"Monty Python's Life of Brian (1979)\",\n",
       " 155: u'Dirty Dancing (1987)',\n",
       " 156: u'Reservoir Dogs (1992)',\n",
       " 157: u'Platoon (1986)',\n",
       " 158: u\"Weekend at Bernie's (1989)\",\n",
       " 159: u'Basic Instinct (1992)',\n",
       " 160: u'Glengarry Glen Ross (1992)',\n",
       " 161: u'Top Gun (1986)',\n",
       " 162: u'On Golden Pond (1981)',\n",
       " 163: u'Return of the Pink Panther, The (1974)',\n",
       " 164: u'Abyss, The (1989)',\n",
       " 165: u'Jean de Florette (1986)',\n",
       " 166: u'Manon of the Spring (Manon des sources) (1986)',\n",
       " 167: u'Private Benjamin (1980)',\n",
       " 168: u'Monty Python and the Holy Grail (1974)',\n",
       " 169: u'Wrong Trousers, The (1993)',\n",
       " 170: u'Cinema Paradiso (1988)',\n",
       " 171: u'Delicatessen (1991)',\n",
       " 172: u'Empire Strikes Back, The (1980)',\n",
       " 173: u'Princess Bride, The (1987)',\n",
       " 174: u'Raiders of the Lost Ark (1981)',\n",
       " 175: u'Brazil (1985)',\n",
       " 176: u'Aliens (1986)',\n",
       " 177: u'Good, The Bad and The Ugly, The (1966)',\n",
       " 178: u'12 Angry Men (1957)',\n",
       " 179: u'Clockwork Orange, A (1971)',\n",
       " 180: u'Apocalypse Now (1979)',\n",
       " 181: u'Return of the Jedi (1983)',\n",
       " 182: u'GoodFellas (1990)',\n",
       " 183: u'Alien (1979)',\n",
       " 184: u'Army of Darkness (1993)',\n",
       " 185: u'Psycho (1960)',\n",
       " 186: u'Blues Brothers, The (1980)',\n",
       " 187: u'Godfather: Part II, The (1974)',\n",
       " 188: u'Full Metal Jacket (1987)',\n",
       " 189: u'Grand Day Out, A (1992)',\n",
       " 190: u'Henry V (1989)',\n",
       " 191: u'Amadeus (1984)',\n",
       " 192: u'Raging Bull (1980)',\n",
       " 193: u'Right Stuff, The (1983)',\n",
       " 194: u'Sting, The (1973)',\n",
       " 195: u'Terminator, The (1984)',\n",
       " 196: u'Dead Poets Society (1989)',\n",
       " 197: u'Graduate, The (1967)',\n",
       " 198: u'Nikita (La Femme Nikita) (1990)',\n",
       " 199: u'Bridge on the River Kwai, The (1957)',\n",
       " 200: u'Shining, The (1980)',\n",
       " 201: u'Evil Dead II (1987)',\n",
       " 202: u'Groundhog Day (1993)',\n",
       " 203: u'Unforgiven (1992)',\n",
       " 204: u'Back to the Future (1985)',\n",
       " 205: u'Patton (1970)',\n",
       " 206: u'Akira (1988)',\n",
       " 207: u'Cyrano de Bergerac (1990)',\n",
       " 208: u'Young Frankenstein (1974)',\n",
       " 209: u'This Is Spinal Tap (1984)',\n",
       " 210: u'Indiana Jones and the Last Crusade (1989)',\n",
       " 211: u'M*A*S*H (1970)',\n",
       " 212: u'Unbearable Lightness of Being, The (1988)',\n",
       " 213: u'Room with a View, A (1986)',\n",
       " 214: u'Pink Floyd - The Wall (1982)',\n",
       " 215: u'Field of Dreams (1989)',\n",
       " 216: u'When Harry Met Sally... (1989)',\n",
       " 217: u\"Bram Stoker's Dracula (1992)\",\n",
       " 218: u'Cape Fear (1991)',\n",
       " 219: u'Nightmare on Elm Street, A (1984)',\n",
       " 220: u'Mirror Has Two Faces, The (1996)',\n",
       " 221: u'Breaking the Waves (1996)',\n",
       " 222: u'Star Trek: First Contact (1996)',\n",
       " 223: u'Sling Blade (1996)',\n",
       " 224: u'Ridicule (1996)',\n",
       " 225: u'101 Dalmatians (1996)',\n",
       " 226: u'Die Hard 2 (1990)',\n",
       " 227: u'Star Trek VI: The Undiscovered Country (1991)',\n",
       " 228: u'Star Trek: The Wrath of Khan (1982)',\n",
       " 229: u'Star Trek III: The Search for Spock (1984)',\n",
       " 230: u'Star Trek IV: The Voyage Home (1986)',\n",
       " 231: u'Batman Returns (1992)',\n",
       " 232: u'Young Guns (1988)',\n",
       " 233: u'Under Siege (1992)',\n",
       " 234: u'Jaws (1975)',\n",
       " 235: u'Mars Attacks! (1996)',\n",
       " 236: u'Citizen Ruth (1996)',\n",
       " 237: u'Jerry Maguire (1996)',\n",
       " 238: u'Raising Arizona (1987)',\n",
       " 239: u'Sneakers (1992)',\n",
       " 240: u'Beavis and Butt-head Do America (1996)',\n",
       " 241: u'Last of the Mohicans, The (1992)',\n",
       " 242: u'Kolya (1996)',\n",
       " 243: u'Jungle2Jungle (1997)',\n",
       " 244: u\"Smilla's Sense of Snow (1997)\",\n",
       " 245: u\"Devil's Own, The (1997)\",\n",
       " 246: u'Chasing Amy (1997)',\n",
       " 247: u'Turbo: A Power Rangers Movie (1997)',\n",
       " 248: u'Grosse Pointe Blank (1997)',\n",
       " 249: u'Austin Powers: International Man of Mystery (1997)',\n",
       " 250: u'Fifth Element, The (1997)',\n",
       " 251: u'Shall We Dance? (1996)',\n",
       " 252: u'Lost World: Jurassic Park, The (1997)',\n",
       " 253: u'Pillow Book, The (1995)',\n",
       " 254: u'Batman & Robin (1997)',\n",
       " 255: u\"My Best Friend's Wedding (1997)\",\n",
       " 256: u'When the Cats Away (Chacun cherche son chat) (1996)',\n",
       " 257: u'Men in Black (1997)',\n",
       " 258: u'Contact (1997)',\n",
       " 259: u'George of the Jungle (1997)',\n",
       " 260: u'Event Horizon (1997)',\n",
       " 261: u'Air Bud (1997)',\n",
       " 262: u'In the Company of Men (1997)',\n",
       " 263: u'Steel (1997)',\n",
       " 264: u'Mimic (1997)',\n",
       " 265: u'Hunt for Red October, The (1990)',\n",
       " 266: u'Kull the Conqueror (1997)',\n",
       " 267: u'unknown',\n",
       " 268: u'Chasing Amy (1997)',\n",
       " 269: u'Full Monty, The (1997)',\n",
       " 270: u'Gattaca (1997)',\n",
       " 271: u'Starship Troopers (1997)',\n",
       " 272: u'Good Will Hunting (1997)',\n",
       " 273: u'Heat (1995)',\n",
       " 274: u'Sabrina (1995)',\n",
       " 275: u'Sense and Sensibility (1995)',\n",
       " 276: u'Leaving Las Vegas (1995)',\n",
       " 277: u'Restoration (1995)',\n",
       " 278: u'Bed of Roses (1996)',\n",
       " 279: u'Once Upon a Time... When We Were Colored (1995)',\n",
       " 280: u'Up Close and Personal (1996)',\n",
       " 281: u'River Wild, The (1994)',\n",
       " 282: u'Time to Kill, A (1996)',\n",
       " 283: u'Emma (1996)',\n",
       " 284: u'Tin Cup (1996)',\n",
       " 285: u'Secrets & Lies (1996)',\n",
       " 286: u'English Patient, The (1996)',\n",
       " 287: u\"Marvin's Room (1996)\",\n",
       " 288: u'Scream (1996)',\n",
       " 289: u'Evita (1996)',\n",
       " 290: u'Fierce Creatures (1997)',\n",
       " 291: u'Absolute Power (1997)',\n",
       " 292: u'Rosewood (1997)',\n",
       " 293: u'Donnie Brasco (1997)',\n",
       " 294: u'Liar Liar (1997)',\n",
       " 295: u'Breakdown (1997)',\n",
       " 296: u'Promesse, La (1996)',\n",
       " 297: u\"Ulee's Gold (1997)\",\n",
       " 298: u'Face/Off (1997)',\n",
       " 299: u'Hoodlum (1997)',\n",
       " 300: u'Air Force One (1997)',\n",
       " 301: u'In & Out (1997)',\n",
       " 302: u'L.A. Confidential (1997)',\n",
       " 303: u\"Ulee's Gold (1997)\",\n",
       " 304: u'Fly Away Home (1996)',\n",
       " 305: u'Ice Storm, The (1997)',\n",
       " 306: u'Mrs. Brown (Her Majesty, Mrs. Brown) (1997)',\n",
       " 307: u\"Devil's Advocate, The (1997)\",\n",
       " 308: u'FairyTale: A True Story (1997)',\n",
       " 309: u'Deceiver (1997)',\n",
       " 310: u'Rainmaker, The (1997)',\n",
       " 311: u'Wings of the Dove, The (1997)',\n",
       " 312: u'Midnight in the Garden of Good and Evil (1997)',\n",
       " 313: u'Titanic (1997)',\n",
       " 314: u'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       " 315: u'Apt Pupil (1998)',\n",
       " 316: u'As Good As It Gets (1997)',\n",
       " 317: u'In the Name of the Father (1993)',\n",
       " 318: u\"Schindler's List (1993)\",\n",
       " 319: u'Everyone Says I Love You (1996)',\n",
       " 320: u'Paradise Lost: The Child Murders at Robin Hood Hills (1996)',\n",
       " 321: u'Mother (1996)',\n",
       " 322: u'Murder at 1600 (1997)',\n",
       " 323: u\"Dante's Peak (1997)\",\n",
       " 324: u'Lost Highway (1997)',\n",
       " 325: u'Crash (1996)',\n",
       " 326: u'G.I. Jane (1997)',\n",
       " 327: u'Cop Land (1997)',\n",
       " 328: u'Conspiracy Theory (1997)',\n",
       " 329: u'Desperate Measures (1998)',\n",
       " 330: u'187 (1997)',\n",
       " 331: u'Edge, The (1997)',\n",
       " 332: u'Kiss the Girls (1997)',\n",
       " 333: u'Game, The (1997)',\n",
       " 334: u'U Turn (1997)',\n",
       " 335: u'How to Be a Player (1997)',\n",
       " 336: u'Playing God (1997)',\n",
       " 337: u'House of Yes, The (1997)',\n",
       " 338: u'Bean (1997)',\n",
       " 339: u'Mad City (1997)',\n",
       " 340: u'Boogie Nights (1997)',\n",
       " 341: u'Critical Care (1997)',\n",
       " 342: u'Man Who Knew Too Little, The (1997)',\n",
       " 343: u'Alien: Resurrection (1997)',\n",
       " 344: u'Apostle, The (1997)',\n",
       " 345: u'Deconstructing Harry (1997)',\n",
       " 346: u'Jackie Brown (1997)',\n",
       " 347: u'Wag the Dog (1997)',\n",
       " 348: u'Desperate Measures (1998)',\n",
       " 349: u'Hard Rain (1998)',\n",
       " 350: u'Fallen (1998)',\n",
       " 351: u'Prophecy II, The (1998)',\n",
       " 352: u'Spice World (1997)',\n",
       " 353: u'Deep Rising (1998)',\n",
       " 354: u'Wedding Singer, The (1998)',\n",
       " 355: u'Sphere (1998)',\n",
       " 356: u'Client, The (1994)',\n",
       " 357: u\"One Flew Over the Cuckoo's Nest (1975)\",\n",
       " 358: u'Spawn (1997)',\n",
       " 359: u'Assignment, The (1997)',\n",
       " 360: u'Wonderland (1997)',\n",
       " 361: u'Incognito (1997)',\n",
       " 362: u'Blues Brothers 2000 (1998)',\n",
       " 363: u'Sudden Death (1995)',\n",
       " 364: u'Ace Ventura: When Nature Calls (1995)',\n",
       " 365: u'Powder (1995)',\n",
       " 366: u'Dangerous Minds (1995)',\n",
       " 367: u'Clueless (1995)',\n",
       " 368: u'Bio-Dome (1996)',\n",
       " 369: u'Black Sheep (1996)',\n",
       " 370: u'Mary Reilly (1996)',\n",
       " 371: u'Bridges of Madison County, The (1995)',\n",
       " 372: u'Jeffrey (1995)',\n",
       " 373: u'Judge Dredd (1995)',\n",
       " 374: u'Mighty Morphin Power Rangers: The Movie (1995)',\n",
       " 375: u'Showgirls (1995)',\n",
       " 376: u'Houseguest (1994)',\n",
       " 377: u'Heavyweights (1994)',\n",
       " 378: u'Miracle on 34th Street (1994)',\n",
       " 379: u'Tales From the Crypt Presents: Demon Knight (1995)',\n",
       " 380: u'Star Trek: Generations (1994)',\n",
       " 381: u\"Muriel's Wedding (1994)\",\n",
       " 382: u'Adventures of Priscilla, Queen of the Desert, The (1994)',\n",
       " 383: u'Flintstones, The (1994)',\n",
       " 384: u'Naked Gun 33 1/3: The Final Insult (1994)',\n",
       " 385: u'True Lies (1994)',\n",
       " 386: u'Addams Family Values (1993)',\n",
       " 387: u'Age of Innocence, The (1993)',\n",
       " 388: u'Beverly Hills Cop III (1994)',\n",
       " 389: u'Black Beauty (1994)',\n",
       " 390: u'Fear of a Black Hat (1993)',\n",
       " 391: u'Last Action Hero (1993)',\n",
       " 392: u'Man Without a Face, The (1993)',\n",
       " 393: u'Mrs. Doubtfire (1993)',\n",
       " 394: u'Radioland Murders (1994)',\n",
       " 395: u'Robin Hood: Men in Tights (1993)',\n",
       " 396: u'Serial Mom (1994)',\n",
       " 397: u'Striking Distance (1993)',\n",
       " 398: u'Super Mario Bros. (1993)',\n",
       " 399: u'Three Musketeers, The (1993)',\n",
       " 400: u'Little Rascals, The (1994)',\n",
       " 401: u'Brady Bunch Movie, The (1995)',\n",
       " 402: u'Ghost (1990)',\n",
       " 403: u'Batman (1989)',\n",
       " 404: u'Pinocchio (1940)',\n",
       " 405: u'Mission: Impossible (1996)',\n",
       " 406: u'Thinner (1996)',\n",
       " 407: u'Spy Hard (1996)',\n",
       " 408: u'Close Shave, A (1995)',\n",
       " 409: u'Jack (1996)',\n",
       " 410: u'Kingpin (1996)',\n",
       " 411: u'Nutty Professor, The (1996)',\n",
       " 412: u'Very Brady Sequel, A (1996)',\n",
       " 413: u'Tales from the Crypt Presents: Bordello of Blood (1996)',\n",
       " 414: u'My Favorite Year (1982)',\n",
       " 415: u'Apple Dumpling Gang, The (1975)',\n",
       " 416: u'Old Yeller (1957)',\n",
       " 417: u'Parent Trap, The (1961)',\n",
       " 418: u'Cinderella (1950)',\n",
       " 419: u'Mary Poppins (1964)',\n",
       " 420: u'Alice in Wonderland (1951)',\n",
       " 421: u\"William Shakespeare's Romeo and Juliet (1996)\",\n",
       " 422: u'Aladdin and the King of Thieves (1996)',\n",
       " 423: u'E.T. the Extra-Terrestrial (1982)',\n",
       " 424: u'Children of the Corn: The Gathering (1996)',\n",
       " 425: u'Bob Roberts (1992)',\n",
       " 426: u'Transformers: The Movie, The (1986)',\n",
       " 427: u'To Kill a Mockingbird (1962)',\n",
       " 428: u'Harold and Maude (1971)',\n",
       " 429: u'Day the Earth Stood Still, The (1951)',\n",
       " 430: u'Duck Soup (1933)',\n",
       " 431: u'Highlander (1986)',\n",
       " 432: u'Fantasia (1940)',\n",
       " 433: u'Heathers (1989)',\n",
       " 434: u'Forbidden Planet (1956)',\n",
       " 435: u'Butch Cassidy and the Sundance Kid (1969)',\n",
       " 436: u'American Werewolf in London, An (1981)',\n",
       " 437: u\"Amityville 1992: It's About Time (1992)\",\n",
       " 438: u'Amityville 3-D (1983)',\n",
       " 439: u'Amityville: A New Generation (1993)',\n",
       " 440: u'Amityville II: The Possession (1982)',\n",
       " 441: u'Amityville Horror, The (1979)',\n",
       " 442: u'Amityville Curse, The (1990)',\n",
       " 443: u'Birds, The (1963)',\n",
       " 444: u'Blob, The (1958)',\n",
       " 445: u'Body Snatcher, The (1945)',\n",
       " 446: u'Burnt Offerings (1976)',\n",
       " 447: u'Carrie (1976)',\n",
       " 448: u'Omen, The (1976)',\n",
       " 449: u'Star Trek: The Motion Picture (1979)',\n",
       " 450: u'Star Trek V: The Final Frontier (1989)',\n",
       " 451: u'Grease (1978)',\n",
       " 452: u'Jaws 2 (1978)',\n",
       " 453: u'Jaws 3-D (1983)',\n",
       " 454: u'Bastard Out of Carolina (1996)',\n",
       " 455: u\"Jackie Chan's First Strike (1996)\",\n",
       " 456: u'Beverly Hills Ninja (1997)',\n",
       " 457: u'Free Willy 3: The Rescue (1997)',\n",
       " 458: u'Nixon (1995)',\n",
       " 459: u'Cry, the Beloved Country (1995)',\n",
       " 460: u'Crossing Guard, The (1995)',\n",
       " 461: u'Smoke (1995)',\n",
       " 462: u'Like Water For Chocolate (Como agua para chocolate) (1992)',\n",
       " 463: u'Secret of Roan Inish, The (1994)',\n",
       " 464: u'Vanya on 42nd Street (1994)',\n",
       " 465: u'Jungle Book, The (1994)',\n",
       " 466: u'Red Rock West (1992)',\n",
       " 467: u'Bronx Tale, A (1993)',\n",
       " 468: u'Rudy (1993)',\n",
       " 469: u'Short Cuts (1993)',\n",
       " 470: u'Tombstone (1993)',\n",
       " 471: u'Courage Under Fire (1996)',\n",
       " 472: u'Dragonheart (1996)',\n",
       " 473: u'James and the Giant Peach (1996)',\n",
       " 474: u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)',\n",
       " 475: u'Trainspotting (1996)',\n",
       " 476: u'First Wives Club, The (1996)',\n",
       " 477: u'Matilda (1996)',\n",
       " 478: u'Philadelphia Story, The (1940)',\n",
       " 479: u'Vertigo (1958)',\n",
       " 480: u'North by Northwest (1959)',\n",
       " 481: u'Apartment, The (1960)',\n",
       " 482: u'Some Like It Hot (1959)',\n",
       " 483: u'Casablanca (1942)',\n",
       " 484: u'Maltese Falcon, The (1941)',\n",
       " 485: u'My Fair Lady (1964)',\n",
       " 486: u'Sabrina (1954)',\n",
       " 487: u'Roman Holiday (1953)',\n",
       " 488: u'Sunset Blvd. (1950)',\n",
       " 489: u'Notorious (1946)',\n",
       " 490: u'To Catch a Thief (1955)',\n",
       " 491: u'Adventures of Robin Hood, The (1938)',\n",
       " 492: u'East of Eden (1955)',\n",
       " 493: u'Thin Man, The (1934)',\n",
       " 494: u'His Girl Friday (1940)',\n",
       " 495: u'Around the World in 80 Days (1956)',\n",
       " 496: u\"It's a Wonderful Life (1946)\",\n",
       " 497: u'Bringing Up Baby (1938)',\n",
       " 498: u'African Queen, The (1951)',\n",
       " 499: u'Cat on a Hot Tin Roof (1958)',\n",
       " 500: u'Fly Away Home (1996)',\n",
       " 501: u'Dumbo (1941)',\n",
       " 502: u'Bananas (1971)',\n",
       " 503: u'Candidate, The (1972)',\n",
       " 504: u'Bonnie and Clyde (1967)',\n",
       " 505: u'Dial M for Murder (1954)',\n",
       " 506: u'Rebel Without a Cause (1955)',\n",
       " 507: u'Streetcar Named Desire, A (1951)',\n",
       " 508: u'People vs. Larry Flynt, The (1996)',\n",
       " 509: u'My Left Foot (1989)',\n",
       " 510: u'Magnificent Seven, The (1954)',\n",
       " 511: u'Lawrence of Arabia (1962)',\n",
       " 512: u'Wings of Desire (1987)',\n",
       " 513: u'Third Man, The (1949)',\n",
       " 514: u'Annie Hall (1977)',\n",
       " 515: u'Boot, Das (1981)',\n",
       " 516: u'Local Hero (1983)',\n",
       " 517: u'Manhattan (1979)',\n",
       " 518: u\"Miller's Crossing (1990)\",\n",
       " 519: u'Treasure of the Sierra Madre, The (1948)',\n",
       " 520: u'Great Escape, The (1963)',\n",
       " 521: u'Deer Hunter, The (1978)',\n",
       " 522: u'Down by Law (1986)',\n",
       " 523: u'Cool Hand Luke (1967)',\n",
       " 524: u'Great Dictator, The (1940)',\n",
       " 525: u'Big Sleep, The (1946)',\n",
       " 526: u'Ben-Hur (1959)',\n",
       " 527: u'Gandhi (1982)',\n",
       " 528: u'Killing Fields, The (1984)',\n",
       " 529: u'My Life as a Dog (Mitt liv som hund) (1985)',\n",
       " 530: u'Man Who Would Be King, The (1975)',\n",
       " 531: u'Shine (1996)',\n",
       " 532: u'Kama Sutra: A Tale of Love (1996)',\n",
       " 533: u'Daytrippers, The (1996)',\n",
       " 534: u'Traveller (1997)',\n",
       " 535: u'Addicted to Love (1997)',\n",
       " 536: u'Ponette (1996)',\n",
       " 537: u'My Own Private Idaho (1991)',\n",
       " 538: u'Anastasia (1997)',\n",
       " 539: u'Mouse Hunt (1997)',\n",
       " 540: u'Money Train (1995)',\n",
       " 541: u'Mortal Kombat (1995)',\n",
       " 542: u'Pocahontas (1995)',\n",
       " 543: u'Mis\\ufffdrables, Les (1995)',\n",
       " 544: u\"Things to Do in Denver when You're Dead (1995)\",\n",
       " 545: u'Vampire in Brooklyn (1995)',\n",
       " 546: u'Broken Arrow (1996)',\n",
       " 547: u\"Young Poisoner's Handbook, The (1995)\",\n",
       " 548: u'NeverEnding Story III, The (1994)',\n",
       " 549: u'Rob Roy (1995)',\n",
       " 550: u'Die Hard: With a Vengeance (1995)',\n",
       " 551: u'Lord of Illusions (1995)',\n",
       " 552: u'Species (1995)',\n",
       " 553: u'Walk in the Clouds, A (1995)',\n",
       " 554: u'Waterworld (1995)',\n",
       " 555: u\"White Man's Burden (1995)\",\n",
       " 556: u'Wild Bill (1995)',\n",
       " 557: u'Farinelli: il castrato (1994)',\n",
       " 558: u'Heavenly Creatures (1994)',\n",
       " 559: u'Interview with the Vampire (1994)',\n",
       " 560: u\"Kid in King Arthur's Court, A (1995)\",\n",
       " 561: u\"Mary Shelley's Frankenstein (1994)\",\n",
       " 562: u'Quick and the Dead, The (1995)',\n",
       " 563: u\"Stephen King's The Langoliers (1995)\",\n",
       " 564: u'Tales from the Hood (1995)',\n",
       " 565: u'Village of the Damned (1995)',\n",
       " 566: u'Clear and Present Danger (1994)',\n",
       " 567: u\"Wes Craven's New Nightmare (1994)\",\n",
       " 568: u'Speed (1994)',\n",
       " 569: u'Wolf (1994)',\n",
       " 570: u'Wyatt Earp (1994)',\n",
       " 571: u'Another Stakeout (1993)',\n",
       " 572: u'Blown Away (1994)',\n",
       " 573: u'Body Snatchers (1993)',\n",
       " 574: u'Boxing Helena (1993)',\n",
       " 575: u\"City Slickers II: The Legend of Curly's Gold (1994)\",\n",
       " 576: u'Cliffhanger (1993)',\n",
       " 577: u'Coneheads (1993)',\n",
       " 578: u'Demolition Man (1993)',\n",
       " 579: u'Fatal Instinct (1993)',\n",
       " 580: u'Englishman Who Went Up a Hill, But Came Down a Mountain, The (1995)',\n",
       " 581: u'Kalifornia (1993)',\n",
       " 582: u'Piano, The (1993)',\n",
       " 583: u'Romeo Is Bleeding (1993)',\n",
       " 584: u'Secret Garden, The (1993)',\n",
       " 585: u'Son in Law (1993)',\n",
       " 586: u'Terminal Velocity (1994)',\n",
       " 587: u'Hour of the Pig, The (1993)',\n",
       " 588: u'Beauty and the Beast (1991)',\n",
       " 589: u'Wild Bunch, The (1969)',\n",
       " 590: u'Hellraiser: Bloodline (1996)',\n",
       " 591: u'Primal Fear (1996)',\n",
       " 592: u'True Crime (1995)',\n",
       " 593: u'Stalingrad (1993)',\n",
       " 594: u'Heavy (1995)',\n",
       " 595: u'Fan, The (1996)',\n",
       " 596: u'Hunchback of Notre Dame, The (1996)',\n",
       " 597: u'Eraser (1996)',\n",
       " 598: u'Big Squeeze, The (1996)',\n",
       " 599: u'Police Story 4: Project S (Chao ji ji hua) (1993)',\n",
       " 600: u\"Daniel Defoe's Robinson Crusoe (1996)\",\n",
       " 601: u'For Whom the Bell Tolls (1943)',\n",
       " 602: u'American in Paris, An (1951)',\n",
       " 603: u'Rear Window (1954)',\n",
       " 604: u'It Happened One Night (1934)',\n",
       " 605: u'Meet Me in St. Louis (1944)',\n",
       " 606: u'All About Eve (1950)',\n",
       " 607: u'Rebecca (1940)',\n",
       " 608: u'Spellbound (1945)',\n",
       " 609: u'Father of the Bride (1950)',\n",
       " 610: u'Gigi (1958)',\n",
       " 611: u'Laura (1944)',\n",
       " 612: u'Lost Horizon (1937)',\n",
       " 613: u'My Man Godfrey (1936)',\n",
       " 614: u'Giant (1956)',\n",
       " 615: u'39 Steps, The (1935)',\n",
       " 616: u'Night of the Living Dead (1968)',\n",
       " 617: u'Blue Angel, The (Blaue Engel, Der) (1930)',\n",
       " 618: u'Picnic (1955)',\n",
       " 619: u'Extreme Measures (1996)',\n",
       " 620: u'Chamber, The (1996)',\n",
       " 621: u'Davy Crockett, King of the Wild Frontier (1955)',\n",
       " 622: u'Swiss Family Robinson (1960)',\n",
       " 623: u'Angels in the Outfield (1994)',\n",
       " 624: u'Three Caballeros, The (1945)',\n",
       " 625: u'Sword in the Stone, The (1963)',\n",
       " 626: u'So Dear to My Heart (1949)',\n",
       " 627: u'Robin Hood: Prince of Thieves (1991)',\n",
       " 628: u'Sleepers (1996)',\n",
       " 629: u'Victor/Victoria (1982)',\n",
       " 630: u'Great Race, The (1965)',\n",
       " 631: u'Crying Game, The (1992)',\n",
       " 632: u\"Sophie's Choice (1982)\",\n",
       " 633: u'Christmas Carol, A (1938)',\n",
       " 634: u\"Microcosmos: Le peuple de l'herbe (1996)\",\n",
       " 635: u'Fog, The (1980)',\n",
       " 636: u'Escape from New York (1981)',\n",
       " 637: u'Howling, The (1981)',\n",
       " 638: u'Return of Martin Guerre, The (Retour de Martin Guerre, Le) (1982)',\n",
       " 639: u'Tin Drum, The (Blechtrommel, Die) (1979)',\n",
       " 640: u'Cook the Thief His Wife & Her Lover, The (1989)',\n",
       " 641: u'Paths of Glory (1957)',\n",
       " 642: u'Grifters, The (1990)',\n",
       " 643: u'The Innocent (1994)',\n",
       " 644: u'Thin Blue Line, The (1988)',\n",
       " 645: u'Paris Is Burning (1990)',\n",
       " 646: u'Once Upon a Time in the West (1969)',\n",
       " 647: u'Ran (1985)',\n",
       " 648: u'Quiet Man, The (1952)',\n",
       " 649: u'Once Upon a Time in America (1984)',\n",
       " 650: u'Seventh Seal, The (Sjunde inseglet, Det) (1957)',\n",
       " 651: u'Glory (1989)',\n",
       " 652: u'Rosencrantz and Guildenstern Are Dead (1990)',\n",
       " 653: u'Touch of Evil (1958)',\n",
       " 654: u'Chinatown (1974)',\n",
       " 655: u'Stand by Me (1986)',\n",
       " 656: u'M (1931)',\n",
       " 657: u'Manchurian Candidate, The (1962)',\n",
       " 658: u'Pump Up the Volume (1990)',\n",
       " 659: u'Arsenic and Old Lace (1944)',\n",
       " 660: u'Fried Green Tomatoes (1991)',\n",
       " 661: u'High Noon (1952)',\n",
       " 662: u'Somewhere in Time (1980)',\n",
       " 663: u'Being There (1979)',\n",
       " 664: u'Paris, Texas (1984)',\n",
       " 665: u'Alien 3 (1992)',\n",
       " 666: u\"Blood For Dracula (Andy Warhol's Dracula) (1974)\",\n",
       " 667: u'Audrey Rose (1977)',\n",
       " 668: u'Blood Beach (1981)',\n",
       " 669: u'Body Parts (1991)',\n",
       " 670: u'Body Snatchers (1993)',\n",
       " 671: u'Bride of Frankenstein (1935)',\n",
       " 672: u'Candyman (1992)',\n",
       " 673: u'Cape Fear (1962)',\n",
       " 674: u'Cat People (1982)',\n",
       " 675: u'Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922)',\n",
       " 676: u'Crucible, The (1996)',\n",
       " 677: u'Fire on the Mountain (1996)',\n",
       " 678: u'Volcano (1997)',\n",
       " 679: u'Conan the Barbarian (1981)',\n",
       " 680: u'Kull the Conqueror (1997)',\n",
       " 681: u'Wishmaster (1997)',\n",
       " 682: u'I Know What You Did Last Summer (1997)',\n",
       " 683: u'Rocket Man (1997)',\n",
       " 684: u'In the Line of Fire (1993)',\n",
       " 685: u'Executive Decision (1996)',\n",
       " 686: u'Perfect World, A (1993)',\n",
       " 687: u\"McHale's Navy (1997)\",\n",
       " 688: u'Leave It to Beaver (1997)',\n",
       " 689: u'Jackal, The (1997)',\n",
       " 690: u'Seven Years in Tibet (1997)',\n",
       " 691: u'Dark City (1998)',\n",
       " 692: u'American President, The (1995)',\n",
       " 693: u'Casino (1995)',\n",
       " 694: u'Persuasion (1995)',\n",
       " 695: u'Kicking and Screaming (1995)',\n",
       " 696: u'City Hall (1996)',\n",
       " 697: u'Basketball Diaries, The (1995)',\n",
       " 698: u'Browning Version, The (1994)',\n",
       " 699: u'Little Women (1994)',\n",
       " 700: u'Miami Rhapsody (1995)',\n",
       " 701: u'Wonderful, Horrible Life of Leni Riefenstahl, The (1993)',\n",
       " 702: u'Barcelona (1994)',\n",
       " 703: u\"Widows' Peak (1994)\",\n",
       " 704: u'House of the Spirits, The (1993)',\n",
       " 705: u\"Singin' in the Rain (1952)\",\n",
       " 706: u'Bad Moon (1996)',\n",
       " 707: u'Enchanted April (1991)',\n",
       " 708: u'Sex, Lies, and Videotape (1989)',\n",
       " 709: u'Strictly Ballroom (1992)',\n",
       " 710: u'Better Off Dead... (1985)',\n",
       " 711: u'Substance of Fire, The (1996)',\n",
       " 712: u'Tin Men (1987)',\n",
       " 713: u'Othello (1995)',\n",
       " 714: u'Carrington (1995)',\n",
       " 715: u'To Die For (1995)',\n",
       " 716: u'Home for the Holidays (1995)',\n",
       " 717: u'Juror, The (1996)',\n",
       " 718: u'In the Bleak Midwinter (1995)',\n",
       " 719: u'Canadian Bacon (1994)',\n",
       " 720: u'First Knight (1995)',\n",
       " 721: u'Mallrats (1995)',\n",
       " 722: u'Nine Months (1995)',\n",
       " 723: u'Boys on the Side (1995)',\n",
       " 724: u'Circle of Friends (1995)',\n",
       " 725: u'Exit to Eden (1994)',\n",
       " 726: u'Fluke (1995)',\n",
       " 727: u'Immortal Beloved (1994)',\n",
       " 728: u'Junior (1994)',\n",
       " 729: u'Nell (1994)',\n",
       " 730: u'Queen Margot (Reine Margot, La) (1994)',\n",
       " 731: u'Corrina, Corrina (1994)',\n",
       " 732: u'Dave (1993)',\n",
       " 733: u'Go Fish (1994)',\n",
       " 734: u'Made in America (1993)',\n",
       " 735: u'Philadelphia (1993)',\n",
       " 736: u'Shadowlands (1993)',\n",
       " 737: u'Sirens (1994)',\n",
       " 738: u'Threesome (1994)',\n",
       " 739: u'Pretty Woman (1990)',\n",
       " 740: u'Jane Eyre (1996)',\n",
       " 741: u'Last Supper, The (1995)',\n",
       " 742: u'Ransom (1996)',\n",
       " 743: u'Crow: City of Angels, The (1996)',\n",
       " 744: u'Michael Collins (1996)',\n",
       " 745: u'Ruling Class, The (1972)',\n",
       " 746: u'Real Genius (1985)',\n",
       " 747: u'Benny & Joon (1993)',\n",
       " 748: u'Saint, The (1997)',\n",
       " 749: u'MatchMaker, The (1997)',\n",
       " 750: u'Amistad (1997)',\n",
       " 751: u'Tomorrow Never Dies (1997)',\n",
       " 752: u'Replacement Killers, The (1998)',\n",
       " 753: u'Burnt By the Sun (1994)',\n",
       " 754: u'Red Corner (1997)',\n",
       " 755: u'Jumanji (1995)',\n",
       " 756: u'Father of the Bride Part II (1995)',\n",
       " 757: u'Across the Sea of Time (1995)',\n",
       " 758: u'Lawnmower Man 2: Beyond Cyberspace (1996)',\n",
       " 759: u'Fair Game (1995)',\n",
       " 760: u'Screamers (1995)',\n",
       " 761: u'Nick of Time (1995)',\n",
       " 762: u'Beautiful Girls (1996)',\n",
       " 763: u'Happy Gilmore (1996)',\n",
       " 764: u'If Lucy Fell (1996)',\n",
       " 765: u'Boomerang (1992)',\n",
       " 766: u'Man of the Year (1995)',\n",
       " 767: u'Addiction, The (1995)',\n",
       " 768: u'Casper (1995)',\n",
       " 769: u'Congo (1995)',\n",
       " 770: u'Devil in a Blue Dress (1995)',\n",
       " 771: u'Johnny Mnemonic (1995)',\n",
       " 772: u'Kids (1995)',\n",
       " 773: u'Mute Witness (1994)',\n",
       " 774: u'Prophecy, The (1995)',\n",
       " 775: u'Something to Talk About (1995)',\n",
       " 776: u'Three Wishes (1995)',\n",
       " 777: u'Castle Freak (1995)',\n",
       " 778: u'Don Juan DeMarco (1995)',\n",
       " 779: u'Drop Zone (1994)',\n",
       " 780: u'Dumb & Dumber (1994)',\n",
       " 781: u'French Kiss (1995)',\n",
       " 782: u'Little Odessa (1994)',\n",
       " 783: u'Milk Money (1994)',\n",
       " 784: u'Beyond Bedlam (1993)',\n",
       " 785: u'Only You (1994)',\n",
       " 786: u'Perez Family, The (1995)',\n",
       " 787: u'Roommates (1995)',\n",
       " 788: u'Relative Fear (1994)',\n",
       " 789: u'Swimming with Sharks (1995)',\n",
       " 790: u'Tommy Boy (1995)',\n",
       " 791: u'Baby-Sitters Club, The (1995)',\n",
       " 792: u'Bullets Over Broadway (1994)',\n",
       " 793: u'Crooklyn (1994)',\n",
       " 794: u'It Could Happen to You (1994)',\n",
       " 795: u'Richie Rich (1994)',\n",
       " 796: u'Speechless (1994)',\n",
       " 797: u'Timecop (1994)',\n",
       " 798: u'Bad Company (1995)',\n",
       " 799: u'Boys Life (1995)',\n",
       " 800: u'In the Mouth of Madness (1995)',\n",
       " 801: u'Air Up There, The (1994)',\n",
       " 802: u'Hard Target (1993)',\n",
       " 803: u'Heaven & Earth (1993)',\n",
       " 804: u'Jimmy Hollywood (1994)',\n",
       " 805: u'Manhattan Murder Mystery (1993)',\n",
       " 806: u'Menace II Society (1993)',\n",
       " 807: u'Poetic Justice (1993)',\n",
       " 808: u'Program, The (1993)',\n",
       " 809: u'Rising Sun (1993)',\n",
       " 810: u'Shadow, The (1994)',\n",
       " 811: u'Thirty-Two Short Films About Glenn Gould (1993)',\n",
       " 812: u'Andre (1994)',\n",
       " 813: u'Celluloid Closet, The (1995)',\n",
       " 814: u'Great Day in Harlem, A (1994)',\n",
       " 815: u'One Fine Day (1996)',\n",
       " 816: u'Candyman: Farewell to the Flesh (1995)',\n",
       " 817: u'Frisk (1995)',\n",
       " 818: u'Girl 6 (1996)',\n",
       " 819: u'Eddie (1996)',\n",
       " 820: u'Space Jam (1996)',\n",
       " 821: u'Mrs. Winterbourne (1996)',\n",
       " 822: u'Faces (1968)',\n",
       " 823: u'Mulholland Falls (1996)',\n",
       " 824: u'Great White Hype, The (1996)',\n",
       " 825: u'Arrival, The (1996)',\n",
       " 826: u'Phantom, The (1996)',\n",
       " 827: u'Daylight (1996)',\n",
       " 828: u'Alaska (1996)',\n",
       " 829: u'Fled (1996)',\n",
       " 830: u'Power 98 (1995)',\n",
       " 831: u'Escape from L.A. (1996)',\n",
       " 832: u'Bogus (1996)',\n",
       " 833: u'Bulletproof (1996)',\n",
       " 834: u'Halloween: The Curse of Michael Myers (1995)',\n",
       " 835: u'Gay Divorcee, The (1934)',\n",
       " 836: u'Ninotchka (1939)',\n",
       " 837: u'Meet John Doe (1941)',\n",
       " 838: u'In the Line of Duty 2 (1987)',\n",
       " 839: u'Loch Ness (1995)',\n",
       " 840: u'Last Man Standing (1996)',\n",
       " 841: u'Glimmer Man, The (1996)',\n",
       " 842: u'Pollyanna (1960)',\n",
       " 843: u'Shaggy Dog, The (1959)',\n",
       " 844: u'Freeway (1996)',\n",
       " 845: u'That Thing You Do! (1996)',\n",
       " 846: u'To Gillian on Her 37th Birthday (1996)',\n",
       " 847: u'Looking for Richard (1996)',\n",
       " 848: u'Murder, My Sweet (1944)',\n",
       " 849: u'Days of Thunder (1990)',\n",
       " 850: u'Perfect Candidate, A (1996)',\n",
       " 851: u'Two or Three Things I Know About Her (1966)',\n",
       " 852: u'Bloody Child, The (1996)',\n",
       " 853: u'Braindead (1992)',\n",
       " 854: u'Bad Taste (1987)',\n",
       " 855: u'Diva (1981)',\n",
       " 856: u'Night on Earth (1991)',\n",
       " 857: u'Paris Was a Woman (1995)',\n",
       " 858: u'Amityville: Dollhouse (1996)',\n",
       " 859: u\"April Fool's Day (1986)\",\n",
       " 860: u'Believers, The (1987)',\n",
       " 861: u'Nosferatu a Venezia (1986)',\n",
       " 862: u'Jingle All the Way (1996)',\n",
       " 863: u'Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)',\n",
       " 864: u'My Fellow Americans (1996)',\n",
       " 865: u'Ice Storm, The (1997)',\n",
       " 866: u'Michael (1996)',\n",
       " 867: u'Whole Wide World, The (1996)',\n",
       " 868: u'Hearts and Minds (1996)',\n",
       " 869: u'Fools Rush In (1997)',\n",
       " 870: u'Touch (1997)',\n",
       " 871: u'Vegas Vacation (1997)',\n",
       " 872: u'Love Jones (1997)',\n",
       " 873: u'Picture Perfect (1997)',\n",
       " 874: u'Career Girls (1997)',\n",
       " 875: u\"She's So Lovely (1997)\",\n",
       " 876: u'Money Talks (1997)',\n",
       " 877: u'Excess Baggage (1997)',\n",
       " 878: u'That Darn Cat! (1997)',\n",
       " 879: u'Peacemaker, The (1997)',\n",
       " 880: u'Soul Food (1997)',\n",
       " 881: u'Money Talks (1997)',\n",
       " 882: u'Washington Square (1997)',\n",
       " 883: u'Telling Lies in America (1997)',\n",
       " 884: u'Year of the Horse (1997)',\n",
       " 885: u'Phantoms (1998)',\n",
       " 886: u'Life Less Ordinary, A (1997)',\n",
       " 887: u\"Eve's Bayou (1997)\",\n",
       " 888: u'One Night Stand (1997)',\n",
       " 889: u'Tango Lesson, The (1997)',\n",
       " 890: u'Mortal Kombat: Annihilation (1997)',\n",
       " 891: u'Bent (1997)',\n",
       " 892: u'Flubber (1997)',\n",
       " 893: u'For Richer or Poorer (1997)',\n",
       " 894: u'Home Alone 3 (1997)',\n",
       " 895: u'Scream 2 (1997)',\n",
       " 896: u'Sweet Hereafter, The (1997)',\n",
       " 897: u'Time Tracers (1995)',\n",
       " 898: u'Postman, The (1997)',\n",
       " 899: u'Winter Guest, The (1997)',\n",
       " 900: u'Kundun (1997)',\n",
       " 901: u'Mr. Magoo (1997)',\n",
       " 902: u'Big Lebowski, The (1998)',\n",
       " 903: u'Afterglow (1997)',\n",
       " 904: u'Ma vie en rose (My Life in Pink) (1997)',\n",
       " 905: u'Great Expectations (1998)',\n",
       " 906: u'Oscar & Lucinda (1997)',\n",
       " 907: u'Vermin (1998)',\n",
       " 908: u'Half Baked (1998)',\n",
       " 909: u'Dangerous Beauty (1998)',\n",
       " 910: u'Nil By Mouth (1997)',\n",
       " 911: u'Twilight (1998)',\n",
       " 912: u'U.S. Marshalls (1998)',\n",
       " 913: u'Love and Death on Long Island (1997)',\n",
       " 914: u'Wild Things (1998)',\n",
       " 915: u'Primary Colors (1998)',\n",
       " 916: u'Lost in Space (1998)',\n",
       " 917: u'Mercury Rising (1998)',\n",
       " 918: u'City of Angels (1998)',\n",
       " 919: u'City of Lost Children, The (1995)',\n",
       " 920: u'Two Bits (1995)',\n",
       " 921: u'Farewell My Concubine (1993)',\n",
       " 922: u'Dead Man (1995)',\n",
       " 923: u'Raise the Red Lantern (1991)',\n",
       " 924: u'White Squall (1996)',\n",
       " 925: u'Unforgettable (1996)',\n",
       " 926: u'Down Periscope (1996)',\n",
       " 927: u'Flower of My Secret, The (Flor de mi secreto, La) (1995)',\n",
       " 928: u'Craft, The (1996)',\n",
       " 929: u'Harriet the Spy (1996)',\n",
       " 930: u'Chain Reaction (1996)',\n",
       " 931: u'Island of Dr. Moreau, The (1996)',\n",
       " 932: u'First Kid (1996)',\n",
       " 933: u'Funeral, The (1996)',\n",
       " 934: u\"Preacher's Wife, The (1996)\",\n",
       " 935: u'Paradise Road (1997)',\n",
       " 936: u'Brassed Off (1996)',\n",
       " 937: u'Thousand Acres, A (1997)',\n",
       " 938: u'Smile Like Yours, A (1997)',\n",
       " 939: u'Murder in the First (1995)',\n",
       " 940: u'Airheads (1994)',\n",
       " 941: u'With Honors (1994)',\n",
       " 942: u\"What's Love Got to Do with It (1993)\",\n",
       " 943: u'Killing Zoe (1994)',\n",
       " 944: u'Renaissance Man (1994)',\n",
       " 945: u'Charade (1963)',\n",
       " 946: u'Fox and the Hound, The (1981)',\n",
       " 947: u'Big Blue, The (Grand bleu, Le) (1988)',\n",
       " 948: u'Booty Call (1997)',\n",
       " 949: u'How to Make an American Quilt (1995)',\n",
       " 950: u'Georgia (1995)',\n",
       " 951: u'Indian in the Cupboard, The (1995)',\n",
       " 952: u'Blue in the Face (1995)',\n",
       " 953: u'Unstrung Heroes (1995)',\n",
       " 954: u'Unzipped (1995)',\n",
       " 955: u'Before Sunrise (1995)',\n",
       " 956: u\"Nobody's Fool (1994)\",\n",
       " 957: u'Pushing Hands (1992)',\n",
       " 958: u'To Live (Huozhe) (1994)',\n",
       " 959: u'Dazed and Confused (1993)',\n",
       " 960: u'Naked (1993)',\n",
       " 961: u'Orlando (1993)',\n",
       " 962: u'Ruby in Paradise (1993)',\n",
       " 963: u'Some Folks Call It a Sling Blade (1993)',\n",
       " 964: u'Month by the Lake, A (1995)',\n",
       " 965: u'Funny Face (1957)',\n",
       " 966: u'Affair to Remember, An (1957)',\n",
       " 967: u'Little Lord Fauntleroy (1936)',\n",
       " 968: u'Inspector General, The (1949)',\n",
       " 969: u'Winnie the Pooh and the Blustery Day (1968)',\n",
       " 970: u'Hear My Song (1991)',\n",
       " 971: u'Mediterraneo (1991)',\n",
       " 972: u'Passion Fish (1992)',\n",
       " 973: u'Grateful Dead (1995)',\n",
       " 974: u'Eye for an Eye (1996)',\n",
       " 975: u'Fear (1996)',\n",
       " 976: u'Solo (1996)',\n",
       " 977: u'Substitute, The (1996)',\n",
       " 978: u\"Heaven's Prisoners (1996)\",\n",
       " 979: u'Trigger Effect, The (1996)',\n",
       " 980: u'Mother Night (1996)',\n",
       " 981: u'Dangerous Ground (1997)',\n",
       " 982: u'Maximum Risk (1996)',\n",
       " 983: u\"Rich Man's Wife, The (1996)\",\n",
       " 984: u'Shadow Conspiracy (1997)',\n",
       " 985: u'Blood & Wine (1997)',\n",
       " 986: u'Turbulence (1997)',\n",
       " 987: u'Underworld (1997)',\n",
       " 988: u'Beautician and the Beast, The (1997)',\n",
       " 989: u\"Cats Don't Dance (1997)\",\n",
       " 990: u'Anna Karenina (1997)',\n",
       " 991: u'Keys to Tulsa (1997)',\n",
       " 992: u'Head Above Water (1996)',\n",
       " 993: u'Hercules (1997)',\n",
       " 994: u'Last Time I Committed Suicide, The (1997)',\n",
       " 995: u'Kiss Me, Guido (1997)',\n",
       " 996: u'Big Green, The (1995)',\n",
       " 997: u'Stuart Saves His Family (1995)',\n",
       " 998: u'Cabin Boy (1994)',\n",
       " 999: u'Clean Slate (1994)',\n",
       " 1000: u'Lightning Jack (1994)',\n",
       " ...}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MovieDictionary.get(u'344')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[943, 942]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMovie.map(lambda x : (x[0])).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MovieName = mostPopularMovie.map(lambda x : (MovieDictionary.get(x[0]),x[1]))\n",
    "#mapping between name of movie and id.\n",
    "#name and id is store in directiory. here we compare id from RDD i.e at X[0] and get value from directiory and then print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Killing Zoe (1994)',\n",
       "  u'444142445524454523214254435414443344435344344544524145135432424152535254555235443454255445241235534233533244123242154442525322414145131345441424144445245353331344214342'),\n",
       " (u\"What's Love Got to Do with It (1993)\",\n",
       "  u'4445454334533245554554544534455553544334444555445455455454434534535555544355554'),\n",
       " (u'With Honors (1994)', u'4555444444422355453544'),\n",
       " (u'Airheads (1994)',\n",
       "  u'33334444335543525141145422324353453324534122434343342343444345333444434444355324433435423453441324445444324'),\n",
       " (u'Murder in the First (1995)',\n",
       "  u'2344554554545323545555555255545455525533444535455'),\n",
       " (u'Smile Like Yours, A (1997)',\n",
       "  u'415233214443215332524542223423355341331354343244533345341555431413544334253323344253433325541145451432533135'),\n",
       " (u'Thousand Acres, A (1997)', u'4541544344144445444341343245143324431441'),\n",
       " (u'Brassed Off (1996)',\n",
       "  u'2444344445344545435442335544445455533124453254223443534344433255532345444144243334145434353444424534454424335554533424434434543354554554433443'),\n",
       " (u'Paradise Road (1997)', u'443444425454454445541444534443452454344'),\n",
       " (u\"Preacher's Wife, The (1996)\",\n",
       "  u'532134553543224444545444314453334425325553443544335455444454423544444443454424144534553344443344424114345334354444444544423444344442334434422234445534534444345345444444444411')]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MovieName.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Most Popular SuperHero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"file:///home/icpl12900/Desktop/assignments/Marvel-Graph.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath1 = \"file:///home/icpl12900/Desktop/assignments/Marvel-Names.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataMarvelGraph = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataMarvelName = sc.textFile(filepath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5988 748 1722 3752 4655 5743 1872 3413 5527 6368 6085 4319 4728 1636 2397 3364 4001 1614 1819 1585 732 2660 3952 2507 3891 2070 2239 2602 612 1352 5447 4548 1596 5488 1605 5517 11 479 2554 2043 17 865 4292 6312 473 534 1479 6375 4456 ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMarvelGraph.take(1) #superhero id that appear with other superhero id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1 \"24-HOUR MAN/EMMANUEL\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMarvelName.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseName(row):\n",
    "    row = row.split('\\\"')\n",
    "    row[0] = row[0]\n",
    "    row[1] = row[1]\n",
    "    return (int(row[0]),(row[1].encode(\"utf8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parseDataMarvelName = dataMarvelName.map(parseName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '24-HOUR MAN/EMMANUEL')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseDataMarvelName.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    row = row.split()\n",
    "    return (int(row[0]), len(row)-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parseMarvelGraph = dataMarvelGraph.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5988, 48)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseMarvelGraph.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mostPopularMarvel = parseMarvelGraph.reduceByKey(lambda x,y : x+y).sortBy(lambda x : -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(859, 1933)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMarvel.take(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joinPopularMarvelWithName = mostPopularMarvel.join(parseDataMarvelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostPopularMarvel_Name = joinPopularMarvelWithName.map(lambda x: (x[1][1],x[1][0])) #1st name then count so use 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8-BALL/', 14)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostPopularMarvel_Name.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the Similar Movies Script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"file:///home/icpl12900/Desktop/assignments/ml-100k/u.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'196\\t242\\t3\\t881250949',\n",
       " u'186\\t302\\t3\\t891717742',\n",
       " u'22\\t377\\t1\\t878887116',\n",
       " u'244\\t51\\t2\\t880606923',\n",
       " u'166\\t346\\t1\\t886397596',\n",
       " u'298\\t474\\t4\\t884182806',\n",
       " u'115\\t265\\t2\\t881171488',\n",
       " u'253\\t465\\t5\\t891628467',\n",
       " u'305\\t451\\t3\\t886324817',\n",
       " u'6\\t86\\t3\\t883603013']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = data.map(lambda x : (x.split())).map(lambda x :(int(x[0]),(int(x[1]) , float(x[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, (242, 3.0)), (186, (302, 3.0))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinedRatings = ratings.join(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512, ((265, 4.0), (265, 4.0))),\n",
       " (512, ((265, 4.0), (23, 4.0))),\n",
       " (512, ((265, 4.0), (1, 4.0))),\n",
       " (512, ((265, 4.0), (198, 5.0))),\n",
       " (512, ((265, 4.0), (318, 5.0)))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinedRatings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterDuplicates( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512, ((265, 4.0), (318, 5.0))), (512, ((265, 4.0), (1459, 4.0)))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueJoinedRatings.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePairs = uniqueJoinedRatings.map(makePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((265, 318), (4.0, 5.0)),\n",
       " ((265, 1459), (4.0, 4.0)),\n",
       " ((265, 313), (4.0, 3.0)),\n",
       " ((265, 527), (4.0, 5.0)),\n",
       " ((265, 302), (4.0, 4.0)),\n",
       " ((265, 273), (4.0, 5.0)),\n",
       " ((265, 286), (4.0, 5.0)),\n",
       " ((265, 325), (4.0, 2.0)),\n",
       " ((265, 1238), (4.0, 4.0)),\n",
       " ((23, 265), (4.0, 4.0))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairs.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moviePairRatings = moviePairs.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((197, 1097), <pyspark.resultiterable.ResultIterable at 0x7fe24503c5d0>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairRatings.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePairSimilarities = moviePairRatings.mapValues(lambda x :x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((197, 1097), <pyspark.resultiterable.ResultIterable at 0x7fe245072c50>),\n",
       " ((42, 364), <pyspark.resultiterable.ResultIterable at 0x7fe245072510>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairSimilarities.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((197, 1097), (0.9758729093599599, 7)), ((42, 364), (0.9093486560398836, 18))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairSimilarities.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((24, 1370), (1.0000000000000002, 3)),\n",
       " ((1010, 1244), (1.0000000000000002, 2))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviePairSimilarities.sortBy(lambda x : -x[1][0]).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spart don't do partitioning or distrubute data across multiple executor in cluster so there is need of use \" partitioningBy() \" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
