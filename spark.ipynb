{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if there is more than one sparksubmit kill them using \"kill pid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f6ca802e8d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/routes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "route=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "route.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take top 10 rows from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "route.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take count of no of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take first row from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#route.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take all rows from RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all this upper operation request data from RDD and all are called ACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method which is use to read file as textFile is call \"TRANSFORMATION\"\n",
    "\n",
    "Operations that create RDD and Convert one RDD into another RDD call \"TRANSFORMATION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Difference between transformations and RDD is:\n",
    "1. Transformation is not execute immediately. they execute only actions are call on them\n",
    "\n",
    "** textFile only take file from path and create RDD for it. It not read or do any operation on it. this job is done by actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_for_filter=\"file:///home/icpl12900/Desktop/data_files/prat.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_for_filter=sc.textFile(file_for_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_for_filter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataofhead=data_for_filter.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_without_head=data_for_filter.filter(lambda x : x <> dataofhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_without_head.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using map we can convert unstructre string into structure string with name of filds with we can access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_string=data_without_head.map(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it take whole record and split it into individual string i.e list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_string.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_string.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields=dataofhead.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to print list use only name of list i.e fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',fields,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any object of class have fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row) #this function return object of class_for_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data_without_head.map(parse) #nametuple is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.first() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.first().id #access filed using name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out missing value and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/routes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "route=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = route.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_missing = route.filter(lambda x : x <> header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_missing.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_fields = header.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',header_fields,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_name=data_missing.map(parse) #nametuple is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.map(lambda x : x.Codeshare).countByValue()  #contain null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_name.map(lambda x : x.Equipment).countByValue() #''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter = data_name.filter(lambda x : not (x.Codeshare == '' or x.Equipment == '')) #take all data from data_name and apply function only on codeshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter.map(lambda x : x.Codeshare).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=data_filter.map(lambda x : x.Source_airport_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.reduce(lambda x :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filter.map(lambda x : x.Airline).countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"file:///home/icpl12900/Desktop/assignments/air.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot=sc.textFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_header = airpot.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'IATA/FAA,ICAO,Location,Altitude,Timezone,DST,Tz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot_data = airpot.filter(lambda x :x <> airpot_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'GKA,AYGA,\"-6.081689,145.391881\",5282,10,U,Pacific/Port_Moresby',\n",
       " u'MAG,AYMD,\"-5.207083,145.7887\",20,10,U,Pacific/Port_Moresby',\n",
       " u'HGU,AYMH,\"-5.826789,144.295861\",5388,10,U,Pacific/Port_Moresby',\n",
       " u'LAE,AYNZ,\"-6.569828,146.726242\",239,10,U,Pacific/Port_Moresby',\n",
       " u'POM,AYPY,\"-9.443383,147.22005\",146,10,U,Pacific/Port_Moresby',\n",
       " u'WWK,AYWK,\"-3.583828,143.669186\",19,10,U,Pacific/Port_Moresby',\n",
       " u'UAK,BGBW,\"61.160517,-45.425978\",112,-3,E,America/Godthab',\n",
       " u'GOH,BGGH,\"64.190922,-51.678064\",283,-3,E,America/Godthab',\n",
       " u'SFJ,BGSF,\"67.016969,-50.689325\",165,-3,E,America/Godthab',\n",
       " u'THU,BGTL,\"76.531203,-68.703161\",251,-4,E,America/Thule']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from StringIO import StringIO\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airpot_header_fields = airpot_header.replace(\" \",\"_\").replace(\"/\",\"_\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'IATA_FAA', u'ICAO', u'Location', u'Altitude', u'Timezone', u'DST', u'Tz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_header_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class class_for_nametuple(tuple):\n",
      "    'class_for_nametuple(IATA_FAA, ICAO, Location, Altitude, Timezone, DST, Tz)'\n",
      "\n",
      "    __slots__ = ()\n",
      "\n",
      "    _fields = ('IATA_FAA', 'ICAO', 'Location', 'Altitude', 'Timezone', 'DST', 'Tz')\n",
      "\n",
      "    def __new__(_cls, IATA_FAA, ICAO, Location, Altitude, Timezone, DST, Tz):\n",
      "        'Create new instance of class_for_nametuple(IATA_FAA, ICAO, Location, Altitude, Timezone, DST, Tz)'\n",
      "        return _tuple.__new__(_cls, (IATA_FAA, ICAO, Location, Altitude, Timezone, DST, Tz))\n",
      "\n",
      "    @classmethod\n",
      "    def _make(cls, iterable, new=tuple.__new__, len=len):\n",
      "        'Make a new class_for_nametuple object from a sequence or iterable'\n",
      "        result = new(cls, iterable)\n",
      "        if len(result) != 7:\n",
      "            raise TypeError('Expected 7 arguments, got %d' % len(result))\n",
      "        return result\n",
      "\n",
      "    def __repr__(self):\n",
      "        'Return a nicely formatted representation string'\n",
      "        return 'class_for_nametuple(IATA_FAA=%r, ICAO=%r, Location=%r, Altitude=%r, Timezone=%r, DST=%r, Tz=%r)' % self\n",
      "\n",
      "    def _asdict(self):\n",
      "        'Return a new OrderedDict which maps field names to their values'\n",
      "        return OrderedDict(zip(self._fields, self))\n",
      "\n",
      "    def _replace(_self, **kwds):\n",
      "        'Return a new class_for_nametuple object replacing specified fields with new values'\n",
      "        result = _self._make(map(kwds.pop, ('IATA_FAA', 'ICAO', 'Location', 'Altitude', 'Timezone', 'DST', 'Tz'), _self))\n",
      "        if kwds:\n",
      "            raise ValueError('Got unexpected field names: %r' % kwds.keys())\n",
      "        return result\n",
      "\n",
      "    def __getnewargs__(self):\n",
      "        'Return self as a plain tuple.  Used by copy and pickle.'\n",
      "        return tuple(self)\n",
      "\n",
      "    __dict__ = _property(_asdict)\n",
      "\n",
      "    def __getstate__(self):\n",
      "        'Exclude the OrderedDict from pickling'\n",
      "        pass\n",
      "\n",
      "    IATA_FAA = _property(_itemgetter(0), doc='Alias for field number 0')\n",
      "\n",
      "    ICAO = _property(_itemgetter(1), doc='Alias for field number 1')\n",
      "\n",
      "    Location = _property(_itemgetter(2), doc='Alias for field number 2')\n",
      "\n",
      "    Altitude = _property(_itemgetter(3), doc='Alias for field number 3')\n",
      "\n",
      "    Timezone = _property(_itemgetter(4), doc='Alias for field number 4')\n",
      "\n",
      "    DST = _property(_itemgetter(5), doc='Alias for field number 5')\n",
      "\n",
      "    Tz = _property(_itemgetter(6), doc='Alias for field number 6')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_for_nametuple=namedtuple('class_for_nametuple',airpot_header_fields,verbose=True) #verbose=True it use for give more output related to class u create in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='/home/icpl12900/Desktop/example1.log',level=logging.DEBUG)\n",
    "logging.debug('This message should go to the log file')\n",
    "logging.info('So should this')\n",
    "logging.warning('And this, too')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    try:\n",
    "        reader = csv.reader(StringIO(row))\n",
    "        row=reader.next()\n",
    "        print(\"{} {}\".format(\"My Data\",row.get(1)))\n",
    "        return class_for_nametuple(*row)\n",
    "    except:\n",
    "        return class_for_nametuple(Airport_ID='24', Name='St Anthony', City='St. Anthony', Country='Canada', IATA_FAA='YAY', ICAO='CYAY', Location=\"51.391944,-56.083056\", Altitude='108', Timezone='-3.5', DST='A', Tz='America/St_Johns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(row):\n",
    "    reader = csv.reader(StringIO(row))\n",
    "    row=reader.next()\n",
    "    return class_for_nametuple(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data_name=airpot_data.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processRecord(record):\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airpot_data.foreach(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[6] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-6.081689,145.391881',\n",
       " '-5.207083,145.7887',\n",
       " '-5.826789,144.295861',\n",
       " '-6.569828,146.726242',\n",
       " '-9.443383,147.22005',\n",
       " '-3.583828,143.669186',\n",
       " '61.160517,-45.425978',\n",
       " '64.190922,-51.678064',\n",
       " '67.016969,-50.689325',\n",
       " '76.531203,-68.703161',\n",
       " '65.659994,-18.072703',\n",
       " '65.283333,-14.401389',\n",
       " '64.295556,-15.227222',\n",
       " '65.952328,-17.425978',\n",
       " '66.058056,-23.135278',\n",
       " '63.985,-22.605556',\n",
       " '65.555833,-23.965',\n",
       " '64.13,-21.940556',\n",
       " '66.133333,-18.916667']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.map(lambda x: x.Location).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractCoords(location):\n",
    "    loc_lat = float(location[1:location.index(\",\")])\n",
    "    loc_lan = float(location[location.index(\",\")+1:-1])\n",
    "    return(loc_lat,loc_lan)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[33] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[class_for_nametuple(IATA_FAA='GKA', ICAO='AYGA', Location='-6.081689,145.391881', Altitude='5282', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='MAG', ICAO='AYMD', Location='-5.207083,145.7887', Altitude='20', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='HGU', ICAO='AYMH', Location='-5.826789,144.295861', Altitude='5388', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='LAE', ICAO='AYNZ', Location='-6.569828,146.726242', Altitude='239', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='POM', ICAO='AYPY', Location='-9.443383,147.22005', Altitude='146', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='WWK', ICAO='AYWK', Location='-3.583828,143.669186', Altitude='19', Timezone='10', DST='U', Tz='Pacific/Port_Moresby'),\n",
       " class_for_nametuple(IATA_FAA='UAK', ICAO='BGBW', Location='61.160517,-45.425978', Altitude='112', Timezone='-3', DST='E', Tz='America/Godthab'),\n",
       " class_for_nametuple(IATA_FAA='GOH', ICAO='BGGH', Location='64.190922,-51.678064', Altitude='283', Timezone='-3', DST='E', Tz='America/Godthab'),\n",
       " class_for_nametuple(IATA_FAA='SFJ', ICAO='BGSF', Location='67.016969,-50.689325', Altitude='165', Timezone='-3', DST='E', Tz='America/Godthab'),\n",
       " class_for_nametuple(IATA_FAA='THU', ICAO='BGTL', Location='76.531203,-68.703161', Altitude='251', Timezone='-4', DST='E', Tz='America/Thule'),\n",
       " class_for_nametuple(IATA_FAA='AEY', ICAO='BIAR', Location='65.659994,-18.072703', Altitude='6', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='EGS', ICAO='BIEG', Location='65.283333,-14.401389', Altitude='76', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='HFN', ICAO='BIHN', Location='64.295556,-15.227222', Altitude='24', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='HZK', ICAO='BIHU', Location='65.952328,-17.425978', Altitude='48', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='IFJ', ICAO='BIIS', Location='66.058056,-23.135278', Altitude='8', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='KEF', ICAO='BIKF', Location='63.985,-22.605556', Altitude='171', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='PFJ', ICAO='BIPA', Location='65.555833,-23.965', Altitude='11', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='RKV', ICAO='BIRK', Location='64.13,-21.940556', Altitude='48', Timezone='0', DST='N', Tz='Atlantic/Reykjavik'),\n",
       " class_for_nametuple(IATA_FAA='SIJ', ICAO='BISI', Location='66.133333,-18.916667', Altitude='10', Timezone='0', DST='N', Tz='Atlantic/Reykjavik')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.160517, -68.70316)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.map(lambda x:extractCoords(x.Location)).reduce(lambda x,y:(min(x[0],y[0]),(min(x[1],y[1]))))\n",
    "\n",
    "#x,y means two rows\n",
    "#it find long and minimum latitude\n",
    "#lambda x, y means two arguuments pass to function\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.081689, 145.39188),\n",
       " (5.207083, 145.788),\n",
       " (5.826789, 144.29586),\n",
       " (6.569828, 146.72624),\n",
       " (9.443383, 147.22),\n",
       " (3.583828, 143.66918),\n",
       " (1.160517, -45.42597),\n",
       " (4.190922, -51.67806),\n",
       " (7.016969, -50.68932),\n",
       " (6.531203, -68.70316),\n",
       " (5.659994, -18.0727),\n",
       " (5.283333, -14.40138),\n",
       " (4.295556, -15.22722),\n",
       " (5.952328, -17.42597),\n",
       " (6.058056, -23.13527),\n",
       " (3.985, -22.60555),\n",
       " (5.555833, -23.96),\n",
       " (4.13, -21.94055),\n",
       " (6.133333, -18.91666)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'Atlantic/Reykjavik': 9})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airpot_data_name.filter(lambda x:x.DST == 'N').map(lambda x:x.Tz).countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to work on it\n",
    "\n",
    "import gmplot\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(37.428, -122.145, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAIR RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file1=\"file:///home/icpl12900/Desktop/Pair_rdd/Dodgers.data\"\n",
    "file2=\"file:///home/icpl12900/Desktop/Pair_rdd/Dodgers.events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'4/10/2005 0:00,-1',\n",
       " u'4/10/2005 0:05,-1',\n",
       " u'4/10/2005 0:10,-1',\n",
       " u'4/10/2005 0:15,-1',\n",
       " u'4/10/2005 0:20,-1',\n",
       " u'4/10/2005 0:25,-1',\n",
       " u'4/10/2005 0:30,-1',\n",
       " u'4/10/2005 0:35,-1',\n",
       " u'4/10/2005 0:40,-1',\n",
       " u'4/10/2005 0:45,-1']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic=sc.textFile(file1)\n",
    "traffic.take(10) #time after 5 min , no of car within that 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'04/12/05,13:10:00,16:23:00,55892,San Francisco,W 9-8\\ufffd',\n",
       " u'04/13/05,19:10:00,21:48:00,46514,San Francisco,W 4-1\\ufffd',\n",
       " u'04/15/05,19:40:00,21:48:00,51816,San Diego,W 4-0\\ufffd',\n",
       " u'04/16/05,19:10:00,21:52:00,54704,San Diego,W 8-3\\ufffd',\n",
       " u'04/17/05,13:10:00,15:31:00,53402,San Diego,W 6-0\\ufffd',\n",
       " u'04/25/05,19:10:00,21:33:00,36876,Arizona,L 4-2\\ufffd',\n",
       " u'04/26/05,19:10:00,22:00:00,44486,Arizona,L 3-2\\ufffd',\n",
       " u'04/27/05,19:10:00,22:17:00,54387,Arizona,L 6-3\\ufffd',\n",
       " u'04/29/05,19:40:00,22:01:00,40150,Colorado,W 6-3\\ufffd',\n",
       " u'04/30/05,19:10:00,21:45:00,54123,Colorado,W 6-2\\ufffd']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game=sc.textFile(file2)\n",
    "game.take(10)  #startTime , endTime, audience,opponent,win/loss along with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def parsetraffic(row):\n",
    "    date_format = \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_format)\n",
    "    row[1]=int(row[1])\n",
    "    return(row[0],row[1]) #here we create tuple from record and i.e we create pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trafficparse = traffic.map(parsetraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2005, 4, 10, 0, 0), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 5), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 10), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 15), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 20), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 25), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 30), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 35), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 40), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 45), -1)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficparse.take(10) #timestamp = key and no. of cars = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. reduceByKey : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "same as reduce operation and use for combine record who have same key\n",
    "\n",
    "it need function with two arguments\n",
    "\n",
    "it is transformation\n",
    "\n",
    "it return RDD and we have to do operation on it\n",
    "\n",
    "\n",
    "syntax: lambda(x,y:x+y)    it take 2 value of same key and combine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailytrend = trafficparse.map(lambda x : (x[0].date(),x[1]))\\\n",
    "                        .reduceByKey(lambda x,y :x+y)\n",
    "    \n",
    "    \n",
    "    #we create RDD where key = date and Value = sum of cars\n",
    "    #we convert timestamp into date and take 2nd argument as it is and apply reduceByKey function to sum no of cars of same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 8, 9), 5958),\n",
       " (datetime.date(2005, 6, 29), 5437),\n",
       " (datetime.date(2005, 8, 17), 6673),\n",
       " (datetime.date(2005, 9, 6), 6402),\n",
       " (datetime.date(2005, 5, 22), 4977),\n",
       " (datetime.date(2005, 6, 21), 5759),\n",
       " (datetime.date(2005, 7, 14), 5338),\n",
       " (datetime.date(2005, 8, 25), 6463),\n",
       " (datetime.date(2005, 9, 14), 5631),\n",
       " (datetime.date(2005, 5, 30), 3973)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytrend.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_dailytrend = dailytrend.sortBy(lambda x: -x[1]) \n",
    "\n",
    "#sort operation to sort record and -x[1]   means sort by value i.e x[1] and -x[1] means sort by descinding order\n",
    "#if we use x[1] only then sort by ascending order\n",
    "#sortBy is built-in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 10), -288),\n",
       " (datetime.date(2005, 10, 1), -260),\n",
       " (datetime.date(2005, 6, 28), -96),\n",
       " (datetime.date(2005, 7, 4), 328),\n",
       " (datetime.date(2005, 7, 12), 1204),\n",
       " (datetime.date(2005, 5, 23), 2173),\n",
       " (datetime.date(2005, 9, 17), 2426),\n",
       " (datetime.date(2005, 9, 10), 2851),\n",
       " (datetime.date(2005, 6, 27), 2907),\n",
       " (datetime.date(2005, 7, 10), 3518)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dailytrend.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Merge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spark allow you to merge two pair RDD based on keys . and if they have different value then it make list of that differnt value of same key and this operation is called \"JOIN\"\n",
    "\n",
    "three diff join:\n",
    "\n",
    "1.join == inner join\n",
    "\n",
    "2.leftOuterJoin == same as sql\n",
    "\n",
    "3.rightOuterJoin == same as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "def parsegame(row):\n",
    "    date_format = \"%m/%d/%y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_format).date()\n",
    "    return(row[0],row[4])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameparse = game.map(parsegame)  #create pair RDD of Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 12), u'San Francisco'),\n",
       " (datetime.date(2005, 4, 13), u'San Francisco'),\n",
       " (datetime.date(2005, 4, 15), u'San Diego'),\n",
       " (datetime.date(2005, 4, 16), u'San Diego'),\n",
       " (datetime.date(2005, 4, 17), u'San Diego'),\n",
       " (datetime.date(2005, 4, 25), u'Arizona'),\n",
       " (datetime.date(2005, 4, 26), u'Arizona'),\n",
       " (datetime.date(2005, 4, 27), u'Arizona'),\n",
       " (datetime.date(2005, 4, 29), u'Colorado'),\n",
       " (datetime.date(2005, 4, 30), u'Colorado')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameparse.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailyTrendCombined = dailytrend.leftOuterJoin(gameparse)\n",
    "#create new RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 9, 24), (5848, u'Pittsburgh')),\n",
       " (datetime.date(2005, 8, 11), (7110, u'Philadelphia')),\n",
       " (datetime.date(2005, 6, 21), (5759, None)),\n",
       " (datetime.date(2005, 5, 24), (4138, None)),\n",
       " (datetime.date(2005, 6, 13), (5974, None)),\n",
       " (datetime.date(2005, 7, 18), (5994, None)),\n",
       " (datetime.date(2005, 4, 23), (5366, None)),\n",
       " (datetime.date(2005, 6, 29), (5437, u'San Diego')),\n",
       " (datetime.date(2005, 8, 15), (5329, None)),\n",
       " (datetime.date(2005, 6, 1), (6520, u'Chicago Cubs'))]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendCombined.take(10)\n",
    "#here we join two RDD using date =key and make list of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkGameDay(row):\n",
    "    if row[1][1] == None:\n",
    "        return (row[0],row[1][1],\"Regular Day\",row[1][0])\n",
    "    else:\n",
    "         return (row[0],row[1][1],\"Game Day\",row[1][0])\n",
    "\n",
    "#create function to convert tuple into 4 values:\n",
    "    #date,opponent,type of day and #car\n",
    "    \n",
    "#here row[1][1] means row from leftOuterJoin 2 value from Value elment bcoz index start with 0 so key =0 index and value=1st index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailytrendgame = dailyTrendCombined.map(checkGameDay)\n",
    "#apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 9, 24), u'Pittsburgh', 'Game Day', 5848),\n",
       " (datetime.date(2005, 8, 11), u'Philadelphia', 'Game Day', 7110),\n",
       " (datetime.date(2005, 6, 21), None, 'Regular Day', 5759),\n",
       " (datetime.date(2005, 5, 24), None, 'Regular Day', 4138),\n",
       " (datetime.date(2005, 6, 13), None, 'Regular Day', 5974),\n",
       " (datetime.date(2005, 7, 18), None, 'Regular Day', 5994),\n",
       " (datetime.date(2005, 4, 23), None, 'Regular Day', 5366),\n",
       " (datetime.date(2005, 6, 29), u'San Diego', 'Game Day', 5437),\n",
       " (datetime.date(2005, 8, 15), None, 'Regular Day', 5329),\n",
       " (datetime.date(2005, 6, 1), u'Chicago Cubs', 'Game Day', 6520)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytrendgame.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 7, 28), u'Cincinnati', 'Game Day', 7661),\n",
       " (datetime.date(2005, 7, 29), u'St. Louis', 'Game Day', 7499),\n",
       " (datetime.date(2005, 8, 12), u'NY Mets', 'Game Day', 7287),\n",
       " (datetime.date(2005, 7, 27), u'Cincinnati', 'Game Day', 7238),\n",
       " (datetime.date(2005, 9, 23), u'Pittsburgh', 'Game Day', 7175),\n",
       " (datetime.date(2005, 7, 26), u'Cincinnati', 'Game Day', 7163),\n",
       " (datetime.date(2005, 5, 20), u'LA Angels', 'Game Day', 7119),\n",
       " (datetime.date(2005, 8, 11), u'Philadelphia', 'Game Day', 7110),\n",
       " (datetime.date(2005, 9, 8), None, 'Regular Day', 7107),\n",
       " (datetime.date(2005, 9, 7), u'San Francisco', 'Game Day', 7082)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytrendgame.sortBy(lambda x : -x[3]).take(10) #apply descending sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. CombineByKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use for combine record of same key within RDD\n",
    "\n",
    "use for finding \"AVERAGE of value\"\n",
    "\n",
    "if we want to calculate average by using \"reduceByKey\" then it give wrong result bcoz reduceByKey 1st apply on 1st two rows then result and 3rd row. so it give wrong result\n",
    "\n",
    "so for right result use following:\n",
    "\n",
    "1.sum per group\n",
    "\n",
    "2.count per group\n",
    "\n",
    "3.join\n",
    "\n",
    "4.divide sum/count\n",
    "\n",
    "using combineByKey we complete 1st three steps in 1 step:\n",
    "\n",
    "    combineByKey required 3 function  to compute sum and count at same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Game Day', 5948), ('Regular Day', 5411)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailytrendgame.map(lambda x : (x[2],x[3]))\\  #here 1st create pair RDD where key=regular day or game day and value=traffic\n",
    "               .combineByKey(lambda value : (value,1),\\\n",
    "                             (lambda acc,value : (acc[0] + value, acc[1] + 1)),\\\n",
    "                             (lambda acc1,acc2 : (acc1[0]+acc2[0],acc1[1]+acc2[1])))\\\n",
    "                .mapValues(lambda x : x[0]/x[1])\\ #here we take ratio of sum and count\n",
    "                .collect()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
